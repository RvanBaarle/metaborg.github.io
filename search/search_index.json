{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Spoofax Language Workbench \u00b6 Spoofax is a platform for developing textual (domain-specific) programming languages. The platform provides the following ingredients: Meta-languages for high-level declarative language definition An interactive environment for developing languages using these meta-languages Code generators that produces parsers, type checkers, compilers, interpreters, and other tools from language definitions Generation of full-featured Eclipse editor plugins from language definitions An API for programmatically combining the components of a language implementation With Spoofax you can focus on the essence of language definition and ignore irrelevant implementation details. Get started by downloading and installing Spoofax or build it from source .","title":"Spoofax Language Designer's Workbench"},{"location":"#spoofax-language-workbench","text":"Spoofax is a platform for developing textual (domain-specific) programming languages. The platform provides the following ingredients: Meta-languages for high-level declarative language definition An interactive environment for developing languages using these meta-languages Code generators that produces parsers, type checkers, compilers, interpreters, and other tools from language definitions Generation of full-featured Eclipse editor plugins from language definitions An API for programmatically combining the components of a language implementation With Spoofax you can focus on the essence of language definition and ignore irrelevant implementation details. Get started by downloading and installing Spoofax or build it from source .","title":"Spoofax Language Workbench"},{"location":"getting-started/","text":"Getting started \u00b6 The quickest way to get started with Spoofax by downloading an instance of Eclipse with the latest release. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, use Homebrew on macOS, or download and build Spoofax from source. Installation \u00b6 The recommended way to get started with Spoofax is to download an Eclipse instance with the latest Spoofax plugin. The plugin also includes the Spoofax meta-languages. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, or download and build Spoofax from source. Choose the Eclipse Bundle installation (recommended) or the Eclipse Plugin installation: Eclipse Bundle Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Download Eclipse with Spoofax without an embedded JRE . Nightly releases . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew ( macOS) On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date. Quick Start \u00b6 Once installed, create a new Spoofax project: Right-click the Package Explorer , choose New \u2192 Project , and select Spoofax Language project from the Spoofax category. Provide a name for your new language and click Finish . Select the created language project and press Ctrl + Alt + B ( Cmd + Alt + B on macOS) to build the project. Create a new file with the extension registered to your language to test it. Follow one of the tutorials to learn more. Finding the filename extension of your language If you didn't explicitly specify a filename extension for your language, it is derived from the language name. You can find the filename extension for your language in editor/Main.esv at the extensions property.","title":"Getting started"},{"location":"getting-started/#getting-started","text":"The quickest way to get started with Spoofax by downloading an instance of Eclipse with the latest release. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, use Homebrew on macOS, or download and build Spoofax from source.","title":"Getting started"},{"location":"getting-started/#installation","text":"The recommended way to get started with Spoofax is to download an Eclipse instance with the latest Spoofax plugin. The plugin also includes the Spoofax meta-languages. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, or download and build Spoofax from source. Choose the Eclipse Bundle installation (recommended) or the Eclipse Plugin installation: Eclipse Bundle Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Download Eclipse with Spoofax without an embedded JRE . Nightly releases . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew ( macOS) On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.","title":"Installation"},{"location":"getting-started/#quick-start","text":"Once installed, create a new Spoofax project: Right-click the Package Explorer , choose New \u2192 Project , and select Spoofax Language project from the Spoofax category. Provide a name for your new language and click Finish . Select the created language project and press Ctrl + Alt + B ( Cmd + Alt + B on macOS) to build the project. Create a new file with the extension registered to your language to test it. Follow one of the tutorials to learn more. Finding the filename extension of your language If you didn't explicitly specify a filename extension for your language, it is derived from the language name. You can find the filename extension for your language in editor/Main.esv at the extensions property.","title":"Quick Start"},{"location":"nightly/","text":"Nightly Releases \u00b6 Use the nightly (development) releases of Spoofax only if you want to be on the cutting-edge of Spoofax development. Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the From Source installation: Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: http://buildfarm.metaborg.org/job/metaborg/job/spoofax-releng/job/master/lastSuccessfulBuild/artifact/dist/spoofax/eclipse/site/ Installation instructions . From Source Use Git to clone the Spoofax Github repository : HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Installation instructions .","title":"Nightly Releases"},{"location":"nightly/#nightly-releases","text":"Use the nightly (development) releases of Spoofax only if you want to be on the cutting-edge of Spoofax development. Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the From Source installation: Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: http://buildfarm.metaborg.org/job/metaborg/job/spoofax-releng/job/master/lastSuccessfulBuild/artifact/dist/spoofax/eclipse/site/ Installation instructions . From Source Use Git to clone the Spoofax Github repository : HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Installation instructions .","title":"Nightly Releases"},{"location":"stable/","text":"Stable Releases \u00b6 This page lists the stable releases of Spoofax. While this version is recommended for most users, there is also the nightly version. Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the Homebrew installation ( macOS only): Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.","title":"Stable Releases"},{"location":"stable/#stable-releases","text":"This page lists the stable releases of Spoofax. While this version is recommended for most users, there is also the nightly version. Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the Homebrew installation ( macOS only): Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.","title":"Stable Releases"},{"location":"background/","text":"Background \u00b6 This section contains information on the ideas, architecture, and design decisions behind Spoofax. For the Spoofax language reference, see the References section. Documentation No background yet.","title":"Background"},{"location":"background/#background","text":"This section contains information on the ideas, architecture, and design decisions behind Spoofax. For the Spoofax language reference, see the References section. Documentation No background yet.","title":"Background"},{"location":"background/documentation/","text":"Documentation \u00b6 This page explains the documentation's technology and structure, and how you can contribute. Technology \u00b6 This documentation uses MkDocs , a fast and simple static site generated that's geared towards building project documentation from Markdown files. In particular, this website uses MkDocs Material , which provides a clean look, easy customization, and many features for technical documentation. Structure \u00b6 The structure of this documentation follows the Grand Unified Theory of Documentation where documentation is split into four categories: Tutorials : oriented to learning , enabling newcomers to get started through a lesson, analogous to teaching a child how to cook. How-Tos : oriented to a particular goal , showing how to solve a specific problem through a series of steps, analogous to a recipe in a cookbook. Reference : oriented to information , describing the machinery through dry description, analogous to an encyclopaedia article. Background : oriented to understanding , explaining through discursive explanation, analogous to an article on culinary social history. Contributing \u00b6 Contributing to the documentation is easy. Quick changes and fixing typos can be done by clicking the button in the top-right corner of a page, and editing and saving the underlying Markdown file. More considerable contributions can be made by cloning this repository locally, and editing the Markdown files there. The easiest way to get a live preview (automatically reloading) of your changes, is by installing Docker and executing make from the root directory. This will serve the latest changes to localhost:8000 . MkDocs Reference Extensions Reference Adding Pages \u00b6 The first page mentioned in nav under a section should be some index.md (without a title), and will be used as the index page (home page) for that section. When you add a new page, don't forget to add it to the nav element in the mkdocs.yml file, or it will not show up. Links \u00b6 Links to other Markdown pages should be written as relative links. For example, to link to tutorials from the background/index.md page, write the relative link including the Markdown file: ```markdown [Tutorials](../tutorials/index.md) ``` Absolute Links are Not Supported Absolute links are not supported, and while they may work locally, they break in production. Citations \u00b6 To cite a paper or work, first ensure the citation is in a bibliography ( .bib ) file in the /bibliographies/ directory. For example, in the bibliographies/spoofax.bib file, we find: @inproceedings { KatsV10 , title = {The {Spoofax} language workbench: rules for declarative specification of languages and {IDEs}} , author = {Lennart C. L. Kats and Eelco Visser} , year = {2010} , doi = {10.1145/1869459.1869497} , url = {https://doi.org/10.1145/1869459.1869497} , pages = {444-463} , booktitle = {Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010} , } Adding References To add a reference, add it on Researchr to the Spoofax bibliography . Then on the command-line, invoke the following to regenerate the spoofax.bib file: make bib Do not change the spoofax.bib file manually, it is generated and updated through Researchr . Then reference the work like this: The Spoofax language workbench[@KatsV10] is vital to declarative language development. Finally, add a place for the bibliography footnotes to be added (usually at the end of the file) by adding the following line to the file: \\bibliography The line will be rendered as: The Spoofax language workbench 1 is vital to declarative language development. And the references will be at the bottom of this page. If the citation appears rendered as Spoofax language workbench[^1] , then you might have forgotten to add a place for the bibliography. Technical Details \u00b6 The structure of the documentation repository is as follows (hover over any of the files to see its description): \ud83d\udce6 / \u2523 \ud83d\udcc1 .github \u2523 \ud83d\udcc2 docs \u2503 \u2523 \ud83d\udcc2 assets \u2503 \u2503 \u2523 \ud83d\udcdc favicon.png \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-dark.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-light.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero.svg \u2503 \u2503 \u2523 \ud83d\udcdc logo.svg \u2503 \u2503 \u2517 \ud83d\udcdc styles.css \u2503 \u2523 \ud83d\udcc2 background \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2523 \ud83d\udcc2 howtos \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2523 \ud83d\udcc2 reference \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2523 \ud83d\udcc2 tutorials \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2517 \ud83d\udcdc index.md \u2523 \ud83d\udcc1 overrides \u2503 \u2523 \ud83d\udcdc index.html \u2503 \u2517 \ud83d\udcdc main.html \u2523 \ud83d\udcdc .gitignore \u2523 \ud83d\udcdc Dockerfile \u2523 \ud83d\udcdc LICENSE \u2523 \ud83d\udcdc Makefile \u2523 \ud83d\udcdc mkdocs_requirements.txt \u2523 \ud83d\udcdc mkdocs.yml \u2517 \ud83d\udcdc README.md Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9","title":"Documentation"},{"location":"background/documentation/#documentation","text":"This page explains the documentation's technology and structure, and how you can contribute.","title":"Documentation"},{"location":"background/documentation/#technology","text":"This documentation uses MkDocs , a fast and simple static site generated that's geared towards building project documentation from Markdown files. In particular, this website uses MkDocs Material , which provides a clean look, easy customization, and many features for technical documentation.","title":"Technology"},{"location":"background/documentation/#structure","text":"The structure of this documentation follows the Grand Unified Theory of Documentation where documentation is split into four categories: Tutorials : oriented to learning , enabling newcomers to get started through a lesson, analogous to teaching a child how to cook. How-Tos : oriented to a particular goal , showing how to solve a specific problem through a series of steps, analogous to a recipe in a cookbook. Reference : oriented to information , describing the machinery through dry description, analogous to an encyclopaedia article. Background : oriented to understanding , explaining through discursive explanation, analogous to an article on culinary social history.","title":"Structure"},{"location":"background/documentation/#contributing","text":"Contributing to the documentation is easy. Quick changes and fixing typos can be done by clicking the button in the top-right corner of a page, and editing and saving the underlying Markdown file. More considerable contributions can be made by cloning this repository locally, and editing the Markdown files there. The easiest way to get a live preview (automatically reloading) of your changes, is by installing Docker and executing make from the root directory. This will serve the latest changes to localhost:8000 . MkDocs Reference Extensions Reference","title":"Contributing"},{"location":"background/documentation/#adding-pages","text":"The first page mentioned in nav under a section should be some index.md (without a title), and will be used as the index page (home page) for that section. When you add a new page, don't forget to add it to the nav element in the mkdocs.yml file, or it will not show up.","title":"Adding Pages"},{"location":"background/documentation/#links","text":"Links to other Markdown pages should be written as relative links. For example, to link to tutorials from the background/index.md page, write the relative link including the Markdown file: ```markdown [Tutorials](../tutorials/index.md) ``` Absolute Links are Not Supported Absolute links are not supported, and while they may work locally, they break in production.","title":"Links"},{"location":"background/documentation/#citations","text":"To cite a paper or work, first ensure the citation is in a bibliography ( .bib ) file in the /bibliographies/ directory. For example, in the bibliographies/spoofax.bib file, we find: @inproceedings { KatsV10 , title = {The {Spoofax} language workbench: rules for declarative specification of languages and {IDEs}} , author = {Lennart C. L. Kats and Eelco Visser} , year = {2010} , doi = {10.1145/1869459.1869497} , url = {https://doi.org/10.1145/1869459.1869497} , pages = {444-463} , booktitle = {Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010} , } Adding References To add a reference, add it on Researchr to the Spoofax bibliography . Then on the command-line, invoke the following to regenerate the spoofax.bib file: make bib Do not change the spoofax.bib file manually, it is generated and updated through Researchr . Then reference the work like this: The Spoofax language workbench[@KatsV10] is vital to declarative language development. Finally, add a place for the bibliography footnotes to be added (usually at the end of the file) by adding the following line to the file: \\bibliography The line will be rendered as: The Spoofax language workbench 1 is vital to declarative language development. And the references will be at the bottom of this page. If the citation appears rendered as Spoofax language workbench[^1] , then you might have forgotten to add a place for the bibliography.","title":"Citations"},{"location":"background/documentation/#technical-details","text":"The structure of the documentation repository is as follows (hover over any of the files to see its description): \ud83d\udce6 / \u2523 \ud83d\udcc1 .github \u2523 \ud83d\udcc2 docs \u2503 \u2523 \ud83d\udcc2 assets \u2503 \u2503 \u2523 \ud83d\udcdc favicon.png \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-dark.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-light.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero.svg \u2503 \u2503 \u2523 \ud83d\udcdc logo.svg \u2503 \u2503 \u2517 \ud83d\udcdc styles.css \u2503 \u2523 \ud83d\udcc2 background \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2523 \ud83d\udcc2 howtos \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2523 \ud83d\udcc2 reference \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2523 \ud83d\udcc2 tutorials \u2503 \u2503 \u2517 \ud83d\udcdc index.md \u2503 \u2517 \ud83d\udcdc index.md \u2523 \ud83d\udcc1 overrides \u2503 \u2523 \ud83d\udcdc index.html \u2503 \u2517 \ud83d\udcdc main.html \u2523 \ud83d\udcdc .gitignore \u2523 \ud83d\udcdc Dockerfile \u2523 \ud83d\udcdc LICENSE \u2523 \ud83d\udcdc Makefile \u2523 \ud83d\udcdc mkdocs_requirements.txt \u2523 \ud83d\udcdc mkdocs.yml \u2517 \ud83d\udcdc README.md Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9","title":"Technical Details"},{"location":"background/bibliography/stratego/","text":"A Stratego Bibliography \u00b6 The original publication on Stratego appeared in ICFP'98 1 and introduced named rewrite rules and a language of strategy combinators. The paper also introduced contextual terms. These where eventually replaced by dynamic rewrite rules 2 . core language 3 System descriptions Stratego 0.5 4 , Stratego/XT 0.16 [@Bravenboer], Stratego/XT 0.17 [@Bravenboer] gradual typing 5 References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae , 69(1-2):123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1 , doi:10.1016/S1571-0661(05)80027-1 . \u21a9 Eelco Visser. Stratego: a language for program transformation based on rewriting strategies. In Aart Middeldorp, editor, Rewriting Techniques and Applications, 12 th International Conference, RTA 2001, Utrecht, The Netherlands, May 22-24, 2001, Proceedings , volume 2051 of Lecture Notes in Computer Science, 357\u2013362. Springer, 2001. URL: https://doi.org/10.1007/3-540-45127-7_27 , doi:10.1007/3-540-45127-7_27 . \u21a9 Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9","title":"A Stratego Bibliography"},{"location":"background/bibliography/stratego/#a-stratego-bibliography","text":"The original publication on Stratego appeared in ICFP'98 1 and introduced named rewrite rules and a language of strategy combinators. The paper also introduced contextual terms. These where eventually replaced by dynamic rewrite rules 2 . core language 3 System descriptions Stratego 0.5 4 , Stratego/XT 0.16 [@Bravenboer], Stratego/XT 0.17 [@Bravenboer] gradual typing 5","title":"A Stratego Bibliography"},{"location":"background/bibliography/stratego/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae , 69(1-2):123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1 , doi:10.1016/S1571-0661(05)80027-1 . \u21a9 Eelco Visser. Stratego: a language for program transformation based on rewriting strategies. In Aart Middeldorp, editor, Rewriting Techniques and Applications, 12 th International Conference, RTA 2001, Utrecht, The Netherlands, May 22-24, 2001, Proceedings , volume 2051 of Lecture Notes in Computer Science, 357\u2013362. Springer, 2001. URL: https://doi.org/10.1007/3-540-45127-7_27 , doi:10.1007/3-540-45127-7_27 . \u21a9 Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9","title":"References"},{"location":"background/statix/","text":"Statix Background \u00b6 rule selection open/closed world reasoning ( try /DWF/DLeq) desugaring of functional rules Internal representation of scope graphs Query Scheduling/Permission to Extend","title":"Statix Background"},{"location":"background/statix/#statix-background","text":"rule selection open/closed world reasoning ( try /DWF/DLeq) desugaring of functional rules Internal representation of scope graphs Query Scheduling/Permission to Extend","title":"Statix Background"},{"location":"howtos/","text":"How-To's \u00b6 These are some How-To's that help you to get to a specific goal or result with Spoofax. For hands-on tutorials on learning Spoofax, see the Tutorials section. For the Spoofax languages references, see the References section. Installation and Build \u00b6 Install the Eclipse with Spoofax Plugin Bundle Install the Spoofax Eclipse Plugin Manually Install Spoofax from Source","title":"How-To's"},{"location":"howtos/#how-tos","text":"These are some How-To's that help you to get to a specific goal or result with Spoofax. For hands-on tutorials on learning Spoofax, see the Tutorials section. For the Spoofax languages references, see the References section.","title":"How-To's"},{"location":"howtos/#installation-and-build","text":"Install the Eclipse with Spoofax Plugin Bundle Install the Spoofax Eclipse Plugin Manually Install Spoofax from Source","title":"Installation and Build"},{"location":"howtos/install-eclipse-bundle/","text":"Install the Eclipse with Spoofax Plugin Bundle \u00b6 Install an Eclipse instance with the latest stable release of the Spoofax plugin pre-installed for your platform: Eclipse with JRE (recommended) Eclipse bundle including the Spoofax plugin with embedded Java Runtime Environment (JRE) (recommended): + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Eclipse Eclipse bundle including the Spoofax plugin ( no embedded JRE ): macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Nightly releases . Troubleshooting \u00b6 macOS: \"Eclipse\" cannot be opened because the developer could not be verified \u00b6 macOS puts unverified binaries in 'quarantine' and disallows their execution. To remove the com.apple.quarantine attribute, do: xattr -rc Eclipse.app Eclipse does not start, or complains about missing Java \u00b6 Download the Eclipse bundle with embedded JRE . Otherwise, ensure you have a distribution of Java installed. Then in eclipse.ini , add a -vm line at the top of the file, followed by the path to the Java installation. For example, with SDKMan! on macOS: -vm /Users/myusername/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib","title":"Install the Eclipse with Spoofax Plugin Bundle"},{"location":"howtos/install-eclipse-bundle/#install-the-eclipse-with-spoofax-plugin-bundle","text":"Install an Eclipse instance with the latest stable release of the Spoofax plugin pre-installed for your platform: Eclipse with JRE (recommended) Eclipse bundle including the Spoofax plugin with embedded Java Runtime Environment (JRE) (recommended): + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Eclipse Eclipse bundle including the Spoofax plugin ( no embedded JRE ): macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Nightly releases .","title":"Install the Eclipse with Spoofax Plugin Bundle"},{"location":"howtos/install-eclipse-bundle/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"howtos/install-eclipse-bundle/#macos-eclipse-cannot-be-opened-because-the-developer-could-not-be-verified","text":"macOS puts unverified binaries in 'quarantine' and disallows their execution. To remove the com.apple.quarantine attribute, do: xattr -rc Eclipse.app","title":" macOS: \"Eclipse\" cannot be opened because the developer could not be verified"},{"location":"howtos/install-eclipse-bundle/#eclipse-does-not-start-or-complains-about-missing-java","text":"Download the Eclipse bundle with embedded JRE . Otherwise, ensure you have a distribution of Java installed. Then in eclipse.ini , add a -vm line at the top of the file, followed by the path to the Java installation. For example, with SDKMan! on macOS: -vm /Users/myusername/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib","title":"Eclipse does not start, or complains about missing Java"},{"location":"howtos/install-eclipse-plugin-manually/","text":"Install the Spoofax Eclipse Plugin Manually \u00b6 Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer. In Eclipse, go to menu Help \u2192 Install New Software . In the Work with: text area, type: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ ( Nightly releases ). Uncheck Group items by category to make the plugin visible. Check Spoofax Eclipse meta-tooling , Spoofax Eclipse meta-tooling M2E integration and Spoofax Eclipse runtime . Click Install and go through the remaining steps. Restart Eclipse.","title":"Install the Spoofax Eclipse Plugin Manually"},{"location":"howtos/install-eclipse-plugin-manually/#install-the-spoofax-eclipse-plugin-manually","text":"Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer. In Eclipse, go to menu Help \u2192 Install New Software . In the Work with: text area, type: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ ( Nightly releases ). Uncheck Group items by category to make the plugin visible. Check Spoofax Eclipse meta-tooling , Spoofax Eclipse meta-tooling M2E integration and Spoofax Eclipse runtime . Click Install and go through the remaining steps. Restart Eclipse.","title":"Install the Spoofax Eclipse Plugin Manually"},{"location":"howtos/install-from-source/","text":"Install Spoofax from Source \u00b6 Perform a manual build and installation of cutting-edge Spoofax from source, by first cloning the Git repository: HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Then: Using a terminal, navigate to the root of the spoofax-releng repository. (Optional.) Generate a new Maven ~/.m2/settings.xml with the Spoofax repository information. ./b gen-mvn-settings This will overwrite your existing ~/.m2/settings.xml file! Invoke the following command to build Spoofax and its submodules and meta-languages: ./b build all (Optional.) Generate a new Eclipse instance with the Spoofax plugin embedded into it: ./b gen-eclipse --destination Spoofax.app","title":"Install Spoofax from Source"},{"location":"howtos/install-from-source/#install-spoofax-from-source","text":"Perform a manual build and installation of cutting-edge Spoofax from source, by first cloning the Git repository: HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Then: Using a terminal, navigate to the root of the spoofax-releng repository. (Optional.) Generate a new Maven ~/.m2/settings.xml with the Spoofax repository information. ./b gen-mvn-settings This will overwrite your existing ~/.m2/settings.xml file! Invoke the following command to build Spoofax and its submodules and meta-languages: ./b build all (Optional.) Generate a new Eclipse instance with the Spoofax plugin embedded into it: ./b gen-eclipse --destination Spoofax.app","title":"Install Spoofax from Source"},{"location":"howtos/editor-services/rename-refactoring/","text":"Add Rename Refactoring to an Existing Project \u00b6 Rename Refactoring is the ability for the user to select a reference or declaration and rename it to across the whole program while not introducing errors and not touching syntactically equal names. Renaming in Statix \u00b6 To enable the Rename Refactoring for an existing Spoofax Language project that uses Statix, create an action that calls the rename-action strategy from the statixruntime library. The parameters are explained in the reference . For example: module renaming imports statixruntime statix / runtime / renaming pp analysis rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id ) Renaming in NaBL2 \u00b6 There also exists a version of the Rename refactoring that works with languages using NaBL2. It can be added with a Stratego module like this: module renaming imports nabl2 / runtime pp analysis rules rename-menu-action = nabl2-rename-action ( construct-textual-change , editor-analyze , id ) Menu Action \u00b6 The rename refactoring is triggered from an entry in the Spoofax menu. To add it to an existing project a menu like the following can be implemented in an ESV file : module Refactoring menus menu : \"Refactoring\" action : \"Rename\" = re name - menu - action See Also \u00b6 Reference: Rename Refactoring","title":"Add Rename Refactoring to an Existing Project"},{"location":"howtos/editor-services/rename-refactoring/#add-rename-refactoring-to-an-existing-project","text":"Rename Refactoring is the ability for the user to select a reference or declaration and rename it to across the whole program while not introducing errors and not touching syntactically equal names.","title":"Add Rename Refactoring to an Existing Project"},{"location":"howtos/editor-services/rename-refactoring/#renaming-in-statix","text":"To enable the Rename Refactoring for an existing Spoofax Language project that uses Statix, create an action that calls the rename-action strategy from the statixruntime library. The parameters are explained in the reference . For example: module renaming imports statixruntime statix / runtime / renaming pp analysis rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id )","title":"Renaming in Statix"},{"location":"howtos/editor-services/rename-refactoring/#renaming-in-nabl2","text":"There also exists a version of the Rename refactoring that works with languages using NaBL2. It can be added with a Stratego module like this: module renaming imports nabl2 / runtime pp analysis rules rename-menu-action = nabl2-rename-action ( construct-textual-change , editor-analyze , id )","title":"Renaming in NaBL2"},{"location":"howtos/editor-services/rename-refactoring/#menu-action","text":"The rename refactoring is triggered from an entry in the Spoofax menu. To add it to an existing project a menu like the following can be implemented in an ESV file : module Refactoring menus menu : \"Refactoring\" action : \"Rename\" = re name - menu - action","title":"Menu Action"},{"location":"howtos/editor-services/rename-refactoring/#see-also","text":"Reference: Rename Refactoring","title":"See Also"},{"location":"howtos/stratego/debug-stratego/","text":"How to Debug Stratego Programs \u00b6 Types \u00b6 With \u00b6 Debug \u00b6 debug ( ! \"\" )","title":"How to Debug Stratego Programs"},{"location":"howtos/stratego/debug-stratego/#how-to-debug-stratego-programs","text":"","title":"How to Debug Stratego Programs"},{"location":"howtos/stratego/debug-stratego/#types","text":"","title":"Types"},{"location":"howtos/stratego/debug-stratego/#with","text":"","title":"With"},{"location":"howtos/stratego/debug-stratego/#debug","text":"debug ( ! \"\" )","title":"Debug"},{"location":"howtos/stratego/exchange-terms/","text":"How to Exchange Terms \u00b6 The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.","title":"How to Exchange Terms"},{"location":"howtos/stratego/exchange-terms/#how-to-exchange-terms","text":"The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.","title":"How to Exchange Terms"},{"location":"howtos/stratego/inspect-terms/","text":"How To Inspect Terms \u00b6 As a Stratego programmer you will be looking a lot at raw ATerms. Stratego pioneers did this by opening an ATerm file in emacs and trying to get a sense of the structure by parenthesis highlighting and inserting newlines here and there. These days your life is much more pleasant through pretty-printing ATerms, which adds layout to a term to make it readable. For example, parsing the following program let function fact(n : int) : int = if n < 1 then 1 else (n * fact(n - 1)) in printint(fact(10)) end produces the following ATerm: Let([FunDecs([FunDec(\"fact\",[FArg(\"n\",Tp(Tid(\"int\")))],Tp(Tid(\"int\")), If(Lt(Var(\"n\"),Int(\"1\")),Int(\"1\"),Seq([Times(Var(\"n\"),Call(Var(\"fact\"), [Minus(Var(\"n\"),Int(\"1\"))]))])))])],[Call(Var(\"printint\"),[Call(Var( \"fact\"),[Int(\"10\")])])]) By pretty-printing the term we get a much more readable term: Let( [ FunDecs( [ FunDec( \"fact\" , [FArg(\"n\", Tp(Tid(\"int\")))] , Tp(Tid(\"int\")) , If( Lt(Var(\"n\"), Int(\"1\")) , Int(\"1\") , Seq([ Times(Var(\"n\"), Call(Var(\"fact\"), [Minus(Var(\"n\"), Int(\"1\"))])) ]) ) ) ] ) ] , [ Call(Var(\"printint\"), [Call(Var(\"fact\"), [Int(\"10\")])]) ] ) In Spoofax/Eclipse, you will find that in some contexts ATerms are automatically pretty-printed, whereas in others they are simply printed linearly. However, you can obtain assistance with perceiving the structure of any ATerm by writing it into a file with the \".aterm\" extension and opening it in the Spoofax Editor in Eclipse. On the right there will be a convenient Outline Navigator which allows you to select any node in the ATerm and see the entire subtree below it highlighted in the editor.","title":"How To Inspect Terms"},{"location":"howtos/stratego/inspect-terms/#how-to-inspect-terms","text":"As a Stratego programmer you will be looking a lot at raw ATerms. Stratego pioneers did this by opening an ATerm file in emacs and trying to get a sense of the structure by parenthesis highlighting and inserting newlines here and there. These days your life is much more pleasant through pretty-printing ATerms, which adds layout to a term to make it readable. For example, parsing the following program let function fact(n : int) : int = if n < 1 then 1 else (n * fact(n - 1)) in printint(fact(10)) end produces the following ATerm: Let([FunDecs([FunDec(\"fact\",[FArg(\"n\",Tp(Tid(\"int\")))],Tp(Tid(\"int\")), If(Lt(Var(\"n\"),Int(\"1\")),Int(\"1\"),Seq([Times(Var(\"n\"),Call(Var(\"fact\"), [Minus(Var(\"n\"),Int(\"1\"))]))])))])],[Call(Var(\"printint\"),[Call(Var( \"fact\"),[Int(\"10\")])])]) By pretty-printing the term we get a much more readable term: Let( [ FunDecs( [ FunDec( \"fact\" , [FArg(\"n\", Tp(Tid(\"int\")))] , Tp(Tid(\"int\")) , If( Lt(Var(\"n\"), Int(\"1\")) , Int(\"1\") , Seq([ Times(Var(\"n\"), Call(Var(\"fact\"), [Minus(Var(\"n\"), Int(\"1\"))])) ]) ) ) ] ) ] , [ Call(Var(\"printint\"), [Call(Var(\"fact\"), [Int(\"10\")])]) ] ) In Spoofax/Eclipse, you will find that in some contexts ATerms are automatically pretty-printed, whereas in others they are simply printed linearly. However, you can obtain assistance with perceiving the structure of any ATerm by writing it into a file with the \".aterm\" extension and opening it in the Spoofax Editor in Eclipse. On the right there will be a convenient Outline Navigator which allows you to select any node in the ATerm and see the entire subtree below it highlighted in the editor.","title":"How To Inspect Terms"},{"location":"howtos/stratego/run-stratego-programs/","text":"How to Run Stratego Programs \u00b6","title":"How to Run Stratego Programs"},{"location":"howtos/stratego/run-stratego-programs/#how-to-run-stratego-programs","text":"","title":"How to Run Stratego Programs"},{"location":"references/","text":"References \u00b6 This are the Spoofax and meta-language references. For more background information on the ideas, architecture, and design decisions behind Spoofax and its meta-languages, see the Background section. The reference section should explain language constructs (syntax, statics, dynamics) and be structured following a taxonomy of the language Table of Contents \u00b6 SDF3 (Jasper) Statix (Aron) FlowSpec (Matthijs, Jeff) Stratego (Eelco, Jeff) PIE (Ivo, Gabri\u00ebl) MkDocs (Dani\u00ebl) bibtex syntax highlighting ESV / editor services Reviewing Peter Toine","title":"References"},{"location":"references/#references","text":"This are the Spoofax and meta-language references. For more background information on the ideas, architecture, and design decisions behind Spoofax and its meta-languages, see the Background section. The reference section should explain language constructs (syntax, statics, dynamics) and be structured following a taxonomy of the language","title":"References"},{"location":"references/#table-of-contents","text":"SDF3 (Jasper) Statix (Aron) FlowSpec (Matthijs, Jeff) Stratego (Eelco, Jeff) PIE (Ivo, Gabri\u00ebl) MkDocs (Dani\u00ebl) bibtex syntax highlighting ESV / editor services Reviewing Peter Toine","title":"Table of Contents"},{"location":"references/config/","text":"Language Configuration \u00b6 metaborg.yaml","title":"Language Configuration"},{"location":"references/config/#language-configuration","text":"metaborg.yaml","title":"Language Configuration"},{"location":"references/editor-services/","text":"Editor Services \u00b6 Most editor services are configured in an ESV file . This way the following editor services can be defined: Action Menus Analysis File Extensions Hover Tooltips On-Save Handlers Outline View Parsing Reference Resolution Stratego Strategies Syntax Highlighting Additionally, the following editor services are configured in a different way: Rename Refactoring","title":"Editor Services"},{"location":"references/editor-services/#editor-services","text":"Most editor services are configured in an ESV file . This way the following editor services can be defined: Action Menus Analysis File Extensions Hover Tooltips On-Save Handlers Outline View Parsing Reference Resolution Stratego Strategies Syntax Highlighting Additionally, the following editor services are configured in a different way: Rename Refactoring","title":"Editor Services"},{"location":"references/editor-services/analysis/","text":"Analysis \u00b6 The analyzer strategy is used to perform static analyses such as name and type analysis, on the AST that a parser produces. An analysis context provides a project-wide store to facilitate multi-file analysis and incrementality. There are four ways to configure the analysis, which set the analyzer strategy with the observer and context keys in an ESV file . language context : $Context observer : $Strategy No Analysis \u00b6 To completely disable analysis, do not set an observer and set the context to none: language context : none Stratego \u00b6 Stratego-based analysis allows you to implement your analysis in Stratego: language context : legacy observer : editor-analyze The identifier after the colon refers to the Stratego strategy that performs the analysis. It must take as input a 3-tuple (ast, path, projectPath) . As output it must produce a 4-tuple (ast, error*, warning*, note*) . The following Stratego code is an example of a strategy that implements this signature: editor-analyze : ( ast , path , projectPath ) - > ( ast ' , errors , warnings , notes ) with ast ' := < analyze > ast ; errors := < collect-all ( check-error )> ast ' ; warnings := < collect-all ( check-warning )> ast ' ; notes := < collect-all ( check-note )> ast ' Statix \u00b6 To use Statix as the meta-language for name and type analysis, use the editor-analyze strategy defined in trans/analysis.str , annotate it with the (constraint) modifier, and set no context: language observer : editor-analyze ( constraint ) By default, the Statix analyzer works in single-file mode and does not consider multi-file name resolution. To enable that, add the (multifile) modifier: language observer : editor-analyze ( constraint ) ( multifile )","title":"Analysis"},{"location":"references/editor-services/analysis/#analysis","text":"The analyzer strategy is used to perform static analyses such as name and type analysis, on the AST that a parser produces. An analysis context provides a project-wide store to facilitate multi-file analysis and incrementality. There are four ways to configure the analysis, which set the analyzer strategy with the observer and context keys in an ESV file . language context : $Context observer : $Strategy","title":"Analysis"},{"location":"references/editor-services/analysis/#no-analysis","text":"To completely disable analysis, do not set an observer and set the context to none: language context : none","title":"No Analysis"},{"location":"references/editor-services/analysis/#stratego","text":"Stratego-based analysis allows you to implement your analysis in Stratego: language context : legacy observer : editor-analyze The identifier after the colon refers to the Stratego strategy that performs the analysis. It must take as input a 3-tuple (ast, path, projectPath) . As output it must produce a 4-tuple (ast, error*, warning*, note*) . The following Stratego code is an example of a strategy that implements this signature: editor-analyze : ( ast , path , projectPath ) - > ( ast ' , errors , warnings , notes ) with ast ' := < analyze > ast ; errors := < collect-all ( check-error )> ast ' ; warnings := < collect-all ( check-warning )> ast ' ; notes := < collect-all ( check-note )> ast '","title":"Stratego"},{"location":"references/editor-services/analysis/#statix","text":"To use Statix as the meta-language for name and type analysis, use the editor-analyze strategy defined in trans/analysis.str , annotate it with the (constraint) modifier, and set no context: language observer : editor-analyze ( constraint ) By default, the Statix analyzer works in single-file mode and does not consider multi-file name resolution. To enable that, add the (multifile) modifier: language observer : editor-analyze ( constraint ) ( multifile )","title":"Statix"},{"location":"references/editor-services/esv/","text":"ESV \u00b6 The Editor Service (ESV) language is a declarative meta-language for configuring the editor services of a language. For example, the following ESV code fragment configures the syntax highlighting for a language, based on the types of tokens: module color colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic Structure \u00b6 ESV files end with the .esv extension, and are by convention placed in the editor/ folder of a language project. Each ESV file defines a module for the file, followed by import statements and then the main configuration sections. Each section consists of a number of keys and values. Main File By convention, the main ESV file of a language project must live at editor/Main.esv (default) or editor/main.esv . Other ESV files can be (transitively) imported from the main ESV file. Module Definition \u00b6 An ESV file starts with a module definition at the top of the file: module $ModuleName The module name is the filename of the ESV file without the exttension, and relative to the editor/ directory. For example, the module editor/mylang/Syntax.esv would have the following module name: module mylang/Syntax Module names can only contains the alphanumeric characters and dash, underscore, and period, and use the forward slash ( / ) as the path separator. Module names cannot be in parent directories, so ../Syntax is not allowed. Imports \u00b6 The imports section is an optional section immediately following the module definition. When specified it is given as: imports $Imports For example, to import editor/Syntax.esv and editor/Analysis.esv : imports Syntax Analysis Imports are transitive. At most one imports section is permitted. When specified, the imports section cannot be empty. Configuration Sections \u00b6 The main body of an ESV file consists of any number of configuration sections. An example of a configuration section is: language line comment : \"//\" block comment : \"/*\" \"*/\" The configuration sections are hard-coded in the ESV language, but mostly use a consistent syntax for the keys and values. The following configuration sections are currently defined: colorer Syntax Highlighting language Language File Extensions Parsing Analysis On-Save Handlers Stratego Strategies menus Action menus references Hover Tooltips Reference Resolutions views Outline View The following sections have been deprecated: analysis builders completions folding outliner refactorings","title":"ESV"},{"location":"references/editor-services/esv/#esv","text":"The Editor Service (ESV) language is a declarative meta-language for configuring the editor services of a language. For example, the following ESV code fragment configures the syntax highlighting for a language, based on the types of tokens: module color colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic","title":"ESV"},{"location":"references/editor-services/esv/#structure","text":"ESV files end with the .esv extension, and are by convention placed in the editor/ folder of a language project. Each ESV file defines a module for the file, followed by import statements and then the main configuration sections. Each section consists of a number of keys and values. Main File By convention, the main ESV file of a language project must live at editor/Main.esv (default) or editor/main.esv . Other ESV files can be (transitively) imported from the main ESV file.","title":"Structure"},{"location":"references/editor-services/esv/#module-definition","text":"An ESV file starts with a module definition at the top of the file: module $ModuleName The module name is the filename of the ESV file without the exttension, and relative to the editor/ directory. For example, the module editor/mylang/Syntax.esv would have the following module name: module mylang/Syntax Module names can only contains the alphanumeric characters and dash, underscore, and period, and use the forward slash ( / ) as the path separator. Module names cannot be in parent directories, so ../Syntax is not allowed.","title":"Module Definition"},{"location":"references/editor-services/esv/#imports","text":"The imports section is an optional section immediately following the module definition. When specified it is given as: imports $Imports For example, to import editor/Syntax.esv and editor/Analysis.esv : imports Syntax Analysis Imports are transitive. At most one imports section is permitted. When specified, the imports section cannot be empty.","title":"Imports"},{"location":"references/editor-services/esv/#configuration-sections","text":"The main body of an ESV file consists of any number of configuration sections. An example of a configuration section is: language line comment : \"//\" block comment : \"/*\" \"*/\" The configuration sections are hard-coded in the ESV language, but mostly use a consistent syntax for the keys and values. The following configuration sections are currently defined: colorer Syntax Highlighting language Language File Extensions Parsing Analysis On-Save Handlers Stratego Strategies menus Action menus references Hover Tooltips Reference Resolutions views Outline View The following sections have been deprecated: analysis builders completions folding outliner refactorings","title":"Configuration Sections"},{"location":"references/editor-services/file-extensions/","text":"Language File Extensions \u00b6 The file extensions that the editor should recognize as files belonging to the language definition, are configured in the language section extensions key of an ESV file . They are specified without a leading dot: language extensions : ent Multiple extensions can be set with a comma-separated list: language extensions : ent , entity , entities This will assign for example foo.ent , foo.entity , and foo.entities to the language.","title":"Language File Extensions"},{"location":"references/editor-services/file-extensions/#language-file-extensions","text":"The file extensions that the editor should recognize as files belonging to the language definition, are configured in the language section extensions key of an ESV file . They are specified without a leading dot: language extensions : ent Multiple extensions can be set with a comma-separated list: language extensions : ent , entity , entities This will assign for example foo.ent , foo.entity , and foo.entities to the language.","title":"Language File Extensions"},{"location":"references/editor-services/hover/","text":"Hover Tooltips \u00b6 Hover tooltips show a textual tooltip with extra information, when hovering part of the text. Hover tooltips are created by a Stratego strategy, but are configured in an ESV file under the references section: references hover _ : $Strategy For example: references hover _ : editor-hover The identifier after the colon refers to the Stratego strategy that creates the hover tooltip. The Stratego strategy takes an AST node, and either fails if no tooltip should be produced, or returns a tooltip string. The string may contain a few simple HTML tag to style the output. The following tags are supported: <br/> \u2014 line break <b>text</b> \u2014 bold <i>text</i> \u2014 italic <pre>code</pre> \u2014 preformatted (code) text Unrecognized HTML tags are stripped from the hover tooltip. Escape angled brackets and ampersands to show them verbatim in the tooltip.","title":"Hover Tooltips"},{"location":"references/editor-services/hover/#hover-tooltips","text":"Hover tooltips show a textual tooltip with extra information, when hovering part of the text. Hover tooltips are created by a Stratego strategy, but are configured in an ESV file under the references section: references hover _ : $Strategy For example: references hover _ : editor-hover The identifier after the colon refers to the Stratego strategy that creates the hover tooltip. The Stratego strategy takes an AST node, and either fails if no tooltip should be produced, or returns a tooltip string. The string may contain a few simple HTML tag to style the output. The following tags are supported: <br/> \u2014 line break <b>text</b> \u2014 bold <i>text</i> \u2014 italic <pre>code</pre> \u2014 preformatted (code) text Unrecognized HTML tags are stripped from the hover tooltip. Escape angled brackets and ampersands to show them verbatim in the tooltip.","title":"Hover Tooltips"},{"location":"references/editor-services/menus/","text":"Action Menus \u00b6 Menus are used to bind actions of your language, such as transformations, to a menu in the IDE. Menus are defined using the menu keyword under a menus section in an ESV file , and can themselves contain submenus, actions, and separators. menu : $String $MenuOptions $MenuContribs Menu Contributions \u00b6 A menu has zero or more $MenuContrib , which are: action , submenu , or separator . Actions \u00b6 Actions (sometimes called builders ) are defined under a menu or submenu with syntax: action : $String = $StrategoCall $MenuOptions Submenus \u00b6 Submenus allow grouping of actions in nested menus. Their syntax is: sub menu : $String $MenuOptions $MenuContribs end Separators \u00b6 Separators allow inserting a separator in a menu list using the syntax: separator Menu Options \u00b6 The menu options specify the behavior of the menu item. The following modifiers are supported: Modifier Description (source) Action is performed on the parsed AST instead of the default analyzed AST. (openeditor) The result should be opened in a new editor. (realtime) (meta) Example \u00b6 An example menu: menus menu : \"Generate\" action : \"To normal form\" = to-normal-form ( source ) sub menu : \"To Java\" action : \"Abstract\" = to-java-abstract ( openeditor ) action : \"Concrete\" = to-java-concrete end","title":"Action Menus"},{"location":"references/editor-services/menus/#action-menus","text":"Menus are used to bind actions of your language, such as transformations, to a menu in the IDE. Menus are defined using the menu keyword under a menus section in an ESV file , and can themselves contain submenus, actions, and separators. menu : $String $MenuOptions $MenuContribs","title":"Action Menus"},{"location":"references/editor-services/menus/#menu-contributions","text":"A menu has zero or more $MenuContrib , which are: action , submenu , or separator .","title":"Menu Contributions"},{"location":"references/editor-services/menus/#actions","text":"Actions (sometimes called builders ) are defined under a menu or submenu with syntax: action : $String = $StrategoCall $MenuOptions","title":"Actions"},{"location":"references/editor-services/menus/#submenus","text":"Submenus allow grouping of actions in nested menus. Their syntax is: sub menu : $String $MenuOptions $MenuContribs end","title":"Submenus"},{"location":"references/editor-services/menus/#separators","text":"Separators allow inserting a separator in a menu list using the syntax: separator","title":"Separators"},{"location":"references/editor-services/menus/#menu-options","text":"The menu options specify the behavior of the menu item. The following modifiers are supported: Modifier Description (source) Action is performed on the parsed AST instead of the default analyzed AST. (openeditor) The result should be opened in a new editor. (realtime) (meta)","title":"Menu Options"},{"location":"references/editor-services/menus/#example","text":"An example menu: menus menu : \"Generate\" action : \"To normal form\" = to-normal-form ( source ) sub menu : \"To Java\" action : \"Abstract\" = to-java-abstract ( openeditor ) action : \"Concrete\" = to-java-concrete end","title":"Example"},{"location":"references/editor-services/on-save/","text":"On-Save Handlers \u00b6 The on-save handler (also known as the compiler strategy) is used to transform files when they are saved in an editor. In an IDE, when a new project is opened, the compiler strategy is also executed on each file in the project, as well as when files change in the background. In a command-line batch compiler setting, it is used to transform all files. The compiler strategy is configured in an ESV file with the on save key: language on save : $Strategy The identifier after the colon refers to the Stratego strategy that performs the transformation. This strategy must have the exact same signature as the one for actions . For example: language on save : compile-file","title":"On-Save Handlers"},{"location":"references/editor-services/on-save/#on-save-handlers","text":"The on-save handler (also known as the compiler strategy) is used to transform files when they are saved in an editor. In an IDE, when a new project is opened, the compiler strategy is also executed on each file in the project, as well as when files change in the background. In a command-line batch compiler setting, it is used to transform all files. The compiler strategy is configured in an ESV file with the on save key: language on save : $Strategy The identifier after the colon refers to the Stratego strategy that performs the transformation. This strategy must have the exact same signature as the one for actions . For example: language on save : compile-file","title":"On-Save Handlers"},{"location":"references/editor-services/outline/","text":"Outline View \u00b6 An outline is a summary of the structure of a file, shown in a separate view next to a textual editor. An outline is created by a Stratego strategy, but is configured in an ESV file under the views section: views outline view : $Strategy expand to level : $Int The Stratego strategy specified as $Strategy must have the following signature: signature constructors Node : Label * Children - > Node rules editor-outline : ( node , position , ast , path , project-path ) - > outline Where the input is the default tuple used for builders , and the result is a list of Node terms, each carrying a label and a (possibly empty) list of child nodes. Preserve origins on the node's label to allow navigating to the corresponding code from the outline. For example: views outline view : editor-outline expand to level : 3 This configures the editor-outline Stratego strategy to be used to create outlines, and that outline nodes should be expanded 3 levels deep by default.","title":"Outline View"},{"location":"references/editor-services/outline/#outline-view","text":"An outline is a summary of the structure of a file, shown in a separate view next to a textual editor. An outline is created by a Stratego strategy, but is configured in an ESV file under the views section: views outline view : $Strategy expand to level : $Int The Stratego strategy specified as $Strategy must have the following signature: signature constructors Node : Label * Children - > Node rules editor-outline : ( node , position , ast , path , project-path ) - > outline Where the input is the default tuple used for builders , and the result is a list of Node terms, each carrying a label and a (possibly empty) list of child nodes. Preserve origins on the node's label to allow navigating to the corresponding code from the outline. For example: views outline view : editor-outline expand to level : 3 This configures the editor-outline Stratego strategy to be used to create outlines, and that outline nodes should be expanded 3 levels deep by default.","title":"Outline View"},{"location":"references/editor-services/parsing/","text":"Parsing \u00b6 Parsing language files in an editor is configured in the language section of an ESV file . The syntax is as follows: language table : $Path start symbols : $Sorts line comment : $String block comment : $String * $String fences : $Fences For example: language table : target/metaborg/sdf . tbl start symbols : File line comment : \"//\" block comment : \"/*\" * \"*/\" fences : [ ] ( ) { } Parse Table \u00b6 The parse table of your language is set with the table key. By default, the parse table of an SDF specification is always produced at target/metaborg/sdf.tbl . It is only necessary to change this configuration when a custom parse table is used. Start Symbols \u00b6 The start symbols key determine which start symbols to use when an editor is opened. This must be a subset of the start symbols defined in the SDF3 specification of your language. Multiple start symbols can be set with a comma-separated list: language start symbols : Start , Program Comments \u00b6 The syntax for comments is: language line comment : $String block comment : $String * $String For example, Java comments are specified as: language line comment : \"//\" block comment : \"/*\" * \"*/\" The line comment key determines how single-line comments are created. It is used by editors to toggle the comment for a single line. For example, in Eclipse, pressing Ctrl + / ( Cmd + / on macOS), respectively comments or uncomments the line. The block comment key determines how multi-line comments are created. It is used when a whole block needs to be commented or uncommented. A block comment is described by the two strings denoting the start and end symbols of the block comment respectively. Fences \u00b6 Fences for bracket matching are set as follows: language fences : $Fences The fences key determines which symbols to use and match for bracket matching. A single fence is defined by a starting and closing symbol. Multiple fences can be set with a space-separated list. Fences are used to do bracket matching in text editors. For example, the default fences in a new Spoofax language project are: language fences : [ ] ( ) { } Multi-Character Fences Fences can contain multiple characters, but some implementations may not handle bracket matching with multiple fence characters. For example, Eclipse does not handle this case and ignores multi-character fences.","title":"Parsing"},{"location":"references/editor-services/parsing/#parsing","text":"Parsing language files in an editor is configured in the language section of an ESV file . The syntax is as follows: language table : $Path start symbols : $Sorts line comment : $String block comment : $String * $String fences : $Fences For example: language table : target/metaborg/sdf . tbl start symbols : File line comment : \"//\" block comment : \"/*\" * \"*/\" fences : [ ] ( ) { }","title":"Parsing"},{"location":"references/editor-services/parsing/#parse-table","text":"The parse table of your language is set with the table key. By default, the parse table of an SDF specification is always produced at target/metaborg/sdf.tbl . It is only necessary to change this configuration when a custom parse table is used.","title":"Parse Table"},{"location":"references/editor-services/parsing/#start-symbols","text":"The start symbols key determine which start symbols to use when an editor is opened. This must be a subset of the start symbols defined in the SDF3 specification of your language. Multiple start symbols can be set with a comma-separated list: language start symbols : Start , Program","title":"Start Symbols"},{"location":"references/editor-services/parsing/#comments","text":"The syntax for comments is: language line comment : $String block comment : $String * $String For example, Java comments are specified as: language line comment : \"//\" block comment : \"/*\" * \"*/\" The line comment key determines how single-line comments are created. It is used by editors to toggle the comment for a single line. For example, in Eclipse, pressing Ctrl + / ( Cmd + / on macOS), respectively comments or uncomments the line. The block comment key determines how multi-line comments are created. It is used when a whole block needs to be commented or uncommented. A block comment is described by the two strings denoting the start and end symbols of the block comment respectively.","title":"Comments"},{"location":"references/editor-services/parsing/#fences","text":"Fences for bracket matching are set as follows: language fences : $Fences The fences key determines which symbols to use and match for bracket matching. A single fence is defined by a starting and closing symbol. Multiple fences can be set with a space-separated list. Fences are used to do bracket matching in text editors. For example, the default fences in a new Spoofax language project are: language fences : [ ] ( ) { } Multi-Character Fences Fences can contain multiple characters, but some implementations may not handle bracket matching with multiple fence characters. For example, Eclipse does not handle this case and ignores multi-character fences.","title":"Fences"},{"location":"references/editor-services/reference-resolution/","text":"Reference Resolution \u00b6 Reference resolution takes an AST node containing a reference, and tries to resolve it to its definition. The resolution is performed by a Stratego strategy, but is configured in an ESV file under the references section: references reference _ : $Strategy The identifier after the colon refers to the Stratego strategy that performs the resolution. The Stratego strategy takes an AST node, and either fails if it could not be resolved, or returns an AST node that has an origin location pointing to the definition site. For example: references reference _ : editor-resolve","title":"Reference Resolution"},{"location":"references/editor-services/reference-resolution/#reference-resolution","text":"Reference resolution takes an AST node containing a reference, and tries to resolve it to its definition. The resolution is performed by a Stratego strategy, but is configured in an ESV file under the references section: references reference _ : $Strategy The identifier after the colon refers to the Stratego strategy that performs the resolution. The Stratego strategy takes an AST node, and either fails if it could not be resolved, or returns an AST node that has an origin location pointing to the definition site. For example: references reference _ : editor-resolve","title":"Reference Resolution"},{"location":"references/editor-services/renaming/","text":"Rename Refactoring \u00b6 Spoofax provides an automated rename refactoring as an editor service for every language developed with it that has the static semantics defined with Statix or NaBL2. Strategy \u00b6 Rename refactoring is enabled by default for new Spoofax language projects. This works by registering the rename-action strategy from the statixruntime library as an action in a menu. This strategy takes three parameters: a layout-preserving pretty-printing strategy ( construct-textual-change by default), the editor analyze strategy ( editor-analyze by default), and a strategy that should succeed when renaming in multi-file mode. The default rename refactoring strategy looks like this: rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , fail ) To enable multi-file mode, change the last argument to id : rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id ) Statix \u00b6 For the renaming to work correctly in all cases when using Statix, terms that represent a declaration of a program entity, such as a function or a variable, need to set the @decl property on the name of the entity. For example, when declaring a type: declareType ( scope , name , T ) : - scope -> Type { name } with typeOfDecl T , @ name . decl := name , typeOfDecl of Type { name } in scope |-> [ ( _ , ( _ , T )) ] . See Also \u00b6 How-To: Add Rename Refactoring to an Existing Project","title":"Rename Refactoring"},{"location":"references/editor-services/renaming/#rename-refactoring","text":"Spoofax provides an automated rename refactoring as an editor service for every language developed with it that has the static semantics defined with Statix or NaBL2.","title":"Rename Refactoring"},{"location":"references/editor-services/renaming/#strategy","text":"Rename refactoring is enabled by default for new Spoofax language projects. This works by registering the rename-action strategy from the statixruntime library as an action in a menu. This strategy takes three parameters: a layout-preserving pretty-printing strategy ( construct-textual-change by default), the editor analyze strategy ( editor-analyze by default), and a strategy that should succeed when renaming in multi-file mode. The default rename refactoring strategy looks like this: rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , fail ) To enable multi-file mode, change the last argument to id : rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id )","title":"Strategy"},{"location":"references/editor-services/renaming/#statix","text":"For the renaming to work correctly in all cases when using Statix, terms that represent a declaration of a program entity, such as a function or a variable, need to set the @decl property on the name of the entity. For example, when declaring a type: declareType ( scope , name , T ) : - scope -> Type { name } with typeOfDecl T , @ name . decl := name , typeOfDecl of Type { name } in scope |-> [ ( _ , ( _ , T )) ] .","title":"Statix"},{"location":"references/editor-services/renaming/#see-also","text":"How-To: Add Rename Refactoring to an Existing Project","title":"See Also"},{"location":"references/editor-services/stratego/","text":"Stratego \u00b6 The Java JAR and CTree files that will be loaded into the Stratego runtime for your language can be configured with the provider key in an ESV file : language provider : $Path The path is a path to a .jar or .ctree file, relative to the root of the project. For example: language provider : target/metaborg/stratego . ctree The extension of the provider should match the format in the metaborg.yaml file of your language. Multiple files can be set by setting the key multiple times: ``esv language provider : target/metaborg/stratego.ctree provider : target/custom1.jar provider : target/custom2.ctree ```","title":"Stratego"},{"location":"references/editor-services/stratego/#stratego","text":"The Java JAR and CTree files that will be loaded into the Stratego runtime for your language can be configured with the provider key in an ESV file : language provider : $Path The path is a path to a .jar or .ctree file, relative to the root of the project. For example: language provider : target/metaborg/stratego . ctree The extension of the provider should match the format in the metaborg.yaml file of your language. Multiple files can be set by setting the key multiple times: ``esv language provider : target/metaborg/stratego.ctree provider : target/custom1.jar provider : target/custom2.ctree ```","title":"Stratego"},{"location":"references/editor-services/syntax-highlighting/","text":"Syntax Highlighting \u00b6 Token-based syntax highlighting is configured in a colorer section of an ESV file . Such a section can contain style definitions and styling rules. Style Definitions \u00b6 Style definitions bind an identifier to a style for later reuse, using the syntax: $ID = $Style Styles \u00b6 A style specifies a combination of a foreground color, optional background color, and optional font style. Colors are specified as Red-Green-Blue values ranging from 0 (none) to 255 (full). The possible font attributes are: Font attribute Description (none) Normal font. bold Bold font. italic Italic font. bold italic Bond and italic font. italic bold Same as bold italic . For example, the following style definitions bind the red , green , and blue colors: colorer red = 255 0 0 green = 0 255 0 blue = 0 0 255 An optional background color can be set by adding another RGB value: colorer redWithGreenBackground = 255 0 0 0 255 0 The font attributes can be used to make the font bold or italic: colorer redWithBold = 255 0 0 bold redWithItalic = 255 0 0 italic redWithGreenBackgroundWithBoldItalic = 255 0 0 0 255 0 bold italic Style Rules \u00b6 Style rules assign a style to matched tokens with syntax: $Matcher : $Style Or assigns a previously defined style definition: $Matcher : $Ref The left hand side of style rules matches a token, whereas the right hand side assigns a style by referring to a previously defined style definition, or by directly assigning a style. For example, the following matches a token type and references a style definition: colorer operator : black whereas the following matches a token with a sort and constructor, and directly assigns a style: colorer ClassBodyDec . MethodDec : 0 255 0 Matchers \u00b6 There are several ways in which the matcher on the left-hand side of a style rule can be specified: by type, by sort, by constructor, or by sort and constructor. Match by Sort and Constructor \u00b6 The combination of a token sort and constructor can be matched by specifying the $Sort.$Constructor . For example: colorer ClassBodyDec.MethodDec : yellow ClassBodyDec.FieldDec : red Match by Constructor \u00b6 It is also possible to match constructors, regardless of their token sorts, using _ in place of the sort name. For example: colorer _ . Str : blue _ . StrCong : blue _ . QStr : blue _ . QDollar : blue _ . QBr : gray Match by Sort \u00b6 Additionally, it is possible to match any constructor for a specific sort. For this, just specify the name of the sort, $Sort . For example: colorer ID : darkblue TYPEID : blue JQTYPEID : blue PQTYPEID : blue FUNCID : 153 51 0 JFUNCID : 153 51 0 STRING : 177 47 2 Match by Type \u00b6 Finally, the following built-in token types can be matched on: identifier \u2014 matches identifiers, found by lexical non-terminals without numbers; keyword \u2014 matches keywords, found by terminals in the syntax definition; layout \u2014 matches layout, such as whitespace and comments, found by layout definition; number \u2014 matches numbers, found by lexical non-terminals with numbers; operator \u2014 matches operations, found by terminals that contain just symbols (no characters); string \u2014 matches strings, found by lexical non-terminals that include quotation marks; unknown \u2014 matches tokens which the parser was unable to infer a type for. var error For example, the following code defines a simple highlighting with token types: colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic","title":"Syntax Highlighting"},{"location":"references/editor-services/syntax-highlighting/#syntax-highlighting","text":"Token-based syntax highlighting is configured in a colorer section of an ESV file . Such a section can contain style definitions and styling rules.","title":"Syntax Highlighting"},{"location":"references/editor-services/syntax-highlighting/#style-definitions","text":"Style definitions bind an identifier to a style for later reuse, using the syntax: $ID = $Style","title":"Style Definitions"},{"location":"references/editor-services/syntax-highlighting/#styles","text":"A style specifies a combination of a foreground color, optional background color, and optional font style. Colors are specified as Red-Green-Blue values ranging from 0 (none) to 255 (full). The possible font attributes are: Font attribute Description (none) Normal font. bold Bold font. italic Italic font. bold italic Bond and italic font. italic bold Same as bold italic . For example, the following style definitions bind the red , green , and blue colors: colorer red = 255 0 0 green = 0 255 0 blue = 0 0 255 An optional background color can be set by adding another RGB value: colorer redWithGreenBackground = 255 0 0 0 255 0 The font attributes can be used to make the font bold or italic: colorer redWithBold = 255 0 0 bold redWithItalic = 255 0 0 italic redWithGreenBackgroundWithBoldItalic = 255 0 0 0 255 0 bold italic","title":"Styles"},{"location":"references/editor-services/syntax-highlighting/#style-rules","text":"Style rules assign a style to matched tokens with syntax: $Matcher : $Style Or assigns a previously defined style definition: $Matcher : $Ref The left hand side of style rules matches a token, whereas the right hand side assigns a style by referring to a previously defined style definition, or by directly assigning a style. For example, the following matches a token type and references a style definition: colorer operator : black whereas the following matches a token with a sort and constructor, and directly assigns a style: colorer ClassBodyDec . MethodDec : 0 255 0","title":"Style Rules"},{"location":"references/editor-services/syntax-highlighting/#matchers","text":"There are several ways in which the matcher on the left-hand side of a style rule can be specified: by type, by sort, by constructor, or by sort and constructor.","title":"Matchers"},{"location":"references/editor-services/syntax-highlighting/#match-by-sort-and-constructor","text":"The combination of a token sort and constructor can be matched by specifying the $Sort.$Constructor . For example: colorer ClassBodyDec.MethodDec : yellow ClassBodyDec.FieldDec : red","title":"Match by Sort and Constructor"},{"location":"references/editor-services/syntax-highlighting/#match-by-constructor","text":"It is also possible to match constructors, regardless of their token sorts, using _ in place of the sort name. For example: colorer _ . Str : blue _ . StrCong : blue _ . QStr : blue _ . QDollar : blue _ . QBr : gray","title":"Match by Constructor"},{"location":"references/editor-services/syntax-highlighting/#match-by-sort","text":"Additionally, it is possible to match any constructor for a specific sort. For this, just specify the name of the sort, $Sort . For example: colorer ID : darkblue TYPEID : blue JQTYPEID : blue PQTYPEID : blue FUNCID : 153 51 0 JFUNCID : 153 51 0 STRING : 177 47 2","title":"Match by Sort"},{"location":"references/editor-services/syntax-highlighting/#match-by-type","text":"Finally, the following built-in token types can be matched on: identifier \u2014 matches identifiers, found by lexical non-terminals without numbers; keyword \u2014 matches keywords, found by terminals in the syntax definition; layout \u2014 matches layout, such as whitespace and comments, found by layout definition; number \u2014 matches numbers, found by lexical non-terminals with numbers; operator \u2014 matches operations, found by terminals that contain just symbols (no characters); string \u2014 matches strings, found by lexical non-terminals that include quotation marks; unknown \u2014 matches tokens which the parser was unable to infer a type for. var error For example, the following code defines a simple highlighting with token types: colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic","title":"Match by Type"},{"location":"references/flowspec/Stratego_API/","text":"Stratego API \u00b6 Strategies for interfacing with FlowSpec from Stratego. Execution, configuration, extracting results. Setup \u00b6 Execution \u00b6 Querying \u00b6","title":"Stratego API"},{"location":"references/flowspec/Stratego_API/#stratego-api","text":"Strategies for interfacing with FlowSpec from Stratego. Execution, configuration, extracting results.","title":"Stratego API"},{"location":"references/flowspec/Stratego_API/#setup","text":"","title":"Setup"},{"location":"references/flowspec/Stratego_API/#execution","text":"","title":"Execution"},{"location":"references/flowspec/Stratego_API/#querying","text":"","title":"Querying"},{"location":"references/flowspec/glossary/","text":"Glossary \u00b6","title":"Glossary"},{"location":"references/flowspec/glossary/#glossary","text":"","title":"Glossary"},{"location":"references/flowspec/introduction/","text":"Introduction \u00b6","title":"Introduction"},{"location":"references/flowspec/introduction/#introduction","text":"","title":"Introduction"},{"location":"references/flowspec/references/","text":"References \u00b6","title":"References"},{"location":"references/flowspec/references/#references","text":"","title":"References"},{"location":"references/flowspec/structure/","text":"Structure \u00b6 Modules \u00b6 A module is defined by a single flowspec file. A module can contain several sections, for defining control flow, data flow, types, and functions. Modules can import other modules. module _module-id_ imports _module-ref*_ _section*_ Control Flow \u00b6 The control flow section contains the rules that define the control flow for the sorts in the subject grammar. control-flow rules control-flow-rule* Control Flow Rules \u00b6 pattern* = {cfg-edges \",\"}+ cfg-edges = {cfg-edge-end \"->\"}+ cfg-edge-end = \"entry\" | \"exit\" | variable | \"node\" variable | \"this\" Example. module control control-flow rules node Int(_) Add(l, r) = entry -> l -> r -> this -> exit Root Rules \u00b6 Data Flow \u00b6 Properties \u00b6 Rules \u00b6 Lattices \u00b6 Types \u00b6 Expressions \u00b6 Literals \u00b6 Sets and Maps \u00b6 Literals Union, Diff, Contains, Intersect Comprehension Match \u00b6 Variables and References \u00b6 Functions \u00b6 Property Lookup \u00b6 Term Positions \u00b6 Lattices \u00b6 Lattice operations Functions \u00b6 Lexical Grammar \u00b6","title":"Structure"},{"location":"references/flowspec/structure/#structure","text":"","title":"Structure"},{"location":"references/flowspec/structure/#modules","text":"A module is defined by a single flowspec file. A module can contain several sections, for defining control flow, data flow, types, and functions. Modules can import other modules. module _module-id_ imports _module-ref*_ _section*_","title":"Modules"},{"location":"references/flowspec/structure/#control-flow","text":"The control flow section contains the rules that define the control flow for the sorts in the subject grammar. control-flow rules control-flow-rule*","title":"Control Flow"},{"location":"references/flowspec/structure/#control-flow-rules","text":"pattern* = {cfg-edges \",\"}+ cfg-edges = {cfg-edge-end \"->\"}+ cfg-edge-end = \"entry\" | \"exit\" | variable | \"node\" variable | \"this\" Example. module control control-flow rules node Int(_) Add(l, r) = entry -> l -> r -> this -> exit","title":"Control Flow Rules"},{"location":"references/flowspec/structure/#root-rules","text":"","title":"Root Rules"},{"location":"references/flowspec/structure/#data-flow","text":"","title":"Data Flow"},{"location":"references/flowspec/structure/#properties","text":"","title":"Properties"},{"location":"references/flowspec/structure/#rules","text":"","title":"Rules"},{"location":"references/flowspec/structure/#lattices","text":"","title":"Lattices"},{"location":"references/flowspec/structure/#types","text":"","title":"Types"},{"location":"references/flowspec/structure/#expressions","text":"","title":"Expressions"},{"location":"references/flowspec/structure/#literals","text":"","title":"Literals"},{"location":"references/flowspec/structure/#sets-and-maps","text":"Literals Union, Diff, Contains, Intersect Comprehension","title":"Sets and Maps"},{"location":"references/flowspec/structure/#match","text":"","title":"Match"},{"location":"references/flowspec/structure/#variables-and-references","text":"","title":"Variables and References"},{"location":"references/flowspec/structure/#functions","text":"","title":"Functions"},{"location":"references/flowspec/structure/#property-lookup","text":"","title":"Property Lookup"},{"location":"references/flowspec/structure/#term-positions","text":"","title":"Term Positions"},{"location":"references/flowspec/structure/#lattices_1","text":"Lattice operations","title":"Lattices"},{"location":"references/flowspec/structure/#functions_1","text":"","title":"Functions"},{"location":"references/flowspec/structure/#lexical-grammar","text":"","title":"Lexical Grammar"},{"location":"references/flowspec/testing/","text":"Testing \u00b6","title":"Testing"},{"location":"references/flowspec/testing/#testing","text":"","title":"Testing"},{"location":"references/pipelines/","text":"Pipelines for Interactive Environments \u00b6 Pipelines for interactive Environments (PIE) is the build system for Spoofax 3. PIE consists of two parts: a Java framework, a Java runtime and the PIE Domain Specific Language (DSL). This reference documentation is for the PIE DSL and will only provide some high level information about the framework and runtime to provide context. PIE uses tasks to compose pipelines. Each task has 0 or more inputs and one output. Each task can depend on files or on other tasks. Tasks can be marked as explicitly observed to indicate that we want the output of these tasks to stay up to date. The PIE runtime executes tasks incrementally, which means that it only executes tasks that are no longer up to date and that are required for a task which is explicitly observed. Tasks can be written in Java, but this involves a lot of boilerplate. Tasks can also be written in the PIE DSL. The PIE DSL is specifically made for PIE, so it has little boilerplate. Tasks written in the PIE DSL are compiled to Java. The PIE DSL \u00b6 PIE models a pipeline as tasks that call each other. The PIE DSL calls these tasks \"functions\", because each task has inputs and an output. A PIE DSL program consists of one or more files. File structure \u00b6 module fully:qualified:moduleName import fully:qualified:name:of:another:module import org:example:multipleDefs:{func1, func2 as other, aDataTypeAsWell} import org:example:languages:{java, cpp, sql}:spoofax:{parse, analyze, compile} data coolDataType = foreign java org.example.MyFirstJavaClass { func aMethod(int) -> bool } func greetWorld() -> string = \"Hello world!\" PIE DSL files contain a module statement, imports, and data and function definitions. The module statement declares the fully qualified name of the module. Imports are optional and import datatypes and function from other modules. They can import multiple functions or datatypes at the same time, and they can rename elements. Data and function definitions define functions and datatypes. Directory structure and module system \u00b6 PIE files have the extension .pie . Each PIE file forms a module. Modules can define functions and datatypes, and can import functions and datatypes from other modules. It is recommended to use the same name for the module as the path and filename, but this is not required. As such, the PIE DSL does not place any restrictions on paths and file names besides the standard restrictions for Spoofax languages. The module system is described in Modules . Types and data definitions \u00b6 The PIE DSL is a statically typed language. There are a few built-in types, such as int and path . Built-in types use lowercase characters. Custom datatypes can currently only be imported from Java as foreign definitions. The types in the PIE DSL are described in Types . The PIE DSL also supports generic datatypes. These follow Java semantics. The semantics of generics can be found in Generics . Function definitions \u00b6 Functions express task definitions. Functions consist of a head and an implementation. func $FuncHead = $FuncImpl func greet(name: string) -> string = \"Hello ${name}!\" func doSomethingDifficult() -> path = foreign org.example.DoSomethingDifficult func callJavaStaticFunction() -> bool = foreign java fully.qualified.java.ClassName#staticMethodName func createCustomType() -> CustomType = foreign java constructor org.example.CustomType The function head describes the signature of the function: the name, the input parameter types and the output type. All functions can be called the same way regardless of their implementation. The function implementation describes the way a function is implemented. A function can be implemented in PIE by providing an expression, as can be seen with greet Expressions are described in Expressions . A function can also be implemented in Java. The three ways this can be done are shown in the example as well. A complete overview of functions is given in Functions . Misc information. \u00b6 Java and C use the function called main with a certain signature as the entry point to the program. A PIE program does not have a set entry point. The entry point is whatever function is called from the PIE runtime.","title":"Pipelines for Interactive Environments"},{"location":"references/pipelines/#pipelines-for-interactive-environments","text":"Pipelines for interactive Environments (PIE) is the build system for Spoofax 3. PIE consists of two parts: a Java framework, a Java runtime and the PIE Domain Specific Language (DSL). This reference documentation is for the PIE DSL and will only provide some high level information about the framework and runtime to provide context. PIE uses tasks to compose pipelines. Each task has 0 or more inputs and one output. Each task can depend on files or on other tasks. Tasks can be marked as explicitly observed to indicate that we want the output of these tasks to stay up to date. The PIE runtime executes tasks incrementally, which means that it only executes tasks that are no longer up to date and that are required for a task which is explicitly observed. Tasks can be written in Java, but this involves a lot of boilerplate. Tasks can also be written in the PIE DSL. The PIE DSL is specifically made for PIE, so it has little boilerplate. Tasks written in the PIE DSL are compiled to Java.","title":"Pipelines for Interactive Environments"},{"location":"references/pipelines/#the-pie-dsl","text":"PIE models a pipeline as tasks that call each other. The PIE DSL calls these tasks \"functions\", because each task has inputs and an output. A PIE DSL program consists of one or more files.","title":"The PIE DSL"},{"location":"references/pipelines/#file-structure","text":"module fully:qualified:moduleName import fully:qualified:name:of:another:module import org:example:multipleDefs:{func1, func2 as other, aDataTypeAsWell} import org:example:languages:{java, cpp, sql}:spoofax:{parse, analyze, compile} data coolDataType = foreign java org.example.MyFirstJavaClass { func aMethod(int) -> bool } func greetWorld() -> string = \"Hello world!\" PIE DSL files contain a module statement, imports, and data and function definitions. The module statement declares the fully qualified name of the module. Imports are optional and import datatypes and function from other modules. They can import multiple functions or datatypes at the same time, and they can rename elements. Data and function definitions define functions and datatypes.","title":"File structure"},{"location":"references/pipelines/#directory-structure-and-module-system","text":"PIE files have the extension .pie . Each PIE file forms a module. Modules can define functions and datatypes, and can import functions and datatypes from other modules. It is recommended to use the same name for the module as the path and filename, but this is not required. As such, the PIE DSL does not place any restrictions on paths and file names besides the standard restrictions for Spoofax languages. The module system is described in Modules .","title":"Directory structure and module system"},{"location":"references/pipelines/#types-and-data-definitions","text":"The PIE DSL is a statically typed language. There are a few built-in types, such as int and path . Built-in types use lowercase characters. Custom datatypes can currently only be imported from Java as foreign definitions. The types in the PIE DSL are described in Types . The PIE DSL also supports generic datatypes. These follow Java semantics. The semantics of generics can be found in Generics .","title":"Types and data definitions"},{"location":"references/pipelines/#function-definitions","text":"Functions express task definitions. Functions consist of a head and an implementation. func $FuncHead = $FuncImpl func greet(name: string) -> string = \"Hello ${name}!\" func doSomethingDifficult() -> path = foreign org.example.DoSomethingDifficult func callJavaStaticFunction() -> bool = foreign java fully.qualified.java.ClassName#staticMethodName func createCustomType() -> CustomType = foreign java constructor org.example.CustomType The function head describes the signature of the function: the name, the input parameter types and the output type. All functions can be called the same way regardless of their implementation. The function implementation describes the way a function is implemented. A function can be implemented in PIE by providing an expression, as can be seen with greet Expressions are described in Expressions . A function can also be implemented in Java. The three ways this can be done are shown in the example as well. A complete overview of functions is given in Functions .","title":"Function definitions"},{"location":"references/pipelines/#misc-information","text":"Java and C use the function called main with a certain signature as the entry point to the program. A PIE program does not have a set entry point. The entry point is whatever function is called from the PIE runtime.","title":"Misc information."},{"location":"references/pipelines/expressions/","text":"Expressions \u00b6 This section describes expressions in the PIE DSL. Todo Write documentation","title":"Expressions"},{"location":"references/pipelines/expressions/#expressions","text":"This section describes expressions in the PIE DSL. Todo Write documentation","title":"Expressions"},{"location":"references/pipelines/functions/","text":"Functions \u00b6 This section describes functions in the PIE DSL. Note A task is a function with some special semantics in regards to runtime behavior. The PIE DSL does not differentiate between functions and tasks. In the DSL, both are called functions. Todo Write documentation","title":"Functions"},{"location":"references/pipelines/functions/#functions","text":"This section describes functions in the PIE DSL. Note A task is a function with some special semantics in regards to runtime behavior. The PIE DSL does not differentiate between functions and tasks. In the DSL, both are called functions. Todo Write documentation","title":"Functions"},{"location":"references/pipelines/generics/","text":"Generics \u00b6 This section describes generics in the PIE DSL. In a nutshell, it just follows the Java semantics. Todo Write documentation","title":"Generics"},{"location":"references/pipelines/generics/#generics","text":"This section describes generics in the PIE DSL. In a nutshell, it just follows the Java semantics. Todo Write documentation","title":"Generics"},{"location":"references/pipelines/modules/","text":"Module system \u00b6 This section describes the module system of the PIE DSL. Todo document the module system","title":"Module system"},{"location":"references/pipelines/modules/#module-system","text":"This section describes the module system of the PIE DSL. Todo document the module system","title":"Module system"},{"location":"references/pipelines/types/","text":"Types \u00b6 There are several built-in types in the PIE DSL. The PIE DSL also allows defining custom types. Todo write about the types in PIE The type system \u00b6 Built-in types \u00b6 unit \u00b6 bool \u00b6 int \u00b6 string \u00b6 path \u00b6 null \u00b6 top \u00b6 bottom \u00b6 Nullable types \u00b6 Lists \u00b6 (todo: also discuss empty lists) Tuples \u00b6 Suppliers \u00b6 Function types \u00b6 Datatypes \u00b6 Wildcards \u00b6 Custom datatypes \u00b6","title":"Types"},{"location":"references/pipelines/types/#types","text":"There are several built-in types in the PIE DSL. The PIE DSL also allows defining custom types. Todo write about the types in PIE","title":"Types"},{"location":"references/pipelines/types/#the-type-system","text":"","title":"The type system"},{"location":"references/pipelines/types/#built-in-types","text":"","title":"Built-in types"},{"location":"references/pipelines/types/#unit","text":"","title":"unit"},{"location":"references/pipelines/types/#bool","text":"","title":"bool"},{"location":"references/pipelines/types/#int","text":"","title":"int"},{"location":"references/pipelines/types/#string","text":"","title":"string"},{"location":"references/pipelines/types/#path","text":"","title":"path"},{"location":"references/pipelines/types/#null","text":"","title":"null"},{"location":"references/pipelines/types/#top","text":"","title":"top"},{"location":"references/pipelines/types/#bottom","text":"","title":"bottom"},{"location":"references/pipelines/types/#nullable-types","text":"","title":"Nullable types"},{"location":"references/pipelines/types/#lists","text":"(todo: also discuss empty lists)","title":"Lists"},{"location":"references/pipelines/types/#tuples","text":"","title":"Tuples"},{"location":"references/pipelines/types/#suppliers","text":"","title":"Suppliers"},{"location":"references/pipelines/types/#function-types","text":"","title":"Function types"},{"location":"references/pipelines/types/#datatypes","text":"","title":"Datatypes"},{"location":"references/pipelines/types/#wildcards","text":"","title":"Wildcards"},{"location":"references/pipelines/types/#custom-datatypes","text":"","title":"Custom datatypes"},{"location":"references/statix/","text":"Statix \u00b6 Meta-language for Specification of Static Semantics.","title":"Statix"},{"location":"references/statix/#statix","text":"Meta-language for Specification of Static Semantics.","title":"Statix"},{"location":"references/statix/basic-constraints/","text":"Basic Constraints \u00b6 True \u00b6 False \u00b6 Conjunction \u00b6 Equality \u00b6 Disequality \u00b6 briefly describe disequality with free variables Exists \u00b6 Try \u00b6 AST Identifiers \u00b6 AST Property \u00b6 Arithmetic Constraints \u00b6","title":"Basic Constraints"},{"location":"references/statix/basic-constraints/#basic-constraints","text":"","title":"Basic Constraints"},{"location":"references/statix/basic-constraints/#true","text":"","title":"True"},{"location":"references/statix/basic-constraints/#false","text":"","title":"False"},{"location":"references/statix/basic-constraints/#conjunction","text":"","title":"Conjunction"},{"location":"references/statix/basic-constraints/#equality","text":"","title":"Equality"},{"location":"references/statix/basic-constraints/#disequality","text":"briefly describe disequality with free variables","title":"Disequality"},{"location":"references/statix/basic-constraints/#exists","text":"","title":"Exists"},{"location":"references/statix/basic-constraints/#try","text":"","title":"Try"},{"location":"references/statix/basic-constraints/#ast-identifiers","text":"","title":"AST Identifiers"},{"location":"references/statix/basic-constraints/#ast-property","text":"","title":"AST Property"},{"location":"references/statix/basic-constraints/#arithmetic-constraints","text":"","title":"Arithmetic Constraints"},{"location":"references/statix/concepts/","text":"Language Concepts \u00b6 In this section, a brief description of the main concepts of the Statix language is provided. Terms \u00b6 The data model that underlies all Statix specifications is algebraic data. Besides several built-in primitives, such as integer and string literals, users can build composite terms using term constructors, tuples and lists. Statix is a sorted logic, in the sense that all runtime data should adhere to a multi-sorted signature. Constraints \u00b6 Key to the Statix design philosophy is to view a type-checking problem as a constraint problem. When solving the constraint problem, a minimal model is inferred from the constraints. This model represents a principal typing for the original program. In order to express such constraint problems, a versatile set of built-in constraints is provided by the Statix language. For more information on constraints, see the Basic Constraints section. Rules \u00b6 Besides using built-in constraints, users can define their own constraints using constraint handling rules. Rules consist of a head and a body. The head specifies the arguments to the constraint, and (optionally) a guard, which indicates when to apply the rule. The body is a regular constraint, which, when proven, asserts that the constraint holds. More detailed information about user-defined constraints can be found in the Rules section. Scope Graphs \u00b6 Since Statix is especially designed for type-checking, and type-checking is heavily intertwined with name binding, special support for name binding is integrated in the language. Name binding is modelled using scope graphs , in which scopes are represented as nodes, visibility is modelled using labelled edges between nodes, and declarations using special terminal nodes that are associated with a particular datum. References are modelled using scope graph queries . For more information on scope graph construction and querying, see sections Scope Graph Constraints and Queries , respectively.","title":"Language Concepts"},{"location":"references/statix/concepts/#language-concepts","text":"In this section, a brief description of the main concepts of the Statix language is provided.","title":"Language Concepts"},{"location":"references/statix/concepts/#terms","text":"The data model that underlies all Statix specifications is algebraic data. Besides several built-in primitives, such as integer and string literals, users can build composite terms using term constructors, tuples and lists. Statix is a sorted logic, in the sense that all runtime data should adhere to a multi-sorted signature.","title":"Terms"},{"location":"references/statix/concepts/#constraints","text":"Key to the Statix design philosophy is to view a type-checking problem as a constraint problem. When solving the constraint problem, a minimal model is inferred from the constraints. This model represents a principal typing for the original program. In order to express such constraint problems, a versatile set of built-in constraints is provided by the Statix language. For more information on constraints, see the Basic Constraints section.","title":"Constraints"},{"location":"references/statix/concepts/#rules","text":"Besides using built-in constraints, users can define their own constraints using constraint handling rules. Rules consist of a head and a body. The head specifies the arguments to the constraint, and (optionally) a guard, which indicates when to apply the rule. The body is a regular constraint, which, when proven, asserts that the constraint holds. More detailed information about user-defined constraints can be found in the Rules section.","title":"Rules"},{"location":"references/statix/concepts/#scope-graphs","text":"Since Statix is especially designed for type-checking, and type-checking is heavily intertwined with name binding, special support for name binding is integrated in the language. Name binding is modelled using scope graphs , in which scopes are represented as nodes, visibility is modelled using labelled edges between nodes, and declarations using special terminal nodes that are associated with a particular datum. References are modelled using scope graph queries . For more information on scope graph construction and querying, see sections Scope Graph Constraints and Queries , respectively.","title":"Scope Graphs"},{"location":"references/statix/modules/","text":"Modules \u00b6 A Statix Specification is organised as a collection of modules. Each module corresponds to a file with a .stx extension. Module Structure \u00b6 The structure of a Statix module looks as follows: module $ ModuleName $ Section * Each module declares its name, and subsequently contains a number of sections. The module name should coincide with the relative path of the module with respect to the closest source root. Todo Link to documentation on source roots. Imports \u00b6 In an imports section, definitions from other modules can be brought in scope. imports $ ModuleName * Modules can only be imported with their fully qualified name. That is, for each $ModuleName in an imports section, a module with exactly the same name must exist. Imports of sorts, constructors and predicates are transitive, while imports of labels and relations are non-transitive. Furthermore, overloading by type, shadowing of top-level definitions, and duplicate imports of specification entities are not allowed. Signatures \u00b6 In a signature section, type definitions are located. signature $ Signature * Examples of signatures are: sort and constructor declarations or label and relation declarations. Each of these will be explained in the appropriate subsection. Rules \u00b6 In a rules section, the rules of a specification are defined. For more information on rules, see the Rules section. rules $ RuleDeclaration *","title":"Modules"},{"location":"references/statix/modules/#modules","text":"A Statix Specification is organised as a collection of modules. Each module corresponds to a file with a .stx extension.","title":"Modules"},{"location":"references/statix/modules/#module-structure","text":"The structure of a Statix module looks as follows: module $ ModuleName $ Section * Each module declares its name, and subsequently contains a number of sections. The module name should coincide with the relative path of the module with respect to the closest source root. Todo Link to documentation on source roots.","title":"Module Structure"},{"location":"references/statix/modules/#imports","text":"In an imports section, definitions from other modules can be brought in scope. imports $ ModuleName * Modules can only be imported with their fully qualified name. That is, for each $ModuleName in an imports section, a module with exactly the same name must exist. Imports of sorts, constructors and predicates are transitive, while imports of labels and relations are non-transitive. Furthermore, overloading by type, shadowing of top-level definitions, and duplicate imports of specification entities are not allowed.","title":"Imports"},{"location":"references/statix/modules/#signatures","text":"In a signature section, type definitions are located. signature $ Signature * Examples of signatures are: sort and constructor declarations or label and relation declarations. Each of these will be explained in the appropriate subsection.","title":"Signatures"},{"location":"references/statix/modules/#rules","text":"In a rules section, the rules of a specification are defined. For more information on rules, see the Rules section. rules $ RuleDeclaration *","title":"Rules"},{"location":"references/statix/queries/","text":"Queries \u00b6 Filters \u00b6 Shadowing \u00b6 Result pattern \u00b6","title":"Queries"},{"location":"references/statix/queries/#queries","text":"","title":"Queries"},{"location":"references/statix/queries/#filters","text":"","title":"Filters"},{"location":"references/statix/queries/#shadowing","text":"","title":"Shadowing"},{"location":"references/statix/queries/#result-pattern","text":"","title":"Result pattern"},{"location":"references/statix/rules/","text":"Rules \u00b6 User-defined constraints and their rules make up the main part of a Statix specification. In this section, we describe the definition and usage of user-defined constraints and their rules. Constraint Definitions \u00b6 In order to define a custom constraint, its type must be declared first. A constraint can be declared in a rules section, or in a constraints subsection of a signature section. A constraint is declared by specifying its name and argument type. For more information on types, please refer to the Types section. Note that the name of the constraint must be unique within a specification. $ ConstraintName : { $ Type \"*\" } * Note In this reference manual, we consistently use the term 'constraint declaration' for the introduction of new user-defined constraints. However, in practise, these are sometimes also referred to as 'predicate' or just simply 'constraint'. When a constraint declaration is provided this way, it can be used as a constraint by providing concrete arguments, separated by comma's. $ ConstraintName ({ $ Term \",\" } * ) The sorts of the argument terms should be equal to the sorts in the constraint declaration. Rule Definitions \u00b6 When solving a user-defined constraint, a rule for that constraint is unfolded in order to infer a model satisfying the constraint. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) : - $ Constraint . The part before the turnstile ( :- ) is often referred to as the head of the rule, while the $Constraint after the turnstile is denoted as body . When applying a rule, each head pattern (which is just a term) will be matched with its corresponding actual argument. Statically, the sorts of the terms in $Patterns are type-checked based on the constraint declaration. Any variables in patterns are implicitly introduced in the scope of the rule. Patterns can be non-linear. That is, a variable may occur multiple times in a pattern. Operationally, the subterms at these positions are then required to be structurally equal. Note that multiple rules for a single constraint can, and often will, be provided. For each constraint, the rule that is used for simplification is determined by the guard of the rule. This guard is derived from the head pattern: a rule can only be applied when the constraint arguments match the patterns. During constraint solving, Statix will try at most one rule for each constraint. The appropriate rule is selected by applying the following heuristics in order: 1. Rules with a smaller domain are preferred over rules with a larger domain. 2. When pairwise comparing rules, the rule for which, in left-to-right order, a more specific pattern is encountered first is preferred over the other. For all cases where these heuristics do not decide which rule to use for a constraint, compile time \"Overlapping patterns\" errors will be emitted. The $RuleName is just a name that can be used for documentation purposes. It cannot be referenced from any position in the specification, and may be omitted altogether. Axiom rules \u00b6 In some cases, a constraint trivially holds for particular inputs. For such constraints, an axiom rule can be specified. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ). This rule is similar to a regular rule, but lacks a body. When applying such a rule, no new constraints are introduced, reflecting the fact that the constraint trivially holds for these arguments. Functional Rules \u00b6 Some user-defined constraints can be thought of more naturally as a function: a constraint where a particular term is inferred by the constraint, rather than validated. Statix allows to write constraints in a functional idiom as follows: First, a constraint declaration for such 'functional constraints' must be provided as follows: $ ConstraintName : { $ Type \"*\" } * -> $ Type In addition to the regular list of input sorts, a sort for the output term is provided to the constraint declaration. Rule definitions for a functional constraint look as follows: [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) = $ Term : - $ Constraint . Compared to predicative rule definitions as introduced earlier in this section, an additional term after an equality-sign is appended to the rule head. This term denotes the output term (the term inferred by the rule). A functional constraint can be used in a term position, as opposed to a constraint position for predicative rules. Otherwise, their syntax is the same. $ ConstraintName ({ $ Term \",\" } * ) Semantically, the output term of applying the constraint is substituted at the position of the application of the functional predicate. Note When we want to make the distinction between these two forms of constraints explicit, we usually refer to either groups with 'predicative constraint declarations' and 'predicative constraints', versus 'functional constraint declarations' and 'functional constraints', respectively. Info Every specification with functional predicates is normalized to a form with only regular predicates. To show the normal form of a specification in Eclipse, use the Spoofax > Syntax > Format normalized AST menu action. Mapping rules \u00b6 Another common pattern in Statix is defining a predicate that instantiates a predicate for all elements in a list. Statix allows derive such mapping rules using the maps keyword as follows: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) A lift specifier ( $Lift ) can be one of the following: * : The identity lift . This lift specifier indicates that this argument is passed to the mapped constraint unchanged. list(*) : The list lift : This lift specifier indicates that the mapped constraint will be instantiated for each element in the list at that argument position. Each constraint defined with maps , must contain at least one list lift. Otherwise, the mapping would be a no-op. ({$Lift \",\"}+) : The tuple lift : This lift specifier indicates that arguments are extracted from a tuple. For each tuple argument, a corresponding lifting is applied afterwards. The type of $MappingConstraintName is inferred by inverse application of the lift specifiers to the type of $MappedConstraintName . Therefore, no explicit declaration of the type of the mapping constraint is required. Similar to predicative constraints, functional mapping constraints can be derived: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) = $ Lift In addition to lift specifiers of the input arguments, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred terms from the mapped constraints are aggregated and returned by the mapping constraint. Example. A common example where mapping rules are used is when type-checking a list of declarations. A specification snippet for that could look as follows: rules declOk : scope * Decl declsOk maps declOk ( * , list ( * )) // rules for declOk In this snippet, the declsOk constraint instantiates declOk for each declaration in a list of declaration. Its inferred type is scope * list(Decl) . When mapping functional constraints, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred values of the mapped constraint are returned by the mapping constraint. When using multiple list lifts in the input, the resulting constraint will zip the arguments. This implicitly requires the input lists to be of equal length. The creation of a cartesian product can be achieved by repeated application of the maps construct for each argument. Info Similar to functional constraints, constraints derived using the maps construct are normalized to regular predicative constraints. This normalization can be inspected using the Spoofax > Syntax > Format normalized AST menu action. Injections of Namespaces and Relations \u00b6 For convenience, it is possible to declare namespaces, namespace queries (both deprecated) and relations in a rules section as well. rules namespace Var : string resolve Var filter P * I * relation var : string -> TYPE","title":"Rules"},{"location":"references/statix/rules/#rules","text":"User-defined constraints and their rules make up the main part of a Statix specification. In this section, we describe the definition and usage of user-defined constraints and their rules.","title":"Rules"},{"location":"references/statix/rules/#constraint-definitions","text":"In order to define a custom constraint, its type must be declared first. A constraint can be declared in a rules section, or in a constraints subsection of a signature section. A constraint is declared by specifying its name and argument type. For more information on types, please refer to the Types section. Note that the name of the constraint must be unique within a specification. $ ConstraintName : { $ Type \"*\" } * Note In this reference manual, we consistently use the term 'constraint declaration' for the introduction of new user-defined constraints. However, in practise, these are sometimes also referred to as 'predicate' or just simply 'constraint'. When a constraint declaration is provided this way, it can be used as a constraint by providing concrete arguments, separated by comma's. $ ConstraintName ({ $ Term \",\" } * ) The sorts of the argument terms should be equal to the sorts in the constraint declaration.","title":"Constraint Definitions"},{"location":"references/statix/rules/#rule-definitions","text":"When solving a user-defined constraint, a rule for that constraint is unfolded in order to infer a model satisfying the constraint. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) : - $ Constraint . The part before the turnstile ( :- ) is often referred to as the head of the rule, while the $Constraint after the turnstile is denoted as body . When applying a rule, each head pattern (which is just a term) will be matched with its corresponding actual argument. Statically, the sorts of the terms in $Patterns are type-checked based on the constraint declaration. Any variables in patterns are implicitly introduced in the scope of the rule. Patterns can be non-linear. That is, a variable may occur multiple times in a pattern. Operationally, the subterms at these positions are then required to be structurally equal. Note that multiple rules for a single constraint can, and often will, be provided. For each constraint, the rule that is used for simplification is determined by the guard of the rule. This guard is derived from the head pattern: a rule can only be applied when the constraint arguments match the patterns. During constraint solving, Statix will try at most one rule for each constraint. The appropriate rule is selected by applying the following heuristics in order: 1. Rules with a smaller domain are preferred over rules with a larger domain. 2. When pairwise comparing rules, the rule for which, in left-to-right order, a more specific pattern is encountered first is preferred over the other. For all cases where these heuristics do not decide which rule to use for a constraint, compile time \"Overlapping patterns\" errors will be emitted. The $RuleName is just a name that can be used for documentation purposes. It cannot be referenced from any position in the specification, and may be omitted altogether.","title":"Rule Definitions"},{"location":"references/statix/rules/#axiom-rules","text":"In some cases, a constraint trivially holds for particular inputs. For such constraints, an axiom rule can be specified. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ). This rule is similar to a regular rule, but lacks a body. When applying such a rule, no new constraints are introduced, reflecting the fact that the constraint trivially holds for these arguments.","title":"Axiom rules"},{"location":"references/statix/rules/#functional-rules","text":"Some user-defined constraints can be thought of more naturally as a function: a constraint where a particular term is inferred by the constraint, rather than validated. Statix allows to write constraints in a functional idiom as follows: First, a constraint declaration for such 'functional constraints' must be provided as follows: $ ConstraintName : { $ Type \"*\" } * -> $ Type In addition to the regular list of input sorts, a sort for the output term is provided to the constraint declaration. Rule definitions for a functional constraint look as follows: [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) = $ Term : - $ Constraint . Compared to predicative rule definitions as introduced earlier in this section, an additional term after an equality-sign is appended to the rule head. This term denotes the output term (the term inferred by the rule). A functional constraint can be used in a term position, as opposed to a constraint position for predicative rules. Otherwise, their syntax is the same. $ ConstraintName ({ $ Term \",\" } * ) Semantically, the output term of applying the constraint is substituted at the position of the application of the functional predicate. Note When we want to make the distinction between these two forms of constraints explicit, we usually refer to either groups with 'predicative constraint declarations' and 'predicative constraints', versus 'functional constraint declarations' and 'functional constraints', respectively. Info Every specification with functional predicates is normalized to a form with only regular predicates. To show the normal form of a specification in Eclipse, use the Spoofax > Syntax > Format normalized AST menu action.","title":"Functional Rules"},{"location":"references/statix/rules/#mapping-rules","text":"Another common pattern in Statix is defining a predicate that instantiates a predicate for all elements in a list. Statix allows derive such mapping rules using the maps keyword as follows: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) A lift specifier ( $Lift ) can be one of the following: * : The identity lift . This lift specifier indicates that this argument is passed to the mapped constraint unchanged. list(*) : The list lift : This lift specifier indicates that the mapped constraint will be instantiated for each element in the list at that argument position. Each constraint defined with maps , must contain at least one list lift. Otherwise, the mapping would be a no-op. ({$Lift \",\"}+) : The tuple lift : This lift specifier indicates that arguments are extracted from a tuple. For each tuple argument, a corresponding lifting is applied afterwards. The type of $MappingConstraintName is inferred by inverse application of the lift specifiers to the type of $MappedConstraintName . Therefore, no explicit declaration of the type of the mapping constraint is required. Similar to predicative constraints, functional mapping constraints can be derived: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) = $ Lift In addition to lift specifiers of the input arguments, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred terms from the mapped constraints are aggregated and returned by the mapping constraint. Example. A common example where mapping rules are used is when type-checking a list of declarations. A specification snippet for that could look as follows: rules declOk : scope * Decl declsOk maps declOk ( * , list ( * )) // rules for declOk In this snippet, the declsOk constraint instantiates declOk for each declaration in a list of declaration. Its inferred type is scope * list(Decl) . When mapping functional constraints, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred values of the mapped constraint are returned by the mapping constraint. When using multiple list lifts in the input, the resulting constraint will zip the arguments. This implicitly requires the input lists to be of equal length. The creation of a cartesian product can be achieved by repeated application of the maps construct for each argument. Info Similar to functional constraints, constraints derived using the maps construct are normalized to regular predicative constraints. This normalization can be inspected using the Spoofax > Syntax > Format normalized AST menu action.","title":"Mapping rules"},{"location":"references/statix/rules/#injections-of-namespaces-and-relations","text":"For convenience, it is possible to declare namespaces, namespace queries (both deprecated) and relations in a rules section as well. rules namespace Var : string resolve Var filter P * I * relation var : string -> TYPE","title":"Injections of Namespaces and Relations"},{"location":"references/statix/scope-graphs/","text":"Scope Graph Constraints \u00b6 Scopes \u00b6 new Edges \u00b6 assert edge constraint label declarations Declarations \u00b6 assert declaration constraint relation declarations permission to extend Query \u00b6 Permission to Extend \u00b6","title":"Scope Graph Constraints"},{"location":"references/statix/scope-graphs/#scope-graph-constraints","text":"","title":"Scope Graph Constraints"},{"location":"references/statix/scope-graphs/#scopes","text":"new","title":"Scopes"},{"location":"references/statix/scope-graphs/#edges","text":"assert edge constraint label declarations","title":"Edges"},{"location":"references/statix/scope-graphs/#declarations","text":"assert declaration constraint relation declarations permission to extend","title":"Declarations"},{"location":"references/statix/scope-graphs/#query","text":"","title":"Query"},{"location":"references/statix/scope-graphs/#permission-to-extend","text":"","title":"Permission to Extend"},{"location":"references/statix/stratego-api/","text":"Stratego API \u00b6 Executing the Solver \u00b6 Querying the Analysis Result \u00b6","title":"Stratego API"},{"location":"references/statix/stratego-api/#stratego-api","text":"","title":"Stratego API"},{"location":"references/statix/stratego-api/#executing-the-solver","text":"","title":"Executing the Solver"},{"location":"references/statix/stratego-api/#querying-the-analysis-result","text":"","title":"Querying the Analysis Result"},{"location":"references/statix/terms/","text":"Terms \u00b6 Numerals \u00b6 Strings \u00b6 Identifiers \u00b6 lowercase id + wildcards Composite terms \u00b6 Tuples \u00b6 Lists \u00b6 various concat/tail types Variables \u00b6 Paths \u00b6 Name Ascription \u00b6 Type Ascription \u00b6 New \u00b6 Arithmetic Operations \u00b6 Occurrences \u00b6 Namespace Query \u00b6 Assertion Match \u00b6","title":"Terms"},{"location":"references/statix/terms/#terms","text":"","title":"Terms"},{"location":"references/statix/terms/#numerals","text":"","title":"Numerals"},{"location":"references/statix/terms/#strings","text":"","title":"Strings"},{"location":"references/statix/terms/#identifiers","text":"lowercase id + wildcards","title":"Identifiers"},{"location":"references/statix/terms/#composite-terms","text":"","title":"Composite terms"},{"location":"references/statix/terms/#tuples","text":"","title":"Tuples"},{"location":"references/statix/terms/#lists","text":"various concat/tail types","title":"Lists"},{"location":"references/statix/terms/#variables","text":"","title":"Variables"},{"location":"references/statix/terms/#paths","text":"","title":"Paths"},{"location":"references/statix/terms/#name-ascription","text":"","title":"Name Ascription"},{"location":"references/statix/terms/#type-ascription","text":"","title":"Type Ascription"},{"location":"references/statix/terms/#new","text":"","title":"New"},{"location":"references/statix/terms/#arithmetic-operations","text":"","title":"Arithmetic Operations"},{"location":"references/statix/terms/#occurrences","text":"","title":"Occurrences"},{"location":"references/statix/terms/#namespace-query","text":"","title":"Namespace Query"},{"location":"references/statix/terms/#assertion-match","text":"","title":"Assertion Match"},{"location":"references/statix/tests/","text":"Tests \u00b6 Test Format \u00b6 Test Output \u00b6 Substitution Scope Graph Messages","title":"Tests"},{"location":"references/statix/tests/#tests","text":"","title":"Tests"},{"location":"references/statix/tests/#test-format","text":"","title":"Test Format"},{"location":"references/statix/tests/#test-output","text":"Substitution Scope Graph Messages","title":"Test Output"},{"location":"references/statix/types/","text":"Types \u00b6 Literal Types \u00b6 Term Types \u00b6 Constraint Types \u00b6","title":"Types"},{"location":"references/statix/types/#types","text":"","title":"Types"},{"location":"references/statix/types/#literal-types","text":"","title":"Literal Types"},{"location":"references/statix/types/#term-types","text":"","title":"Term Types"},{"location":"references/statix/types/#constraint-types","text":"","title":"Constraint Types"},{"location":"references/stratego/","text":"Stratego \u00b6 The Stratego language caters for the definition of program transformations. Transformations operate on the abstract syntax trees of programs. Abstract syntax trees are represented by means of first-order terms . By using the concrete syntax of a language, transformations can be expressed in the native syntax of the language under transformation, rather than using abstract syntax. A program is structured as a collection of modules , which may import each other. Transformations are defined by means of named rewrite rules . Rules may explicitly invoke rules. Alternatively, rules may be invoked by strategies that define how to combine rules into a more complex transformation using strategy combinators . Context-sensitive transformations can be expressed using dynamic rewrite rules . Starting with Stratego 2, terms and transformation strategies are (gradually) typed . Placeholder Convention \u00b6 In this reference manual we use placeholders to indicate the syntactic structure of language constructs. For example, a rewrite rule has the form $ Label : $ Term - > $ Term in which the $Label is the name of the rule, the first $Term the left-hand side, and the second the right-hand side of the rule. This convention should give an indication of the formal structure of a construct, without going down to the precise details of the syntax definition. As a side effect, the schema also shows the preferred indentation of language constructs where that is applicable. Source \u00b6 The sources of the Stratego implementation can be found at https://github.com/metaborg/stratego : The Stratego language implementation https://github.com/metaborg/strategoxt : The Stratego/XT ecosystem Todo Give more specific links to syntax definition etc.","title":"Stratego"},{"location":"references/stratego/#stratego","text":"The Stratego language caters for the definition of program transformations. Transformations operate on the abstract syntax trees of programs. Abstract syntax trees are represented by means of first-order terms . By using the concrete syntax of a language, transformations can be expressed in the native syntax of the language under transformation, rather than using abstract syntax. A program is structured as a collection of modules , which may import each other. Transformations are defined by means of named rewrite rules . Rules may explicitly invoke rules. Alternatively, rules may be invoked by strategies that define how to combine rules into a more complex transformation using strategy combinators . Context-sensitive transformations can be expressed using dynamic rewrite rules . Starting with Stratego 2, terms and transformation strategies are (gradually) typed .","title":"Stratego"},{"location":"references/stratego/#placeholder-convention","text":"In this reference manual we use placeholders to indicate the syntactic structure of language constructs. For example, a rewrite rule has the form $ Label : $ Term - > $ Term in which the $Label is the name of the rule, the first $Term the left-hand side, and the second the right-hand side of the rule. This convention should give an indication of the formal structure of a construct, without going down to the precise details of the syntax definition. As a side effect, the schema also shows the preferred indentation of language constructs where that is applicable.","title":"Placeholder Convention"},{"location":"references/stratego/#source","text":"The sources of the Stratego implementation can be found at https://github.com/metaborg/stratego : The Stratego language implementation https://github.com/metaborg/strategoxt : The Stratego/XT ecosystem Todo Give more specific links to syntax definition etc.","title":"Source"},{"location":"references/stratego/concrete-syntax/","text":"Concrete Syntax \u00b6 Mixing Grammars \u00b6 ToTerm and FromTerm Imploding Terms \u00b6","title":"Concrete Syntax"},{"location":"references/stratego/concrete-syntax/#concrete-syntax","text":"","title":"Concrete Syntax"},{"location":"references/stratego/concrete-syntax/#mixing-grammars","text":"ToTerm and FromTerm","title":"Mixing Grammars"},{"location":"references/stratego/concrete-syntax/#imploding-terms","text":"","title":"Imploding Terms"},{"location":"references/stratego/dynamic-rules/","text":"Dynamic Rewrite Rules \u00b6","title":"Dynamic Rewrite Rules"},{"location":"references/stratego/dynamic-rules/#dynamic-rewrite-rules","text":"","title":"Dynamic Rewrite Rules"},{"location":"references/stratego/lexical/","text":"Lexical Conventions \u00b6 Module Names \u00b6 Module names can be ??? Identifiers \u00b6 Identifiers used as names of constructors and transformations have the form ID = [ a-zA-Z ][ a-zA-Z0-9 \\ - \\ _ ] * In particular, hyphens can be part of identifiers. Identifiers cannot be followed by identifiers or keywords without intervening whitespace. Integers \u00b6 INT = [ 0 -9 ] + Check syntax of integers Whitespace \u00b6 Spaces, tabs, and newlines are whitespace and can occur between any two tokens. Comments \u00b6 Comments follow the C/Java tradition. That is, the language supports single line comments after \\\\ // a single line comment and multi-line comments between /* and */ /* a multi-line comment can be spread over multiple lines */ Comments can occur anywhere. Multi-line comments cannot be nested currently. Todo but this should be changed so that multi-line comments can be nested Reserved Words \u00b6 Todo provide list of reserved words","title":"Lexical Conventions"},{"location":"references/stratego/lexical/#lexical-conventions","text":"","title":"Lexical Conventions"},{"location":"references/stratego/lexical/#module-names","text":"Module names can be ???","title":"Module Names"},{"location":"references/stratego/lexical/#identifiers","text":"Identifiers used as names of constructors and transformations have the form ID = [ a-zA-Z ][ a-zA-Z0-9 \\ - \\ _ ] * In particular, hyphens can be part of identifiers. Identifiers cannot be followed by identifiers or keywords without intervening whitespace.","title":"Identifiers"},{"location":"references/stratego/lexical/#integers","text":"INT = [ 0 -9 ] + Check syntax of integers","title":"Integers"},{"location":"references/stratego/lexical/#whitespace","text":"Spaces, tabs, and newlines are whitespace and can occur between any two tokens.","title":"Whitespace"},{"location":"references/stratego/lexical/#comments","text":"Comments follow the C/Java tradition. That is, the language supports single line comments after \\\\ // a single line comment and multi-line comments between /* and */ /* a multi-line comment can be spread over multiple lines */ Comments can occur anywhere. Multi-line comments cannot be nested currently. Todo but this should be changed so that multi-line comments can be nested","title":"Comments"},{"location":"references/stratego/lexical/#reserved-words","text":"Todo provide list of reserved words","title":"Reserved Words"},{"location":"references/stratego/modules/","text":"Modules \u00b6 A Stratego program is organised as a collection of modules, which are imported from a main module. File Name and File Extension \u00b6 A module coincides with the file it resides in. It is not possible to define more than one module in a file, which precludes nested modules. The name of a module coincides with the file name, which should be fully qualified relative to a root directory. A Stratego is a file with the extension .str2 for Stratego 2. Modules for the Stratego 1 version of the language have extension .str . The file extension does not feature in the module names used in the language. Consider the following example of a module header: module compilation / translation imports desugaring / desugar Module Names \u00b6 Module names can be hierarchical. For example, consider the following directory structure - trans - compilation - optimization.str2 - translation.str2 - desugaring - desugar.str2 A declaration of or reference to a module uses its fully qualified name, with / to indicate the directory structure, relative to a 'root' directory. For example, if trans is declared as a root , then the module names for the modules above are - compilation/optimization - compilation/translation - desugaring/desugar Module Structure \u00b6 A Stratego module has the following structure, where a single occurrence of a construct can be multiplied: module $ ModuleName imports $ ModuleName signature sort $ Sort constructors $ ConstructorDef rules $ RuleDef strategies $ StrategyDef Thus, a module starts with a module header followed by a list of imports . The name of a module in the header and imports should correspond to the file name, relative to a 'root' directory. The rest of a module consists of signature , rules , and strategies sections, in any order and possibly repeated. A signature section introduces sorts and constructors. Rule definitions and strategy definitions introduce named transformations. The rules and strategies section headers are indicative only; rule and strategy definitions can actually be mixed. Imports \u00b6 A module should import all other modules from which it uses definitions. Imports are non-transitive and may be mutually recursive. Modules can extend rule and strategy definitions from other modules. This allows the modular extension of a language. Libraries \u00b6 A Stratego library is a closed collection of modules. A library can be pre-compiled since client programs may not extend its definitions. A library should provide external definitions to publicize the signatures of constructors and transformations it defines. Source Inclusion \u00b6 Todo Concrete Syntax \u00b6 When using concrete syntax in a module, a .meta file accompanying the module indicates the parse table to use.","title":"Modules"},{"location":"references/stratego/modules/#modules","text":"A Stratego program is organised as a collection of modules, which are imported from a main module.","title":"Modules"},{"location":"references/stratego/modules/#file-name-and-file-extension","text":"A module coincides with the file it resides in. It is not possible to define more than one module in a file, which precludes nested modules. The name of a module coincides with the file name, which should be fully qualified relative to a root directory. A Stratego is a file with the extension .str2 for Stratego 2. Modules for the Stratego 1 version of the language have extension .str . The file extension does not feature in the module names used in the language. Consider the following example of a module header: module compilation / translation imports desugaring / desugar","title":"File Name and File Extension"},{"location":"references/stratego/modules/#module-names","text":"Module names can be hierarchical. For example, consider the following directory structure - trans - compilation - optimization.str2 - translation.str2 - desugaring - desugar.str2 A declaration of or reference to a module uses its fully qualified name, with / to indicate the directory structure, relative to a 'root' directory. For example, if trans is declared as a root , then the module names for the modules above are - compilation/optimization - compilation/translation - desugaring/desugar","title":"Module Names"},{"location":"references/stratego/modules/#module-structure","text":"A Stratego module has the following structure, where a single occurrence of a construct can be multiplied: module $ ModuleName imports $ ModuleName signature sort $ Sort constructors $ ConstructorDef rules $ RuleDef strategies $ StrategyDef Thus, a module starts with a module header followed by a list of imports . The name of a module in the header and imports should correspond to the file name, relative to a 'root' directory. The rest of a module consists of signature , rules , and strategies sections, in any order and possibly repeated. A signature section introduces sorts and constructors. Rule definitions and strategy definitions introduce named transformations. The rules and strategies section headers are indicative only; rule and strategy definitions can actually be mixed.","title":"Module Structure"},{"location":"references/stratego/modules/#imports","text":"A module should import all other modules from which it uses definitions. Imports are non-transitive and may be mutually recursive. Modules can extend rule and strategy definitions from other modules. This allows the modular extension of a language.","title":"Imports"},{"location":"references/stratego/modules/#libraries","text":"A Stratego library is a closed collection of modules. A library can be pre-compiled since client programs may not extend its definitions. A library should provide external definitions to publicize the signatures of constructors and transformations it defines.","title":"Libraries"},{"location":"references/stratego/modules/#source-inclusion","text":"Todo","title":"Source Inclusion"},{"location":"references/stratego/modules/#concrete-syntax","text":"When using concrete syntax in a module, a .meta file accompanying the module indicates the parse table to use.","title":"Concrete Syntax"},{"location":"references/stratego/overlays/","text":"Overlays \u00b6 Todo","title":"Overlays"},{"location":"references/stratego/overlays/#overlays","text":"Todo","title":"Overlays"},{"location":"references/stratego/patterns/","text":"Patterns \u00b6 Term Patterns \u00b6 A term pattern , is a term extended with variables. In the term pattern Plus ( e , Int ( \"0\" )) the identifier e is a variable that stands for any term. Linear vs Non-Linear \u00b6 A pattern is linear if each variable occurs at most once, non-linear otherwise. The non-linear pattern Plus ( e , e ) stands for a Plus term with identical arguments. A term pattern without variables (aka term ) is ground . Substitution \u00b6 Substitution is the process of applying a map from variables to terms to a term pattern, replacing occurrence of variables in the domain of the map with the corresponding terms in the codomain of the map. Substitution is also the name for the mapping of variables to terms. Pattern Matching \u00b6 Pattern matching is the process of matching a ground term against a term pattern. A term t matches a term pattern p iff there is a substition S such that applying the substitution to the pattern S(p) yields the term t .","title":"Patterns"},{"location":"references/stratego/patterns/#patterns","text":"","title":"Patterns"},{"location":"references/stratego/patterns/#term-patterns","text":"A term pattern , is a term extended with variables. In the term pattern Plus ( e , Int ( \"0\" )) the identifier e is a variable that stands for any term.","title":"Term Patterns"},{"location":"references/stratego/patterns/#linear-vs-non-linear","text":"A pattern is linear if each variable occurs at most once, non-linear otherwise. The non-linear pattern Plus ( e , e ) stands for a Plus term with identical arguments. A term pattern without variables (aka term ) is ground .","title":"Linear vs Non-Linear"},{"location":"references/stratego/patterns/#substitution","text":"Substitution is the process of applying a map from variables to terms to a term pattern, replacing occurrence of variables in the domain of the map with the corresponding terms in the codomain of the map. Substitution is also the name for the mapping of variables to terms.","title":"Substitution"},{"location":"references/stratego/patterns/#pattern-matching","text":"Pattern matching is the process of matching a ground term against a term pattern. A term t matches a term pattern p iff there is a substition S such that applying the substitution to the pattern S(p) yields the term t .","title":"Pattern Matching"},{"location":"references/stratego/rewrite-rules/","text":"Rewrite Rules \u00b6 Rewrite rules are used to define basic transformations in Stratego. Simple Rewrite Rules \u00b6 A simple rewrite rule has the form $ Id : $ Term - > $ Term It consists of a name that identifies the rule, a left-hand side term pattern, and a right-hand side term pattern. Applying a rule to a term t entails matching t against the left-hand side, binding any variables and replacing it with an instantiation of the right-hand side. For example, the rewrite rule DeMorgan DeMorgan : Not ( And ( e1 , e2 )) - > Or ( Not ( e1 ), Not ( e2 )) transforms a negation of a conjunction to a disjunction of negations. Applying this rule to the term Not(And(Var(p), Var(q))) results in a substitution binding Var(p) to e1 and Var(q) to e2 , and the instantiation Or(Not(Var(p)), Not(Var(q))) of the right-hand side of the rule. Note that a rewrite rule defines a partial computation . Only if the pattern match succeeds is the transformation applied. Such (pattern match) failure is a first-class citizen in Stratego and its effects are discussed with strategy combinators . Rules with the Same Name \u00b6 Multiple rewrite rules may have the same name. When a (simple) rewrite rule fails to apply to a term, the next rule with the same name is tried. For examples, the following rules define desugarings of expressions. rules desugar-exp :: Exp - > Exp desugar-exp : Seq ([], e ) - > e desugar-exp : Seq ([ e ], Unit ()) - > e desugar-exp : Seq ([ e1 , e2 | e * ], e3 ) - > Seq ([ e1 ], Seq ([ e2 | e * ], e3 )) desugar-exp : Seq ([ Seq ( e1 * , e1 ) | e2 * ], e2 ) - > Seq ([ e1 * , e1 | e2 * ], e2 ) desugar-exp : Let ( dec * , [ e1 , e2 | e * ]) - > Let ( dec * , [ Seq ([ e1 , e2 | e * ], Unit ())]) When one rule fails to apply, the next rule is tried. When the left-hand sides are non-overlapping, the order of the rules does not matter. In case of overlap, the rules are tried in textual order. When overlapping rules are defined in separate modules, the order is undefined. Note We should consider specificity ordering. Conditional Rewrite Rules \u00b6 A conditional rewrite rule checks a condition or performs a side computation before instantiating the right-hand side of the rule. The basic form of a conditional rewrite rule in Stratego is $ Id : $ Term - > $ Term where $ Strategy where the strategy expression represents a computation that may fail. When the condition fails, the expectation is that some other rule will pick up the computation. For example, the following conditional rewrite rules combine pattern matching with the predicate is-atom to select the rule to apply: rules rco-atom :: Exp - > ( List ( Dec ) * Exp ) rco-atom : Let ( dec * , [ e ]) - > ( dec * , e ) where < is-atom > e rco-atom : e - > ([], e ) where < is-atom > e rco-atom : e - > ([ VarDec ( x , Tid ( \"int\" ), e )], Var ( x )) where < not ( is-atom )> e where < newname > \"tmp\" => x When the condition fails, the application of the rule fails (and the next rule is tried if there is one). Side Computations with With \u00b6 Failure is not always expected. When a condition is used to express a side computation, the expection may be that it should always succeed. However, due to a programming error (e.g. a missed case), the condition may fail in some cases. To guard against such programming errors, the with condition expresses that the programmer expects a side computation to always succeed. When a with clause fails, the program should fail with an exception (and a stack trace). $ Id : $ Term - > $ Term with $ Strategy For example, a translate transformation from expressions to list of (stack machine) instructions may use side computations to recursively apply the transformation. translate :: Exp - > List ( Instr ) translate : Plus ( e1 , e2 ) - > < concat >[ instrs1 , instrs2 , [ ADD ()]] with < translate > e1 => instrs1 with < translate > e2 => instrs2 The recursive applications are not expected to fail. Therefore a with is used. Thus, use a where clause when the condition is to determine whether to apply the rule, and use a with clause to perform a side computation, which has to succeed and will trow an exception when it fails. Combining With and Where \u00b6 Rewrite rules can combine multiple with/where clauses in any order. $ Id : $ Term - > $ Term where $ Strategy with $ Strategy with $ Strategy where $ Strategy The only rule is that with clauses should always succeed. For example, the following explicate-exp rule defines the translation of an operator expression in a source language to an operator expression in a target language. explicate-exp :: Exp - > CExp explicate-exp : op # ( es ) - > cop # ( atms ) where < is-operator > op with < map ( explicate-atom )> es => atms with < operator-to-coperator > op => cop The where condition tests whether the rule should be applied using the is-operator strategy. (By using generic term deconstruction to obtain the term constructor.) The with premises define side computations. Parameterized Rewrite Rules \u00b6 Rewrite rules can be parameterized with transformation strategies and with terms. In general, a parameterized rule has the form: $ Id ( $ StrategyArg , ... | $ TermArg , ... ) : $ Term - > $ Term where $ Strategy ... The strategy parameters represent computations that can be applied in the body of the rule. The term parameters are terms that are evaluated eagerly at the call site. The (arity of the) parameters of a rule are part of its identity. That is, rules with the same name, but different numbers of parameters are different. For example, the following rules define reversal of a list with an accumulator: rules reverse :: List ( a ) - > List ( a ) reverse (| List ( a )) :: List ( a ) - > List ( a ) s reverse : xs - > < reverse (|[])> xs reverse (| xs ) : [] - > xs reverse (| xs ) : [ y | ys ] - > < reverse-acc (|[ y | xs ])> ys When leaving out the term parameters, the bar can be left out as well $ Id ( $ StrategyArg ) : $ Term - > $ Term where $ Strategy For example, the map(s) strategy applies transformation s to each element of a list: map ( a - > b ) :: List ( a ) - > List ( b ) map ( s ) : [] - > [] map ( s ) : [ hd | tl ] - > [< s > hd | < map ( s )> tl ] The simple rewrite rules are above are the special case in which there are no strategy and term parameters. In that case, the parentheses can be left out as well. Note In the absence of a type system, the distinction between strategy arguments and term arguments was made based on the syntactic distinction. In a future version of the language, this syntactic distiction may no longer be necessary based on types. Typing Rewrite Rules \u00b6 As noted in the type section, rewrite rules can be typed using a signature of the form $Id($StrategyTypes | $TermTypes) :: $Type -> $Type Not providing a type signature amounts to declaring the rule as having signature $Id(?|?) :: ? -> ? That is, nothing is known about the term that is transformed or the strategies and terms that are passed. But do note that the arity of the strategy and term arguments is relevant for identifying the transformation rule that is defined.","title":"Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#rewrite-rules","text":"Rewrite rules are used to define basic transformations in Stratego.","title":"Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#simple-rewrite-rules","text":"A simple rewrite rule has the form $ Id : $ Term - > $ Term It consists of a name that identifies the rule, a left-hand side term pattern, and a right-hand side term pattern. Applying a rule to a term t entails matching t against the left-hand side, binding any variables and replacing it with an instantiation of the right-hand side. For example, the rewrite rule DeMorgan DeMorgan : Not ( And ( e1 , e2 )) - > Or ( Not ( e1 ), Not ( e2 )) transforms a negation of a conjunction to a disjunction of negations. Applying this rule to the term Not(And(Var(p), Var(q))) results in a substitution binding Var(p) to e1 and Var(q) to e2 , and the instantiation Or(Not(Var(p)), Not(Var(q))) of the right-hand side of the rule. Note that a rewrite rule defines a partial computation . Only if the pattern match succeeds is the transformation applied. Such (pattern match) failure is a first-class citizen in Stratego and its effects are discussed with strategy combinators .","title":"Simple Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#rules-with-the-same-name","text":"Multiple rewrite rules may have the same name. When a (simple) rewrite rule fails to apply to a term, the next rule with the same name is tried. For examples, the following rules define desugarings of expressions. rules desugar-exp :: Exp - > Exp desugar-exp : Seq ([], e ) - > e desugar-exp : Seq ([ e ], Unit ()) - > e desugar-exp : Seq ([ e1 , e2 | e * ], e3 ) - > Seq ([ e1 ], Seq ([ e2 | e * ], e3 )) desugar-exp : Seq ([ Seq ( e1 * , e1 ) | e2 * ], e2 ) - > Seq ([ e1 * , e1 | e2 * ], e2 ) desugar-exp : Let ( dec * , [ e1 , e2 | e * ]) - > Let ( dec * , [ Seq ([ e1 , e2 | e * ], Unit ())]) When one rule fails to apply, the next rule is tried. When the left-hand sides are non-overlapping, the order of the rules does not matter. In case of overlap, the rules are tried in textual order. When overlapping rules are defined in separate modules, the order is undefined. Note We should consider specificity ordering.","title":"Rules with the Same Name"},{"location":"references/stratego/rewrite-rules/#conditional-rewrite-rules","text":"A conditional rewrite rule checks a condition or performs a side computation before instantiating the right-hand side of the rule. The basic form of a conditional rewrite rule in Stratego is $ Id : $ Term - > $ Term where $ Strategy where the strategy expression represents a computation that may fail. When the condition fails, the expectation is that some other rule will pick up the computation. For example, the following conditional rewrite rules combine pattern matching with the predicate is-atom to select the rule to apply: rules rco-atom :: Exp - > ( List ( Dec ) * Exp ) rco-atom : Let ( dec * , [ e ]) - > ( dec * , e ) where < is-atom > e rco-atom : e - > ([], e ) where < is-atom > e rco-atom : e - > ([ VarDec ( x , Tid ( \"int\" ), e )], Var ( x )) where < not ( is-atom )> e where < newname > \"tmp\" => x When the condition fails, the application of the rule fails (and the next rule is tried if there is one).","title":"Conditional Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#side-computations-with-with","text":"Failure is not always expected. When a condition is used to express a side computation, the expection may be that it should always succeed. However, due to a programming error (e.g. a missed case), the condition may fail in some cases. To guard against such programming errors, the with condition expresses that the programmer expects a side computation to always succeed. When a with clause fails, the program should fail with an exception (and a stack trace). $ Id : $ Term - > $ Term with $ Strategy For example, a translate transformation from expressions to list of (stack machine) instructions may use side computations to recursively apply the transformation. translate :: Exp - > List ( Instr ) translate : Plus ( e1 , e2 ) - > < concat >[ instrs1 , instrs2 , [ ADD ()]] with < translate > e1 => instrs1 with < translate > e2 => instrs2 The recursive applications are not expected to fail. Therefore a with is used. Thus, use a where clause when the condition is to determine whether to apply the rule, and use a with clause to perform a side computation, which has to succeed and will trow an exception when it fails.","title":"Side Computations with With"},{"location":"references/stratego/rewrite-rules/#combining-with-and-where","text":"Rewrite rules can combine multiple with/where clauses in any order. $ Id : $ Term - > $ Term where $ Strategy with $ Strategy with $ Strategy where $ Strategy The only rule is that with clauses should always succeed. For example, the following explicate-exp rule defines the translation of an operator expression in a source language to an operator expression in a target language. explicate-exp :: Exp - > CExp explicate-exp : op # ( es ) - > cop # ( atms ) where < is-operator > op with < map ( explicate-atom )> es => atms with < operator-to-coperator > op => cop The where condition tests whether the rule should be applied using the is-operator strategy. (By using generic term deconstruction to obtain the term constructor.) The with premises define side computations.","title":"Combining With and Where"},{"location":"references/stratego/rewrite-rules/#parameterized-rewrite-rules","text":"Rewrite rules can be parameterized with transformation strategies and with terms. In general, a parameterized rule has the form: $ Id ( $ StrategyArg , ... | $ TermArg , ... ) : $ Term - > $ Term where $ Strategy ... The strategy parameters represent computations that can be applied in the body of the rule. The term parameters are terms that are evaluated eagerly at the call site. The (arity of the) parameters of a rule are part of its identity. That is, rules with the same name, but different numbers of parameters are different. For example, the following rules define reversal of a list with an accumulator: rules reverse :: List ( a ) - > List ( a ) reverse (| List ( a )) :: List ( a ) - > List ( a ) s reverse : xs - > < reverse (|[])> xs reverse (| xs ) : [] - > xs reverse (| xs ) : [ y | ys ] - > < reverse-acc (|[ y | xs ])> ys When leaving out the term parameters, the bar can be left out as well $ Id ( $ StrategyArg ) : $ Term - > $ Term where $ Strategy For example, the map(s) strategy applies transformation s to each element of a list: map ( a - > b ) :: List ( a ) - > List ( b ) map ( s ) : [] - > [] map ( s ) : [ hd | tl ] - > [< s > hd | < map ( s )> tl ] The simple rewrite rules are above are the special case in which there are no strategy and term parameters. In that case, the parentheses can be left out as well. Note In the absence of a type system, the distinction between strategy arguments and term arguments was made based on the syntactic distinction. In a future version of the language, this syntactic distiction may no longer be necessary based on types.","title":"Parameterized Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#typing-rewrite-rules","text":"As noted in the type section, rewrite rules can be typed using a signature of the form $Id($StrategyTypes | $TermTypes) :: $Type -> $Type Not providing a type signature amounts to declaring the rule as having signature $Id(?|?) :: ? -> ? That is, nothing is known about the term that is transformed or the strategies and terms that are passed. But do note that the arity of the strategy and term arguments is relevant for identifying the transformation rule that is defined.","title":"Typing Rewrite Rules"},{"location":"references/stratego/strategies/","text":"Strategy Definitions \u00b6 Strategy definitions give a name to a strategy expression. Simple Definitions \u00b6 A simple strategy definition gaves a name to a strategy expression . $ Id = s For example, the following definition defines desugar as an application of the innermost strategy to the rewrite rule(s) desugar-exp . strategies desugar :: Module - > Module desugar = innermost ( desugar-exp ) Parameterized Definitions \u00b6 Just like rewrite rules , strategy definitions can be parameterized with strategies and terms. $ Id ( $ StrategyArg , ... | $ TermArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... | t1 , ... ) = s When a strategy has no term arguments, the bar can be left out: $ Id ( $ StrategyArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... ) = s Simple strategy definitions are the special case in which a strategy does not have strategy and term arguments. For example, the following definition defines topdown(s) in terms of sequential composition and generic traversal: topdown ( TP ) :: TP topdown ( s ) = s ; all ( topdown ( s )) Extending Definitions \u00b6 Just like rewrite rules, strategy definitions can have multiple definitions. In case a strategy expression fails to apply, the next definition is applied. When definitions are in the same module, definitions are applied in the textual order they are defined in. When definitions are defined in separate modules, the order is undefined. External Definitions \u00b6 external definitions libraries Todo finish this section on external definitions Local Definitions \u00b6 Todo finish this section on local definitions","title":"Strategy Definitions"},{"location":"references/stratego/strategies/#strategy-definitions","text":"Strategy definitions give a name to a strategy expression.","title":"Strategy Definitions"},{"location":"references/stratego/strategies/#simple-definitions","text":"A simple strategy definition gaves a name to a strategy expression . $ Id = s For example, the following definition defines desugar as an application of the innermost strategy to the rewrite rule(s) desugar-exp . strategies desugar :: Module - > Module desugar = innermost ( desugar-exp )","title":"Simple Definitions"},{"location":"references/stratego/strategies/#parameterized-definitions","text":"Just like rewrite rules , strategy definitions can be parameterized with strategies and terms. $ Id ( $ StrategyArg , ... | $ TermArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... | t1 , ... ) = s When a strategy has no term arguments, the bar can be left out: $ Id ( $ StrategyArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... ) = s Simple strategy definitions are the special case in which a strategy does not have strategy and term arguments. For example, the following definition defines topdown(s) in terms of sequential composition and generic traversal: topdown ( TP ) :: TP topdown ( s ) = s ; all ( topdown ( s ))","title":"Parameterized Definitions"},{"location":"references/stratego/strategies/#extending-definitions","text":"Just like rewrite rules, strategy definitions can have multiple definitions. In case a strategy expression fails to apply, the next definition is applied. When definitions are in the same module, definitions are applied in the textual order they are defined in. When definitions are defined in separate modules, the order is undefined.","title":"Extending Definitions"},{"location":"references/stratego/strategies/#external-definitions","text":"external definitions libraries Todo finish this section on external definitions","title":"External Definitions"},{"location":"references/stratego/strategies/#local-definitions","text":"Todo finish this section on local definitions","title":"Local Definitions"},{"location":"references/stratego/strategy-combinators-traversal/","text":"Traversal Combinators \u00b6 1 2 All \u00b6 One \u00b6 Some \u00b6 Applications \u00b6 References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1 , doi:10.1016/S1571-0661(05)80027-1 . \u21a9","title":"Traversal Combinators"},{"location":"references/stratego/strategy-combinators-traversal/#traversal-combinators","text":"1 2","title":"Traversal Combinators"},{"location":"references/stratego/strategy-combinators-traversal/#all","text":"","title":"All"},{"location":"references/stratego/strategy-combinators-traversal/#one","text":"","title":"One"},{"location":"references/stratego/strategy-combinators-traversal/#some","text":"","title":"Some"},{"location":"references/stratego/strategy-combinators-traversal/#applications","text":"","title":"Applications"},{"location":"references/stratego/strategy-combinators-traversal/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1 , doi:10.1016/S1571-0661(05)80027-1 . \u21a9","title":"References"},{"location":"references/stratego/strategy-combinators-type-unifying/","text":"Type Unifying Transformations \u00b6 1 2 References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1 , doi:10.1016/S1571-0661(05)80027-1 . \u21a9","title":"Type Unifying Transformations"},{"location":"references/stratego/strategy-combinators-type-unifying/#type-unifying-transformations","text":"1 2","title":"Type Unifying Transformations"},{"location":"references/stratego/strategy-combinators-type-unifying/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1 , doi:10.1016/S1571-0661(05)80027-1 . \u21a9","title":"References"},{"location":"references/stratego/strategy-combinators/","text":"Strategy Combinators \u00b6 Rather than building in rewrite rules and high-level strategies, Stratego provides strategy combinators as basic building blocks from which these can defined strategies 1 core language [VisserB98] to which more complex strategies can be desugared Warning While it useful to understand the constructs defined in this and the next sections, their use should be avoided in favour of the higher-level language constructs where possible. Identity and Failure \u00b6 The most basic operations in Stratego are id and fail. The identity strategy id always succeeds and behaves as the identity function on terms. The failure strategy fail always fails. The operations have no side effects. Sequential Composition \u00b6 The sequential composition s1 ; s2 of the strategies s1 and s2 first applies the strategy s1 to the subject term and then s2 to the result of that first application. The strategy fails if either s1 or s2 fails. Left Choice \u00b6 Guarded Choice \u00b6 Match \u00b6 Build \u00b6 Variable Scope \u00b6 Calling Primitives \u00b6 References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9","title":"Strategy Combinators"},{"location":"references/stratego/strategy-combinators/#strategy-combinators","text":"Rather than building in rewrite rules and high-level strategies, Stratego provides strategy combinators as basic building blocks from which these can defined strategies 1 core language [VisserB98] to which more complex strategies can be desugared Warning While it useful to understand the constructs defined in this and the next sections, their use should be avoided in favour of the higher-level language constructs where possible.","title":"Strategy Combinators"},{"location":"references/stratego/strategy-combinators/#identity-and-failure","text":"The most basic operations in Stratego are id and fail. The identity strategy id always succeeds and behaves as the identity function on terms. The failure strategy fail always fails. The operations have no side effects.","title":"Identity and Failure"},{"location":"references/stratego/strategy-combinators/#sequential-composition","text":"The sequential composition s1 ; s2 of the strategies s1 and s2 first applies the strategy s1 to the subject term and then s2 to the result of that first application. The strategy fails if either s1 or s2 fails.","title":"Sequential Composition"},{"location":"references/stratego/strategy-combinators/#left-choice","text":"","title":"Left Choice"},{"location":"references/stratego/strategy-combinators/#guarded-choice","text":"","title":"Guarded Choice"},{"location":"references/stratego/strategy-combinators/#match","text":"","title":"Match"},{"location":"references/stratego/strategy-combinators/#build","text":"","title":"Build"},{"location":"references/stratego/strategy-combinators/#variable-scope","text":"","title":"Variable Scope"},{"location":"references/stratego/strategy-combinators/#calling-primitives","text":"","title":"Calling Primitives"},{"location":"references/stratego/strategy-combinators/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9","title":"References"},{"location":"references/stratego/terms/","text":"Terms \u00b6 Stratego programs transform terms. When using Stratego for program transformation, terms typically represent the abstract syntax tree of a program. But Stratego does not much care what a term represents. Terms can just as well represent structured documents, software models, or anything else that can be rendered in a structured format. Generally program text is transformed into a term by means of parsing, and turned back into program text by means of pretty-printing. One way to achieve this is by using SDF3 . Annotated Term Format \u00b6 Terms in Stratego are terms in the Annotated Term Format , or ATerms for short 1 . The ATerm format provides a set of constructs for representing trees, comparable to XML or abstract data types in functional programming languages. For example, the code 4 + f(5 * x) might be represented in a term as: Plus ( Int ( \"4\" ), Call ( \"f\" , [ Mul ( Int ( \"5\" ), Var ( \"x\" ))])) ATerms are constructed from the following elements: Integer : An integer constant, that is a list of decimal digits, is an ATerm. Examples: 1 , 12343 {.docutils .literal .notranslate}. String : A string constant, that is a list of characters between double quotes is an ATerm. Special characters such as double quotes and newlines should be escaped using a backslash. The backslash character itself should be escaped as well. Examples: \"foobar\" , \"string with quotes\\\"\" , \"escaped escape character\\\\ and a newline\\n\" . Constructor application : A constructor is an identifier, that is an alphanumeric string starting with a letter, or a double quoted string. A constructor application c(t1,...,tn) creates a term by applying a constructor to a list of zero or more terms. For example, the term Plus(Int(\"4\"),Var(\"x\")) uses the constructors Plus , Int , and Var to create a nested term from the strings \"4\" and \"x\" . List : A list is a term of the form [t1,...,tn] , that is a list of zero or more terms between square brackets. While all applications of a specific constructor typically have the same number of subterms, lists can have a variable number of subterms. The elements of a list are typically of the same type, while the subterms of a constructor application can vary in type. Example: The second argument of the call to \"f\" in the term Call(\"f\",[Int(\"5\"),Var(\"x\")]) is a list of expressions. Tuple : A tuple (t1,...,tn) is a constructor application without a constructor. Example: (Var(\"x\"), Type(\"int\")) Annotation : The elements defined above are used to create the structural part of terms. Optionally, a term can be annotated with a list of terms. These annotations typically carry additional semantic information about the term. An annotated term has the form t{t1,...,tn} . Example: Lt(Var(\"n\"),Int(\"1\")){Type(\"bool\")} . The contents of annotations is up to the application. Persistent Representation \u00b6 The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer. Namespaces \u00b6 Currently, the constructors of terms live in a global namespace. In the future, we want to support qualified names. References \u00b6 Mark G. J. van den Brand, H. A. de Jong, Paul Klint, and Pieter A. Olivier. Efficient annotated terms. Software: Practice and Experience , 30(3):259\u2013291, 2000. \u21a9","title":"Terms"},{"location":"references/stratego/terms/#terms","text":"Stratego programs transform terms. When using Stratego for program transformation, terms typically represent the abstract syntax tree of a program. But Stratego does not much care what a term represents. Terms can just as well represent structured documents, software models, or anything else that can be rendered in a structured format. Generally program text is transformed into a term by means of parsing, and turned back into program text by means of pretty-printing. One way to achieve this is by using SDF3 .","title":"Terms"},{"location":"references/stratego/terms/#annotated-term-format","text":"Terms in Stratego are terms in the Annotated Term Format , or ATerms for short 1 . The ATerm format provides a set of constructs for representing trees, comparable to XML or abstract data types in functional programming languages. For example, the code 4 + f(5 * x) might be represented in a term as: Plus ( Int ( \"4\" ), Call ( \"f\" , [ Mul ( Int ( \"5\" ), Var ( \"x\" ))])) ATerms are constructed from the following elements: Integer : An integer constant, that is a list of decimal digits, is an ATerm. Examples: 1 , 12343 {.docutils .literal .notranslate}. String : A string constant, that is a list of characters between double quotes is an ATerm. Special characters such as double quotes and newlines should be escaped using a backslash. The backslash character itself should be escaped as well. Examples: \"foobar\" , \"string with quotes\\\"\" , \"escaped escape character\\\\ and a newline\\n\" . Constructor application : A constructor is an identifier, that is an alphanumeric string starting with a letter, or a double quoted string. A constructor application c(t1,...,tn) creates a term by applying a constructor to a list of zero or more terms. For example, the term Plus(Int(\"4\"),Var(\"x\")) uses the constructors Plus , Int , and Var to create a nested term from the strings \"4\" and \"x\" . List : A list is a term of the form [t1,...,tn] , that is a list of zero or more terms between square brackets. While all applications of a specific constructor typically have the same number of subterms, lists can have a variable number of subterms. The elements of a list are typically of the same type, while the subterms of a constructor application can vary in type. Example: The second argument of the call to \"f\" in the term Call(\"f\",[Int(\"5\"),Var(\"x\")]) is a list of expressions. Tuple : A tuple (t1,...,tn) is a constructor application without a constructor. Example: (Var(\"x\"), Type(\"int\")) Annotation : The elements defined above are used to create the structural part of terms. Optionally, a term can be annotated with a list of terms. These annotations typically carry additional semantic information about the term. An annotated term has the form t{t1,...,tn} . Example: Lt(Var(\"n\"),Int(\"1\")){Type(\"bool\")} . The contents of annotations is up to the application.","title":"Annotated Term Format"},{"location":"references/stratego/terms/#persistent-representation","text":"The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.","title":"Persistent Representation"},{"location":"references/stratego/terms/#namespaces","text":"Currently, the constructors of terms live in a global namespace. In the future, we want to support qualified names.","title":"Namespaces"},{"location":"references/stratego/terms/#references","text":"Mark G. J. van den Brand, H. A. de Jong, Paul Klint, and Pieter A. Olivier. Efficient annotated terms. Software: Practice and Experience , 30(3):259\u2013291, 2000. \u21a9","title":"References"},{"location":"references/stratego/types/","text":"Types \u00b6 Annotated Terms provide a generic, untyped format to represent tree-structured data. Stratego transformations can transform such data, but require at least that the arities of term constructors that are used in rules are declared. Further, starting with Stratego 2, the types of terms and term transformations may be declared and checked in more detail 1 . Term Signatures \u00b6 A signature declares sorts and constructors for these sorts using a definition of the form: signature sorts $ Sort ... constructors $ Constructor : $ Type * ... - > $ Sort A sort is determined by an identifier and optionally has arguments. For each constructor, a signature declares the number and types of its arguments. The Stratego1 compiler only checks the arity of constructor applications against the signature. The Stratego2 compiler uses signature definitions to type check code if it has been given a type signature. Injections \u00b6 An injection is a constructor without name and with a single domain argument. signature constructors : $ Sort - > $ Sort Injections include an entire type as a subtype of another type without cluttering the tree structure. Example Signature \u00b6 For example, the following signature declares some typical constructors for constructing abstract syntax trees of expressions in a programming language: signature sorts Id Exp constructors : string - > Id Var : Id - > Exp Int : Int - > Exp Plus : Exp * Exp - > Exp Mul : Exp * Exp - > Exp Call : Id * List ( Exp ) - > Exp Note that the first injection allows strings to be used as identifiers ( Id ). The List Type \u00b6 The List(Exp) type used above is built-in and corresponds to homogenous lists of terms of the same type ( Exp in this case). Polymorphic Types \u00b6 Stratego2 also supports user-defined polymorphic types. That is, sorts can have parameters. For example, the following signature defines the type of priority queues, polymorphic in the carrier type, in which the priority is determined by the length of the list. signature sorts PrioQ ( * ) constructors NilQ : PrioQ ( a ) ConsQ : a * int * List ( a ) * PrioQ ( a ) - > PrioQ ( a ) Signature from Syntax Definition \u00b6 Signatures can be generated automatically from a syntax definition in SDF3 . That ensures that the signature describes exactly the abstract syntax terms generated by a parser generated from that syntax definition. Furthermore, an automatically generated pretty-printer maps terms conforming to such a signature to a well-formed textual representation of the program. Todo link to pretty-printer generation Transformation Types \u00b6 Starting with Stratego2, the language also supports the definition of types for transformation definitions. The general form of a transformation type definition is $ Id ( $ StrategyType , ... | $ TermType , ... ) :: $ TermType - > $ TermType defining the signature of a transformation with name $Id with the types of its strategy arguments and term arguments, the type of the 'current term' to which the transformation is applied, and the type of the term that is returned, if the transformation succeeds. When a transformation only has strategy parameters, the bar can be left out, resulting in a signature of the form: $ Id ( $ StrategyType , ... ) :: $ TermType - > $ TermType When a transformation also has no strategy parameters, the parentheses can be left out as well, resulting in a signature of the form: $ Id :: $ TermType - > $ TermType Type Dynamic \u00b6 Stratego2 is a gradually typed language in order to facilitate the migration from (mostly) untyped Stratego1 code to typed Stratego2 code. Furthermore, some patterns in Stratego cannot be typed statically. Type dynamic , written ? , represents the unknown type. Type Casts \u00b6 Gradual type systems allow a term with the dynamic type to be used in any place where a static type is required. Stratego2 will insert a type cast at such a point to check at run time that the term is type-correct. This way, a Stratego program halts execution in predictable places when a run time type error occurs. There can be no run time type errors in fully statically typed code either, only at the boundary between dynamically and statically typed code. Type Preserving Transformations \u00b6 A type preserving transformation transforms any type to itself (or fails). In signatures, a type preserving transformation is indicated with TP . For example, the topdown traversal is type preserving if its argument strategy is. Thus, its signature is defined as topdown ( s : TP ) :: TP The type-checking for a type preserving transformation is very strict. It should be in terms of other type preserving transformations, or match the input term to a specific type and return a term from that specific type. Is Type \u00b6 Given the definition of a term signature, the is(S) strategy checks whether a term is of sort S and fails if that is not the case. For example, the strategy <is(Exp)>t checks that term t conforms to the signature of sort Exp . The is(S) strategy uses the same mechanism as type casts for checking a term type at run time. References \u00b6 Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9","title":"Types"},{"location":"references/stratego/types/#types","text":"Annotated Terms provide a generic, untyped format to represent tree-structured data. Stratego transformations can transform such data, but require at least that the arities of term constructors that are used in rules are declared. Further, starting with Stratego 2, the types of terms and term transformations may be declared and checked in more detail 1 .","title":"Types"},{"location":"references/stratego/types/#term-signatures","text":"A signature declares sorts and constructors for these sorts using a definition of the form: signature sorts $ Sort ... constructors $ Constructor : $ Type * ... - > $ Sort A sort is determined by an identifier and optionally has arguments. For each constructor, a signature declares the number and types of its arguments. The Stratego1 compiler only checks the arity of constructor applications against the signature. The Stratego2 compiler uses signature definitions to type check code if it has been given a type signature.","title":"Term Signatures"},{"location":"references/stratego/types/#injections","text":"An injection is a constructor without name and with a single domain argument. signature constructors : $ Sort - > $ Sort Injections include an entire type as a subtype of another type without cluttering the tree structure.","title":"Injections"},{"location":"references/stratego/types/#example-signature","text":"For example, the following signature declares some typical constructors for constructing abstract syntax trees of expressions in a programming language: signature sorts Id Exp constructors : string - > Id Var : Id - > Exp Int : Int - > Exp Plus : Exp * Exp - > Exp Mul : Exp * Exp - > Exp Call : Id * List ( Exp ) - > Exp Note that the first injection allows strings to be used as identifiers ( Id ).","title":"Example Signature"},{"location":"references/stratego/types/#the-list-type","text":"The List(Exp) type used above is built-in and corresponds to homogenous lists of terms of the same type ( Exp in this case).","title":"The List Type"},{"location":"references/stratego/types/#polymorphic-types","text":"Stratego2 also supports user-defined polymorphic types. That is, sorts can have parameters. For example, the following signature defines the type of priority queues, polymorphic in the carrier type, in which the priority is determined by the length of the list. signature sorts PrioQ ( * ) constructors NilQ : PrioQ ( a ) ConsQ : a * int * List ( a ) * PrioQ ( a ) - > PrioQ ( a )","title":"Polymorphic Types"},{"location":"references/stratego/types/#signature-from-syntax-definition","text":"Signatures can be generated automatically from a syntax definition in SDF3 . That ensures that the signature describes exactly the abstract syntax terms generated by a parser generated from that syntax definition. Furthermore, an automatically generated pretty-printer maps terms conforming to such a signature to a well-formed textual representation of the program. Todo link to pretty-printer generation","title":"Signature from Syntax Definition"},{"location":"references/stratego/types/#transformation-types","text":"Starting with Stratego2, the language also supports the definition of types for transformation definitions. The general form of a transformation type definition is $ Id ( $ StrategyType , ... | $ TermType , ... ) :: $ TermType - > $ TermType defining the signature of a transformation with name $Id with the types of its strategy arguments and term arguments, the type of the 'current term' to which the transformation is applied, and the type of the term that is returned, if the transformation succeeds. When a transformation only has strategy parameters, the bar can be left out, resulting in a signature of the form: $ Id ( $ StrategyType , ... ) :: $ TermType - > $ TermType When a transformation also has no strategy parameters, the parentheses can be left out as well, resulting in a signature of the form: $ Id :: $ TermType - > $ TermType","title":"Transformation Types"},{"location":"references/stratego/types/#type-dynamic","text":"Stratego2 is a gradually typed language in order to facilitate the migration from (mostly) untyped Stratego1 code to typed Stratego2 code. Furthermore, some patterns in Stratego cannot be typed statically. Type dynamic , written ? , represents the unknown type.","title":"Type Dynamic"},{"location":"references/stratego/types/#type-casts","text":"Gradual type systems allow a term with the dynamic type to be used in any place where a static type is required. Stratego2 will insert a type cast at such a point to check at run time that the term is type-correct. This way, a Stratego program halts execution in predictable places when a run time type error occurs. There can be no run time type errors in fully statically typed code either, only at the boundary between dynamically and statically typed code.","title":"Type Casts"},{"location":"references/stratego/types/#type-preserving-transformations","text":"A type preserving transformation transforms any type to itself (or fails). In signatures, a type preserving transformation is indicated with TP . For example, the topdown traversal is type preserving if its argument strategy is. Thus, its signature is defined as topdown ( s : TP ) :: TP The type-checking for a type preserving transformation is very strict. It should be in terms of other type preserving transformations, or match the input term to a specific type and return a term from that specific type.","title":"Type Preserving Transformations"},{"location":"references/stratego/types/#is-type","text":"Given the definition of a term signature, the is(S) strategy checks whether a term is of sort S and fails if that is not the case. For example, the strategy <is(Exp)>t checks that term t conforms to the signature of sort Exp . The is(S) strategy uses the same mechanism as type casts for checking a term type at run time.","title":"Is Type"},{"location":"references/stratego/types/#references","text":"Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9","title":"References"},{"location":"references/syntax/","text":"SDF3 \u00b6 SDF3 is the meta-language in Spoofax for syntax definition. A syntax definition is structured as a collection of modules , which may import each other. Symbols are the building blocks of productions . Productions are defined for lexical , context-free , or kernel syntax. Start symbols indicate the entry point of a syntax definition. SDF3 automatically generates a pretty-printer for template -based productions. Grammars can be disambiguated by means of rejects, priorities, associativity, and restrictions. SDF3 provides additional constructs for the definition of layout-sensitivite languages. Permissive grammars are automatically generated for error-recovery parsing. Handwritten recovery rules can be added to tweak recovery behavior. Source \u00b6 The sources of the SDF3 implementation can be found at https://github.com/metaborg/sdf/tree/master/org.metaborg.meta.lang.template : The SDF3 language implementation (SDF3 was called TemplateLang before and it has not been renamed everywhere yet)","title":"SDF3"},{"location":"references/syntax/#sdf3","text":"SDF3 is the meta-language in Spoofax for syntax definition. A syntax definition is structured as a collection of modules , which may import each other. Symbols are the building blocks of productions . Productions are defined for lexical , context-free , or kernel syntax. Start symbols indicate the entry point of a syntax definition. SDF3 automatically generates a pretty-printer for template -based productions. Grammars can be disambiguated by means of rejects, priorities, associativity, and restrictions. SDF3 provides additional constructs for the definition of layout-sensitivite languages. Permissive grammars are automatically generated for error-recovery parsing. Handwritten recovery rules can be added to tweak recovery behavior.","title":"SDF3"},{"location":"references/syntax/#source","text":"The sources of the SDF3 implementation can be found at https://github.com/metaborg/sdf/tree/master/org.metaborg.meta.lang.template : The SDF3 language implementation (SDF3 was called TemplateLang before and it has not been renamed everywhere yet)","title":"Source"},{"location":"references/syntax/configuration/","text":"Configuration \u00b6 When using SDF3 inside Spoofax, it is possible to specify different configuration options that. They allow using the new parser generator, specifying the shape of completion placeholders, or disable SDF altogether. These options should be specified in the metaborg.yaml file. For example, to disable SDF for the current project, use: language : sdf : enabled : false This configuration should be present when defining language components for a language that has SDF enabled. SDF3 allows generating placeholders for code completion. The default \"shape\" of placeholders is [[Symbol]] . However, it is possible to tweak this shape using the configuration below (the configuration for suffix is optional): language : sdf : placeholder : prefix : \"$\" suffix : \"$\" Currently, the path to the parse table is specified in the :file: Syntax.esv file, commonly as table: target/metaborg/sdf.tbl . When the ESV file does not contain this entry, it is also possible to specify the path to the parse table in the :file: metaborg.yaml file. This is useful when testing an external parse table, or using a parse table different from the one being generated in the project. In the example below, the table is loaded from the path tables/sdf.tbl . The same can be applied to the parse table used for code completion. language : sdf : parse-table : \"tables/sdf.tbl\" completion-parse-table : \"tables/sdf-completions.tbl\" In a Spoofax project, it is also possible to use SDF2 instead of SDF3. This enables SDF2 tools such as the SDF2 parenthesizer, signature generator, etc. For example: language : sdf : version : sdf2 By default SDF3 compilation works by generating SDF2 files, and depending on the SDF2 toolchain. However, a new (and experimental) parse table generator can be selected by writing: language : sdf : sdf2table : java This configuration disables the SDF2 generation, and may cause problems when defining grammars to use concrete syntax, since this feature is not supported yet by SDF3. However, the java parse table generator supports Unicode, whereas SDF2 generation does not. Furthermore, dynamic can be used instead of java , to enable lazy parse table generation, where the parse table is generated while the program is parsed. A namespaced grammar can be generated automatically from an SDF3 grammar. This namespacing is done by adding the language name to all module names and sort names. The generated grammar is put in src-gen/syntax . The configuration to enable this is: language : sdf : generate-namespaced : true Note that namespacing doesn't not handle imports of grammar files from other projects very well. JSGLR version \u00b6 An experimental new version of the SGLR parser implementation is available: JSGLR2. It supports parsing, imploding and syntax highlighting. Error reporting, recovery and completions are currently not supported. It can be enabled with: language : sdf : jsglr-version : v2 There are some extensions of JSGLR2 available. To use them, change the jsglr-version by replacing v2 with one of the following: data-dependent : Data-dependent JSGLR2 solves deep priority conflicts using data-dependent parsing, which does not require duplicating the grammar productions. incremental : Incremental JSGLR2 reuses previous parse results to speed up parsing. layout-sensitive : Layout-sensitive JSGLR2, see Layout Sensitivity . recovery : JSGLR2 with recovery tries to recover from parse errors. This extension is experimental. recovery-incremental : Incremental JSGLR2 with recovery. This extension is experimental. JSGLR2 logging \u00b6 Logging is available for JSGLR2. It can be enabled with: language : sdf : jsglr2-logging : all Since logging all parsing events is quite verbose, several other scopes are available in addition to the all option: none : Log nothing (default). minimal : Only log the start and end of a parse, including a measurement of total parse time (including imploding and tokenization). parsing : Log all standard parsing events (such as stack and parse forest operations, action execution, etc.) but no variant-specific events (e.g. related to recovery). recovery : Log the recovery iterations and the recovery productions that are applied. Todo Whenever changing any of these configurations, clean the project before rebuilding. Todo Write documentation on how to use SDF3 outside of Spoofax","title":"Configuration"},{"location":"references/syntax/configuration/#configuration","text":"When using SDF3 inside Spoofax, it is possible to specify different configuration options that. They allow using the new parser generator, specifying the shape of completion placeholders, or disable SDF altogether. These options should be specified in the metaborg.yaml file. For example, to disable SDF for the current project, use: language : sdf : enabled : false This configuration should be present when defining language components for a language that has SDF enabled. SDF3 allows generating placeholders for code completion. The default \"shape\" of placeholders is [[Symbol]] . However, it is possible to tweak this shape using the configuration below (the configuration for suffix is optional): language : sdf : placeholder : prefix : \"$\" suffix : \"$\" Currently, the path to the parse table is specified in the :file: Syntax.esv file, commonly as table: target/metaborg/sdf.tbl . When the ESV file does not contain this entry, it is also possible to specify the path to the parse table in the :file: metaborg.yaml file. This is useful when testing an external parse table, or using a parse table different from the one being generated in the project. In the example below, the table is loaded from the path tables/sdf.tbl . The same can be applied to the parse table used for code completion. language : sdf : parse-table : \"tables/sdf.tbl\" completion-parse-table : \"tables/sdf-completions.tbl\" In a Spoofax project, it is also possible to use SDF2 instead of SDF3. This enables SDF2 tools such as the SDF2 parenthesizer, signature generator, etc. For example: language : sdf : version : sdf2 By default SDF3 compilation works by generating SDF2 files, and depending on the SDF2 toolchain. However, a new (and experimental) parse table generator can be selected by writing: language : sdf : sdf2table : java This configuration disables the SDF2 generation, and may cause problems when defining grammars to use concrete syntax, since this feature is not supported yet by SDF3. However, the java parse table generator supports Unicode, whereas SDF2 generation does not. Furthermore, dynamic can be used instead of java , to enable lazy parse table generation, where the parse table is generated while the program is parsed. A namespaced grammar can be generated automatically from an SDF3 grammar. This namespacing is done by adding the language name to all module names and sort names. The generated grammar is put in src-gen/syntax . The configuration to enable this is: language : sdf : generate-namespaced : true Note that namespacing doesn't not handle imports of grammar files from other projects very well.","title":"Configuration"},{"location":"references/syntax/configuration/#jsglr-version","text":"An experimental new version of the SGLR parser implementation is available: JSGLR2. It supports parsing, imploding and syntax highlighting. Error reporting, recovery and completions are currently not supported. It can be enabled with: language : sdf : jsglr-version : v2 There are some extensions of JSGLR2 available. To use them, change the jsglr-version by replacing v2 with one of the following: data-dependent : Data-dependent JSGLR2 solves deep priority conflicts using data-dependent parsing, which does not require duplicating the grammar productions. incremental : Incremental JSGLR2 reuses previous parse results to speed up parsing. layout-sensitive : Layout-sensitive JSGLR2, see Layout Sensitivity . recovery : JSGLR2 with recovery tries to recover from parse errors. This extension is experimental. recovery-incremental : Incremental JSGLR2 with recovery. This extension is experimental.","title":"JSGLR version"},{"location":"references/syntax/configuration/#jsglr2-logging","text":"Logging is available for JSGLR2. It can be enabled with: language : sdf : jsglr2-logging : all Since logging all parsing events is quite verbose, several other scopes are available in addition to the all option: none : Log nothing (default). minimal : Only log the start and end of a parse, including a measurement of total parse time (including imploding and tokenization). parsing : Log all standard parsing events (such as stack and parse forest operations, action execution, etc.) but no variant-specific events (e.g. related to recovery). recovery : Log the recovery iterations and the recovery productions that are applied. Todo Whenever changing any of these configurations, clean the project before rebuilding. Todo Write documentation on how to use SDF3 outside of Spoofax","title":"JSGLR2 logging"},{"location":"references/syntax/context-free-syntax/","text":"Context-Free Syntax \u00b6 The context-free syntax describes the more high-level syntactic structure of sentences in a language. A context-free syntax contains a list of productions. Elements of the right-hand side of a context-free production are pre-processed in a normalization step before parser generation that adds the LAYOUT? symbol between any two symbols. Context-free syntax has the form: context-free syntax <Production>* An example production rule: context-free syntax Block.Block = \"{\" Statement* \"}\" SDF3 automatically allows for layout to be present between the symbols of a rule. This means that a fragment such as: { } will still be recognized as a block (assuming that the newline and line-feed characters are defined as layout).","title":"Context-Free Syntax"},{"location":"references/syntax/context-free-syntax/#context-free-syntax","text":"The context-free syntax describes the more high-level syntactic structure of sentences in a language. A context-free syntax contains a list of productions. Elements of the right-hand side of a context-free production are pre-processed in a normalization step before parser generation that adds the LAYOUT? symbol between any two symbols. Context-free syntax has the form: context-free syntax <Production>* An example production rule: context-free syntax Block.Block = \"{\" Statement* \"}\" SDF3 automatically allows for layout to be present between the symbols of a rule. This means that a fragment such as: { } will still be recognized as a block (assuming that the newline and line-feed characters are defined as layout).","title":"Context-Free Syntax"},{"location":"references/syntax/disambiguation/","text":"Disambiguation \u00b6 As we showed before, the semantics of SDF3 can be seen as two-staged. First, the grammar generates all possible derivations. Second, the disambiguation constructs remove a number of derivations that are not valid. Note that SDF3 actually performs some disambiguation when generating the parse table or during parsing. Rejections \u00b6 Rejections filter derivations. The semantics of a rejection is that the set of valid derivations for the left-hand side of the production will not contain the construction described on the right-hand side. In other words, the language defined by the sort on the left-hand side has become smaller, removing all the constructions generated by the rule on the right-hand side. Disambiguation by reject occurs at parse time (mostly). A rule can be marked as rejected by using the attribute {reject} after the rule: <Sort> = ... {reject} The {reject} attribute works well for lexical rejections, especially keyword reservation in the form of productions like: ID = \"keyword\" {reject} Preferences \u00b6 The preferences mechanism is another disambiguation filter that provides a post parse filter to parse forests. The attributes prefer and avoid are the only disambiguation constructs that compare alternative derivations after parsing. Warning prefer and avoid are deprecated and will be removed in a future version of Spoofax. The following definition assumes that derivations are represented using parse forests with \"packaged ambiguity nodes\". This means that whenever in a derivation there is a choice for several sub-derivations, at that point a special choice node (ambiguity constructor) is placed with all alternatives as children. We assume here that the ambiguity constructor is always placed at the location where a choice is needed, and not higher (i.e. a minimal parse forest representation). The preference mechanism compares the top nodes of each alternative: All alternative derivations that have avoid at the top node will be removed, but only if other alternatives derivations are there that do not have avoid at the top node. If there are derivations that have prefer at the top node, all other derivations that do not have prefer at the top node will be removed. The preference attribute can be used to handle the case when two productions can parse the same input. Here is an example:: Exp.FunctionApp = <<Expr> <Expr*>> Exp.Constructor = <<ID> <Expr>> {prefer} Priorities \u00b6 Priorities are one of SDF3's most often used disambiguation constructs. A priority section defines the relative priorities between productions. Priorities are a powerful disambiguation construct because it occurs at parse generation time. The idea behind the semantics of priorities is that productions with a higher priority \"bind stronger\" than productions with a lower priority. The essence of the priority disambiguation construct is that certain parse trees are removed from the \u2018forest\u2019 (the set of all possible parse trees that can be derived from a segment of code). The basic priority syntax looks like this: context-free priorities <ProductionRef> > <ProductionRef> Where <ProductionRef> can either be <Sort>.<Cons> or the entire production itself. Several priorities in a priority grammar are separated by commas. If more productions have the same priority they may be grouped between curly braces on each side of the > sign. context-free priorities {<ProductionRef> <ProductionRef>} > <ProductionRef>, <ProductionRef> > <ProductionRef> By default, the priority relation is automatically transitively closed (i.e. if A > B and B > C then A > C). To specify a non-transitive priority relation it is necessary to include a dot before the > sign ( .> ). SDF3 provides safe disambiguation, meaning that priority relations only remove ambiguous derivations. Furthermore, SDF3 also allows tree filtering by means of indexed priorities such as: context-free priorities <ProductionRef> <idx> > <ProductionRef> where the symbol at position idx (starting with 0) in the first production should not derive the second production. An example defining priorities for the addition, subtraction and multiplication operators is listed below. Because addition and subtraction have the same priority, the are grouped together between brackets. context-free priorities {Exp.Times} > {Exp.Plus Exp.Minus} Associativity \u00b6 Like with priorities, the essence of the associativity attribute is that certain parse trees are removed from the \u2018forest\u2019. The left associativity attribute on a production P filters all occurrences of P as a direct child of P in the right-most argument. This implies that left is only effective on productions that are recursive on the right (as in A B C -> C ). The right associativity attribute on a production P filters all occurrences of P as a direct child of P in the left-most argument. This implies that right is only effective on productions that are recursive on the left ( as in C A B -> C ). The non-assoc associativity attribute on a production P filters all occurrences of P as a direct child of P in any argument. This implement that non-assoc is only effective if a production is indeed recursive (as in A C B -> C ). The assoc attribute means the same as left Associativity declarations occur in two places in SDF3. The first is as production attributes. The second is as associativity declarations in priority groups. An example on how to mention associativity as a production attribute is given below: Exp.Plus = <<Exp> + <Exp>> {left} In priority groups, the associativity has the same semantics as the associativity attributes, except that the filter refers to more nested productions instead of a recursive nesting of one production. The group associativity attribute works pairwise and commutative on all combinations of productions in the group. If there is only one element in the group the attribute is reflexive, otherwise it is not reflexive. context-free priorities {left: Exp.Times} > {left: Exp.Plus Exp.Minus} Restrictions \u00b6 The notion of restrictions enables the formulation of lexical disambiguation strategies. Examples are \"shift before reduce\" and \"longest match\". A restriction filters applications of productions for certain non-terminals if the following character (lookahead) is in a certain class. The result is that specific symbols may not be followed by a character from a given character class. A lookahead may consist of more than one character class (multiple lookahead). Restrictions come in two flavors: lexical restrictions that apply to lexical non-terminals context-free restrictions that apply to context-free non-terminals. The general form of a restriction is: <Symbol>+ -/- <Lookaheads> The semantics of a restriction is to remove all derivations that produce a certain <Symbol> . The condition for this removal is that the derivation tree for that symbol is followed immediately by something that matches the lookahead declaration. Note that to be able to check this condition, one must look past derivations that produce the empty language, until the characters to the right of the filtered symbol are found. Also, for finding multiple lookahead matches, one must ignore nullable sub-trees that may occur in the middle of the matched lookahead. In case of lexical restrictions <Symbol> may be either a literal or sort. In case of context-free restrictions only a sort or symbol is allowed. The restriction operator -/- should be read as may not be followed by. Before the restriction operator -/- a list of symbols is given for which the restriction holds. As an example, the following restriction rule implements the \u201clongest match\u201d policy: an identifier can not be followed by an alpha-numeric character. ID -/- [a-zA-Z0-9\\_]","title":"Disambiguation"},{"location":"references/syntax/disambiguation/#disambiguation","text":"As we showed before, the semantics of SDF3 can be seen as two-staged. First, the grammar generates all possible derivations. Second, the disambiguation constructs remove a number of derivations that are not valid. Note that SDF3 actually performs some disambiguation when generating the parse table or during parsing.","title":"Disambiguation"},{"location":"references/syntax/disambiguation/#rejections","text":"Rejections filter derivations. The semantics of a rejection is that the set of valid derivations for the left-hand side of the production will not contain the construction described on the right-hand side. In other words, the language defined by the sort on the left-hand side has become smaller, removing all the constructions generated by the rule on the right-hand side. Disambiguation by reject occurs at parse time (mostly). A rule can be marked as rejected by using the attribute {reject} after the rule: <Sort> = ... {reject} The {reject} attribute works well for lexical rejections, especially keyword reservation in the form of productions like: ID = \"keyword\" {reject}","title":"Rejections"},{"location":"references/syntax/disambiguation/#preferences","text":"The preferences mechanism is another disambiguation filter that provides a post parse filter to parse forests. The attributes prefer and avoid are the only disambiguation constructs that compare alternative derivations after parsing. Warning prefer and avoid are deprecated and will be removed in a future version of Spoofax. The following definition assumes that derivations are represented using parse forests with \"packaged ambiguity nodes\". This means that whenever in a derivation there is a choice for several sub-derivations, at that point a special choice node (ambiguity constructor) is placed with all alternatives as children. We assume here that the ambiguity constructor is always placed at the location where a choice is needed, and not higher (i.e. a minimal parse forest representation). The preference mechanism compares the top nodes of each alternative: All alternative derivations that have avoid at the top node will be removed, but only if other alternatives derivations are there that do not have avoid at the top node. If there are derivations that have prefer at the top node, all other derivations that do not have prefer at the top node will be removed. The preference attribute can be used to handle the case when two productions can parse the same input. Here is an example:: Exp.FunctionApp = <<Expr> <Expr*>> Exp.Constructor = <<ID> <Expr>> {prefer}","title":"Preferences"},{"location":"references/syntax/disambiguation/#priorities","text":"Priorities are one of SDF3's most often used disambiguation constructs. A priority section defines the relative priorities between productions. Priorities are a powerful disambiguation construct because it occurs at parse generation time. The idea behind the semantics of priorities is that productions with a higher priority \"bind stronger\" than productions with a lower priority. The essence of the priority disambiguation construct is that certain parse trees are removed from the \u2018forest\u2019 (the set of all possible parse trees that can be derived from a segment of code). The basic priority syntax looks like this: context-free priorities <ProductionRef> > <ProductionRef> Where <ProductionRef> can either be <Sort>.<Cons> or the entire production itself. Several priorities in a priority grammar are separated by commas. If more productions have the same priority they may be grouped between curly braces on each side of the > sign. context-free priorities {<ProductionRef> <ProductionRef>} > <ProductionRef>, <ProductionRef> > <ProductionRef> By default, the priority relation is automatically transitively closed (i.e. if A > B and B > C then A > C). To specify a non-transitive priority relation it is necessary to include a dot before the > sign ( .> ). SDF3 provides safe disambiguation, meaning that priority relations only remove ambiguous derivations. Furthermore, SDF3 also allows tree filtering by means of indexed priorities such as: context-free priorities <ProductionRef> <idx> > <ProductionRef> where the symbol at position idx (starting with 0) in the first production should not derive the second production. An example defining priorities for the addition, subtraction and multiplication operators is listed below. Because addition and subtraction have the same priority, the are grouped together between brackets. context-free priorities {Exp.Times} > {Exp.Plus Exp.Minus}","title":"Priorities"},{"location":"references/syntax/disambiguation/#associativity","text":"Like with priorities, the essence of the associativity attribute is that certain parse trees are removed from the \u2018forest\u2019. The left associativity attribute on a production P filters all occurrences of P as a direct child of P in the right-most argument. This implies that left is only effective on productions that are recursive on the right (as in A B C -> C ). The right associativity attribute on a production P filters all occurrences of P as a direct child of P in the left-most argument. This implies that right is only effective on productions that are recursive on the left ( as in C A B -> C ). The non-assoc associativity attribute on a production P filters all occurrences of P as a direct child of P in any argument. This implement that non-assoc is only effective if a production is indeed recursive (as in A C B -> C ). The assoc attribute means the same as left Associativity declarations occur in two places in SDF3. The first is as production attributes. The second is as associativity declarations in priority groups. An example on how to mention associativity as a production attribute is given below: Exp.Plus = <<Exp> + <Exp>> {left} In priority groups, the associativity has the same semantics as the associativity attributes, except that the filter refers to more nested productions instead of a recursive nesting of one production. The group associativity attribute works pairwise and commutative on all combinations of productions in the group. If there is only one element in the group the attribute is reflexive, otherwise it is not reflexive. context-free priorities {left: Exp.Times} > {left: Exp.Plus Exp.Minus}","title":"Associativity"},{"location":"references/syntax/disambiguation/#restrictions","text":"The notion of restrictions enables the formulation of lexical disambiguation strategies. Examples are \"shift before reduce\" and \"longest match\". A restriction filters applications of productions for certain non-terminals if the following character (lookahead) is in a certain class. The result is that specific symbols may not be followed by a character from a given character class. A lookahead may consist of more than one character class (multiple lookahead). Restrictions come in two flavors: lexical restrictions that apply to lexical non-terminals context-free restrictions that apply to context-free non-terminals. The general form of a restriction is: <Symbol>+ -/- <Lookaheads> The semantics of a restriction is to remove all derivations that produce a certain <Symbol> . The condition for this removal is that the derivation tree for that symbol is followed immediately by something that matches the lookahead declaration. Note that to be able to check this condition, one must look past derivations that produce the empty language, until the characters to the right of the filtered symbol are found. Also, for finding multiple lookahead matches, one must ignore nullable sub-trees that may occur in the middle of the matched lookahead. In case of lexical restrictions <Symbol> may be either a literal or sort. In case of context-free restrictions only a sort or symbol is allowed. The restriction operator -/- should be read as may not be followed by. Before the restriction operator -/- a list of symbols is given for which the restriction holds. As an example, the following restriction rule implements the \u201clongest match\u201d policy: an identifier can not be followed by an alpha-numeric character. ID -/- [a-zA-Z0-9\\_]","title":"Restrictions"},{"location":"references/syntax/kernel-syntax/","text":"Kernel Syntax \u00b6 The rules from context-free and lexical syntax are translated into kernel syntax by the SDF3 normalizer. When writing kernel syntax, one has more control over the layout between symbols of a production. As part of normalization, among other things, SDF3 renames each symbol in the lexical syntax to include the suffix -LEX and each symbol in the context-free syntax to include the suffix -CF . For example, the two productions lexical syntax BinaryConst = [0-1]+ context-free syntax Block.Block = \"{\" Statement* \"}\" written in kernel syntax look like syntax Block-CF.Block = \"{\" LAYOUT?-CF Statement*-CF LAYOUT?-CF \"}\" BinaryConst-LEX = [0-1]+ Literals and character classes are lexical by definition, thus they do not need any suffix. Note that each symbol in kernel syntax is uniquely identified by its full name including -CF and -LEX . That is, two symbols named Block-CF and Block are different, if both occur in kernel syntax. However, Block-CF is the same symbol as Block if the latter appears in a context-free syntax section. As mentioned before, layout can only occur in between symbols if explicitly specified. For example, the production syntax Block-CF.Block = \"{\" Statement*-CF LAYOUT?-CF \"}\" does not allow layout to occur in between the opening bracket and the list of statements. This means that a fragment such as: { x = 1; } would not be recognized as a block.","title":"Kernel Syntax"},{"location":"references/syntax/kernel-syntax/#kernel-syntax","text":"The rules from context-free and lexical syntax are translated into kernel syntax by the SDF3 normalizer. When writing kernel syntax, one has more control over the layout between symbols of a production. As part of normalization, among other things, SDF3 renames each symbol in the lexical syntax to include the suffix -LEX and each symbol in the context-free syntax to include the suffix -CF . For example, the two productions lexical syntax BinaryConst = [0-1]+ context-free syntax Block.Block = \"{\" Statement* \"}\" written in kernel syntax look like syntax Block-CF.Block = \"{\" LAYOUT?-CF Statement*-CF LAYOUT?-CF \"}\" BinaryConst-LEX = [0-1]+ Literals and character classes are lexical by definition, thus they do not need any suffix. Note that each symbol in kernel syntax is uniquely identified by its full name including -CF and -LEX . That is, two symbols named Block-CF and Block are different, if both occur in kernel syntax. However, Block-CF is the same symbol as Block if the latter appears in a context-free syntax section. As mentioned before, layout can only occur in between symbols if explicitly specified. For example, the production syntax Block-CF.Block = \"{\" Statement*-CF LAYOUT?-CF \"}\" does not allow layout to occur in between the opening bracket and the list of statements. This means that a fragment such as: { x = 1; } would not be recognized as a block.","title":"Kernel Syntax"},{"location":"references/syntax/layout-sensitivity/","text":"Layout Sensitivity \u00b6 SDF3 supports definition of layout sensitive syntax by means of low-level layout constraints and high-level layout declarations . Note If you want to use layout constraints or layout declarations, you should specify the jsglr-version: layout-sensitive parameter for SDF3, see configuration . Layout Constraints \u00b6 While we haven't covered layout constraints in this documentation, the paper [^1] describes the concepts. Layout Declarations \u00b6 In the paper [^1], the authors describe layout constraints in terms of restrictions involving the position of the subtree involved in the constraint ( 0 , 1 , ...), token selectors ( first , left , last and right ), and position selectors as lines and columns ( line and col ). This mechanism allows writing layout constraints to express alignment, offside and indentation rules, but writing such constraints is rather cumbersome and error prone. Alternatively, one may write layout constraints using layout declarations , which are more declarative specifications and abstract over lines, columns and token selectors as the original layout constraints from [^1]. Tree selectors \u00b6 To specify which trees should be subject to a layout constraint, one may use: tree positions, SDF3 labeled non-terminals, or unique literals that occurs in the production. For example: context-free syntax Stmt.IfElse = \"if\" Exp \"then\" Stmts \"else\" else:Stmts {layout( indent \"if\" 3, else && align 3 else && align \"if\" \"else\" )} In the layout constraint for the production above, else refers to the tree for the labeled non-terminal else:Stmts , \"if\" refers to the tree corresponding to the \"if\" literal and the number 3 correspond to the tree at position 3 in the parse tree (starting at 0, ignoring trees for LAYOUT? ). align \u00b6 The layout constraint layout(align x y1, ..., yn) specifies that the trees indicated by the tree selectors yi should be aligned with the tree indicated by the tree selector x , i.e., all these trees should start in the same column. For example, if we consider the production above, the following program is correct according to the align constraints: if x < 0 then \u00b7\u00b7 x = 0 else \u00b7\u00b7 y = 1 Whereas, the following program is incorrect because neither the if and else keyword align ( align \"if\" \"else\" ), nor the statements in the branches ( align 3 else ): if x < 0 then \u00b7\u00b7 x = 0 \u00b7 else \u00b7\u00b7\u00b7 y = 1 align-list \u00b6 The constraint align-list can be used to indicate that all subtrees within a list should be aligned. That is, a constraint layout(align-list x) , where x is a tree selector for a list subtree, can be used to enforce such constraint. For example, consider the following production and its layout constraint: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( align-list then )} This constraint indicates that statements inside the list should be aligned. Therefore, the following program is correct according to this constraint: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2 And the following program is invalid, as the second statement is misaligned: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2 offside \u00b6 The offside rule is very common in layout-sensitive languages. It states that all lines after the first one should be further to the right compared to the first line. For a description of how the offside rule can be modelled with layout constraints, refer to :cite: s-ErdwegRKO12 . An example of a declarative specification of the offside rule can be seen in the production below: context-free syntax Stmt.Assign = <<ID> = <Exp>> {layout(offside 3)} The layout constraint specifies that when the expression in the statement spams multiple lines, all following lines should be indented with respect to the column where the expression started. For example, the following program is valid according to this constraint: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7\u00b7 + 2 However, the following program is not valid, as the second line of the expression starts at the same column as the first line: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7 + 2 Note that if the expression is written on a single line, the constraint is also verified. That is, the following program successfully parses: x = 4 * 10 + 2 It is also possible to use the offside relation on different trees. For example, consider the constraint in the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( offside \"if\" then )} This constraint states that all lines (except the first) of the statements in the then branch should be indented with respect to the if literal. Thus, the following program is invalid according to this layout constraint, because the statement x = 2 should be indented with relation to the topmost if . if x < 0 then \u00b7\u00b7 if y < 0 then x = 2 In general, an offside constraint involving more than a single tree is combined with indent constraint to enforce that the column of the first and all subsequent lines should be indented. indent \u00b6 An indent constraint indicates that the column of the first line of a certain tree should be further to the right with respect to another tree. For example, consider the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then )} This constraint indicates that the first line of the list of statements should be indented with respect to the if literal. Thus, according to this constraint the following program is valid: if x < 0 then \u00b7\u00b7 x = 2 Note that if the list of statements in the then branch spams multiple lines, the constraint does not apply to its subsequent lines. For example, consider the following program: if x < 0 then \u00b7\u00b7 x = 2 + 10 * 4 y = 3 This program is still valid, since the column of the first line of the first assignment is indented with respect to the if literal. To indicate that the first and all subsequent lines should be indented, an offside constraint should also be included. context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then && offside \"if\" then )} With this constraint, the remainder of the expression * 4 should also be further to the right compared to the \"if\" literal. The following program is correct according to these two constraints, since the second line of the first assignment and the second assignment are also indented with respect to the if literal: if x < 0 then \u00b7\u00b7 x = 2 + 10 \u00b7 * 4 \u00b7 y = 3 Finally, all these layout declarations can be ignored by the parser and used only when generating the pretty-printer. To do that, prefix the constraint with pp- writing, for example, pp-offside or pp-align .","title":"Layout Sensitivity"},{"location":"references/syntax/layout-sensitivity/#layout-sensitivity","text":"SDF3 supports definition of layout sensitive syntax by means of low-level layout constraints and high-level layout declarations . Note If you want to use layout constraints or layout declarations, you should specify the jsglr-version: layout-sensitive parameter for SDF3, see configuration .","title":"Layout Sensitivity"},{"location":"references/syntax/layout-sensitivity/#layout-constraints","text":"While we haven't covered layout constraints in this documentation, the paper [^1] describes the concepts.","title":"Layout Constraints"},{"location":"references/syntax/layout-sensitivity/#layout-declarations","text":"In the paper [^1], the authors describe layout constraints in terms of restrictions involving the position of the subtree involved in the constraint ( 0 , 1 , ...), token selectors ( first , left , last and right ), and position selectors as lines and columns ( line and col ). This mechanism allows writing layout constraints to express alignment, offside and indentation rules, but writing such constraints is rather cumbersome and error prone. Alternatively, one may write layout constraints using layout declarations , which are more declarative specifications and abstract over lines, columns and token selectors as the original layout constraints from [^1].","title":"Layout Declarations"},{"location":"references/syntax/layout-sensitivity/#tree-selectors","text":"To specify which trees should be subject to a layout constraint, one may use: tree positions, SDF3 labeled non-terminals, or unique literals that occurs in the production. For example: context-free syntax Stmt.IfElse = \"if\" Exp \"then\" Stmts \"else\" else:Stmts {layout( indent \"if\" 3, else && align 3 else && align \"if\" \"else\" )} In the layout constraint for the production above, else refers to the tree for the labeled non-terminal else:Stmts , \"if\" refers to the tree corresponding to the \"if\" literal and the number 3 correspond to the tree at position 3 in the parse tree (starting at 0, ignoring trees for LAYOUT? ).","title":"Tree selectors"},{"location":"references/syntax/layout-sensitivity/#align","text":"The layout constraint layout(align x y1, ..., yn) specifies that the trees indicated by the tree selectors yi should be aligned with the tree indicated by the tree selector x , i.e., all these trees should start in the same column. For example, if we consider the production above, the following program is correct according to the align constraints: if x < 0 then \u00b7\u00b7 x = 0 else \u00b7\u00b7 y = 1 Whereas, the following program is incorrect because neither the if and else keyword align ( align \"if\" \"else\" ), nor the statements in the branches ( align 3 else ): if x < 0 then \u00b7\u00b7 x = 0 \u00b7 else \u00b7\u00b7\u00b7 y = 1","title":"align"},{"location":"references/syntax/layout-sensitivity/#align-list","text":"The constraint align-list can be used to indicate that all subtrees within a list should be aligned. That is, a constraint layout(align-list x) , where x is a tree selector for a list subtree, can be used to enforce such constraint. For example, consider the following production and its layout constraint: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( align-list then )} This constraint indicates that statements inside the list should be aligned. Therefore, the following program is correct according to this constraint: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2 And the following program is invalid, as the second statement is misaligned: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2","title":"align-list"},{"location":"references/syntax/layout-sensitivity/#offside","text":"The offside rule is very common in layout-sensitive languages. It states that all lines after the first one should be further to the right compared to the first line. For a description of how the offside rule can be modelled with layout constraints, refer to :cite: s-ErdwegRKO12 . An example of a declarative specification of the offside rule can be seen in the production below: context-free syntax Stmt.Assign = <<ID> = <Exp>> {layout(offside 3)} The layout constraint specifies that when the expression in the statement spams multiple lines, all following lines should be indented with respect to the column where the expression started. For example, the following program is valid according to this constraint: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7\u00b7 + 2 However, the following program is not valid, as the second line of the expression starts at the same column as the first line: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7 + 2 Note that if the expression is written on a single line, the constraint is also verified. That is, the following program successfully parses: x = 4 * 10 + 2 It is also possible to use the offside relation on different trees. For example, consider the constraint in the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( offside \"if\" then )} This constraint states that all lines (except the first) of the statements in the then branch should be indented with respect to the if literal. Thus, the following program is invalid according to this layout constraint, because the statement x = 2 should be indented with relation to the topmost if . if x < 0 then \u00b7\u00b7 if y < 0 then x = 2 In general, an offside constraint involving more than a single tree is combined with indent constraint to enforce that the column of the first and all subsequent lines should be indented.","title":"offside"},{"location":"references/syntax/layout-sensitivity/#indent","text":"An indent constraint indicates that the column of the first line of a certain tree should be further to the right with respect to another tree. For example, consider the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then )} This constraint indicates that the first line of the list of statements should be indented with respect to the if literal. Thus, according to this constraint the following program is valid: if x < 0 then \u00b7\u00b7 x = 2 Note that if the list of statements in the then branch spams multiple lines, the constraint does not apply to its subsequent lines. For example, consider the following program: if x < 0 then \u00b7\u00b7 x = 2 + 10 * 4 y = 3 This program is still valid, since the column of the first line of the first assignment is indented with respect to the if literal. To indicate that the first and all subsequent lines should be indented, an offside constraint should also be included. context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then && offside \"if\" then )} With this constraint, the remainder of the expression * 4 should also be further to the right compared to the \"if\" literal. The following program is correct according to these two constraints, since the second line of the first assignment and the second assignment are also indented with respect to the if literal: if x < 0 then \u00b7\u00b7 x = 2 + 10 \u00b7 * 4 \u00b7 y = 3 Finally, all these layout declarations can be ignored by the parser and used only when generating the pretty-printer. To do that, prefix the constraint with pp- writing, for example, pp-offside or pp-align .","title":"indent"},{"location":"references/syntax/lexical-syntax/","text":"Lexical Syntax \u00b6 The lexical syntax usually describes the low level structure of programs (often referred to as lexical tokens). However, in SDF3, the token concept is not really relevant, since only character classes are terminals. The lexical syntax sections in SDF3 are simply a convenient notation for the low level syntax of a language. The LAYOUT symbol should also be defined in a lexical syntax section. A lexical syntax consists of a list of productions. Lexical syntax is described as follows:: lexical syntax <Production>* An example of a production in lexical syntax: lexical syntax BinaryConst = [0-1]+","title":"Lexical Syntax"},{"location":"references/syntax/lexical-syntax/#lexical-syntax","text":"The lexical syntax usually describes the low level structure of programs (often referred to as lexical tokens). However, in SDF3, the token concept is not really relevant, since only character classes are terminals. The lexical syntax sections in SDF3 are simply a convenient notation for the low level syntax of a language. The LAYOUT symbol should also be defined in a lexical syntax section. A lexical syntax consists of a list of productions. Lexical syntax is described as follows:: lexical syntax <Production>* An example of a production in lexical syntax: lexical syntax BinaryConst = [0-1]+","title":"Lexical Syntax"},{"location":"references/syntax/modules/","text":"Modules \u00b6 An SDF3 specification consists of a number of module declarations. Each module defines sections and may import other modules. Imports \u00b6 Modules may import other modules for reuse or separation of concerns. A module may extend the definition of a non-terminal in another module. A module may compose the definition of a language by importing the parts of the language. The structure of a module is as follows: module <ModuleName> <ImportSection>* <Section>* The module keyword is followed by the module name, then a series of imports can be made, followed by sections that contain the actual definition of the syntax. An import section is structured as follows: imports <ModuleName>* Note that SDF3 does not support parameterized modules. Sections \u00b6 A SDF3 module may constitute of zero or more sections. All sections contribute to the final grammar that defines a language: sorts , lexical sorts , context-free sorts (see Sorts ) lexical syntax (see Lexical Syntax ) context-free syntax (see Context-Free Syntax ) syntax (see Kernel Syntax ) lexical start-symbols , context-free start-symbols , start-symbols (see Start Symbols ) context-free priorities , priorities (see Disambiguation ) template options (see Templates )","title":"Modules"},{"location":"references/syntax/modules/#modules","text":"An SDF3 specification consists of a number of module declarations. Each module defines sections and may import other modules.","title":"Modules"},{"location":"references/syntax/modules/#imports","text":"Modules may import other modules for reuse or separation of concerns. A module may extend the definition of a non-terminal in another module. A module may compose the definition of a language by importing the parts of the language. The structure of a module is as follows: module <ModuleName> <ImportSection>* <Section>* The module keyword is followed by the module name, then a series of imports can be made, followed by sections that contain the actual definition of the syntax. An import section is structured as follows: imports <ModuleName>* Note that SDF3 does not support parameterized modules.","title":"Imports"},{"location":"references/syntax/modules/#sections","text":"A SDF3 module may constitute of zero or more sections. All sections contribute to the final grammar that defines a language: sorts , lexical sorts , context-free sorts (see Sorts ) lexical syntax (see Lexical Syntax ) context-free syntax (see Context-Free Syntax ) syntax (see Kernel Syntax ) lexical start-symbols , context-free start-symbols , start-symbols (see Start Symbols ) context-free priorities , priorities (see Disambiguation ) template options (see Templates )","title":"Sections"},{"location":"references/syntax/productions/","text":"Productions \u00b6 The basic building block of syntax sections is the production. The left-hand side of a regular production rule can be either just a symbol or a symbol followed by . and a constructor name. The right-hand side consists of zero or more symbols. Both sides are separated by = : <Symbol> = <Symbol>* <Symbol>.<Constructor> = <Symbol>* A production is read as the definition. The symbol on the left-hand side is defined by the right-hand side of the production. Productions are used to describe lexical as well as context-free syntax. Productions may also occur in priority sections, but might also be referred to by its <Symbol>.<Constructor> . All productions with the same symbol together define the alternatives for that symbol. Attributes \u00b6 The definition of lexical and context-free productions may be followed by attributes that define additional (syntactic or semantic) properties of that production. The attributes are written between curly brackets after the right-hand side of a production. If a production has more than one attribute they are separated by commas. Attributes have thus the following form: <Sort> = <Symbol>* { <Attribute1>, <Attribute2>, ...} <Sort>.<Constructor> = <Symbol>* { <Attribute1>, <Attribute2>, ...} The following syntax-related attributes exist: bracket is an important attribute in combination with priorities. For example, the sdf2parenthesize tool uses the bracket attribute to find productions to add to a parse tree before pretty printing (when the tree violates priority constraints). Note that most of these tools demand the production with a bracket attribute to have the shape: X = \"(\" X \")\" {bracket} with any kind of bracket syntax but the X being the same symbol on the left-hand side and the right-hand side. The connection with priorities and associativity is that when a non-terminal is disambiguated using either of them, a production rule with the bracket attribute is probably also needed. left , right , non-assoc , assoc are disambiguation constructs used to define the associativity of productions. See Disambiguation . prefer and avoid are deprecated disambiguation constructs to define preference of one derivation over others. See Disambiguation . reject is a disambiguation construct that implements language difference. It is used for keyword reservation. See Disambiguation .","title":"Productions"},{"location":"references/syntax/productions/#productions","text":"The basic building block of syntax sections is the production. The left-hand side of a regular production rule can be either just a symbol or a symbol followed by . and a constructor name. The right-hand side consists of zero or more symbols. Both sides are separated by = : <Symbol> = <Symbol>* <Symbol>.<Constructor> = <Symbol>* A production is read as the definition. The symbol on the left-hand side is defined by the right-hand side of the production. Productions are used to describe lexical as well as context-free syntax. Productions may also occur in priority sections, but might also be referred to by its <Symbol>.<Constructor> . All productions with the same symbol together define the alternatives for that symbol.","title":"Productions"},{"location":"references/syntax/productions/#attributes","text":"The definition of lexical and context-free productions may be followed by attributes that define additional (syntactic or semantic) properties of that production. The attributes are written between curly brackets after the right-hand side of a production. If a production has more than one attribute they are separated by commas. Attributes have thus the following form: <Sort> = <Symbol>* { <Attribute1>, <Attribute2>, ...} <Sort>.<Constructor> = <Symbol>* { <Attribute1>, <Attribute2>, ...} The following syntax-related attributes exist: bracket is an important attribute in combination with priorities. For example, the sdf2parenthesize tool uses the bracket attribute to find productions to add to a parse tree before pretty printing (when the tree violates priority constraints). Note that most of these tools demand the production with a bracket attribute to have the shape: X = \"(\" X \")\" {bracket} with any kind of bracket syntax but the X being the same symbol on the left-hand side and the right-hand side. The connection with priorities and associativity is that when a non-terminal is disambiguated using either of them, a production rule with the bracket attribute is probably also needed. left , right , non-assoc , assoc are disambiguation constructs used to define the associativity of productions. See Disambiguation . prefer and avoid are deprecated disambiguation constructs to define preference of one derivation over others. See Disambiguation . reject is a disambiguation construct that implements language difference. It is used for keyword reservation. See Disambiguation .","title":"Attributes"},{"location":"references/syntax/recovery/","text":"Recovery \u00b6 SDF3 automatically generates permissive grammars for supporting error-recovery parsing. Handwritten recovery rules can be added to tweak the permissive grammar.","title":"Recovery"},{"location":"references/syntax/recovery/#recovery","text":"SDF3 automatically generates permissive grammars for supporting error-recovery parsing. Handwritten recovery rules can be added to tweak the permissive grammar.","title":"Recovery"},{"location":"references/syntax/start-symbols/","text":"Start Symbols \u00b6 The lexical or context-free start symbols sections explicitly define the symbols which will serve as start symbols when parsing terms. If no start symbols are defined it is not possible to recognize terms. This has the effect that input sentences corresponding to these symbols can be parsed. So, if we want to recognize boolean terms we have to define explicitly the sort Boolean as a start symbol in the module Booleans . Any symbol and also lists, optionals, etc., can serve as a start-symbol. A definition of lexical start symbols looks like: lexical start-symbols <Symbol>* While context-free start symbols are defined as: context-free start-symbols <Symbol>* SDF3 also supports kernel start-symbols: start-symbols <Symbol>* In contrast to lexical and kernel start-symbols, context-free start symbols can be surrounded by optional layout. A lexical start-symbol should have been defined by a production in the lexical syntax; a context-free symbol should have been defined in the context-free syntax. Both symbols can also be defined in kernel syntax using the suffix -LEX or -CF .","title":"Start Symbols"},{"location":"references/syntax/start-symbols/#start-symbols","text":"The lexical or context-free start symbols sections explicitly define the symbols which will serve as start symbols when parsing terms. If no start symbols are defined it is not possible to recognize terms. This has the effect that input sentences corresponding to these symbols can be parsed. So, if we want to recognize boolean terms we have to define explicitly the sort Boolean as a start symbol in the module Booleans . Any symbol and also lists, optionals, etc., can serve as a start-symbol. A definition of lexical start symbols looks like: lexical start-symbols <Symbol>* While context-free start symbols are defined as: context-free start-symbols <Symbol>* SDF3 also supports kernel start-symbols: start-symbols <Symbol>* In contrast to lexical and kernel start-symbols, context-free start symbols can be surrounded by optional layout. A lexical start-symbol should have been defined by a production in the lexical syntax; a context-free symbol should have been defined in the context-free syntax. Both symbols can also be defined in kernel syntax using the suffix -LEX or -CF .","title":"Start Symbols"},{"location":"references/syntax/symbols/","text":"Symbols \u00b6 The building block of SDF3 productions is a symbol. SDF3 symbols can be compared to terminals and non-terminals in other grammar formalisms. The elementary symbols are character classes, literals, and sorts. Intrinsically, only character classes are real terminal symbols. All other symbols represent non-terminals. SDF3 also support symbols that capture BNF-like notation such as lists, optionals, alternatives, and sequences. Note that these symbols are also non-terminals, and are just shorthands for common structures present in context-free grammars. Character classes \u00b6 Character classes occur only in lexical syntax and are enclosed by [ and ] . A character class consists of a list of zero or more characters (which stand for themselves) such as [x] to represent the character x , or character ranges, as an abbreviation for all the characters in the range such as [0-9] representing 0 , 1 , ..., 9 . A valid range consists of [c1-c2] , where the character c2 has a higher ASCII code than c1 . Note that nested character classes can also be concatenated within the same character class symbol, for example [c1c2-c3c4-c5] includes the characters c1 and the ranges c2-c3 , c4-c5 . In this case, the nested character classes do not need to be ordered, as SDF3 orders them when performing a normalization step. Escaped Characters : SDF3 uses a backslash ( \\ ) as a escape for the quoting of special characters. One should use \\c whenever c is not a digit or a letter in a character class. Arbitrary Unicode code points can be included in a character class by writing an escaped integer, which is particularly useful for representing characters outside the printable ASCII range. The integer can be a binary, octal, decimal, or hexadecimal number, for example: \\0b101010 , \\052 , \\42 , and \\0x2A all represent the code point 42, or the '*' character. Additionally, special ASCII characters are represented by: \\t : horizontal tabulation \\n : newline character \\v : vertical tabulation \\f : form feed \\r : carriage return Character Class Operators : SDF3 provides the following operators for character classes: (complement) ~ : Accepts all the characters that are not in the original class. (difference) / : Accepts all the characters in the first class unless they are in a second class. (union) \\/ : Accepts all the characters in either character classes. (intersection) /\\ : Accepts all the characters that are accepted by both character classes. Note that the first operator is unary and the other ones are left associative binary operators. Furthermore, such operators are not applicable to other symbols in general. Literals \u00b6 A literal symbol defines a fixed length word. This usually corresponds to a terminal symbol in ordinary context-free grammars, for example \"true\" or \"+\" . Literals must always be quoted and consist of (possibly escaped) ASCII characters. As literals are also regular non-terminals, SDF3 automatically generates productions for them in terms of terminal symbols. \"definition\" = [d][e][f][i][n][i][t][i][o][n] Note that the production above defines a case-sensitive implementation of the defined literal. Case-insensitive literals are defined using single-quoted strings as in 'true' or 'else' . SDF3 generates a different production for case-insensitive literals as 'definition' = [dD][eE][fF][iI][nN][iI][tT][iI][oO][nN] The literal above accepts case-insensitive inputs such as definition , DEFINITION , DeFiNiTiOn or defINITION . Sorts \u00b6 A sort corresponds to a plain non-terminal, e.g. Statement or Exp . Sort names start with a capital letter and may be followed by letters, digits, hyphens, or underscores. Note that unlike SDF2, SDF3 does not support parameterized sorts (yet!). Sorts are declared by listing their name in the appropriate sorts section, which have the following forms. For context-free sorts: context-free sorts <Sort>* For lexical sorts: lexical sorts <Sort>* SDF3 also supports kernel sorts: sorts <Sort>* Note Kernel sorts should be suffixed with -CF or -LEX , depending on whether they are context-free sorts or lexical sorts. When a sort in a sorts block does not have a suffix, it is treated as a context-free sort. Writing a sort in these sections only indicates that a sort has been declared, even if it does not have any explicit production visible. Optionals \u00b6 SDF3 provides a shorthand for describing zero or exactly one occurrence of a sort by appending the sort with ? . For example, the sort Extends? can be parsed as Extends or without consuming any input. Internally, SDF3 generates the following productions after normalizing the grammar:: Extends?.None = Extends?.Some = Extends Note that using ? adds the constructors None and Some to the final abstract syntax tree. Lists \u00b6 Lists symbols as the name says, indicate that a symbol should occur several times. In this way, it is also possible to construct flat structures to represent them. SDF3 provides support for two types of lists, with and without separators. Furthermore, it is also possible to indicate whether a list can be empty ( * ) or should have at least one element ( + ). For example, a list Statement* indicates zero or more Statement , whereas a list with separator {ID \",\"}+ indicates one or more ID separated by , . Note that SDF3 only supports literal symbols as separators. Again, SDF3 generates the following productions to represent lists, when normalizing the grammar. Statement* = Statement* = Statement+ Statement+ = Statement+ Statement Statement+ = Statement {ID \",\"}* = {ID \",\"}* = {ID \",\"}+ {ID \",\"}+ = {ID \",\"}+ \",\" {ID \",\"} {ID \",\"}+ = {ID \",\"} When parsing a context-free list, SDF3 produces a flattened list as an AST node such as [Statement, ..., Statement] or [ID, ..., ID] . Note that because the separator is a literal, it does not appear in the AST. Alternative \u00b6 Alternative symbols express the choice between two symbols, for example, ID | INT . That is, the symbol ID | INT can be parsed as either ID or INT . For that reason, SDF3 normalizes alternatives by generating the following productions: ID | INT = ID ID | INT = INT Note that SDF3 only allow alternative symbols to occur in lexical syntax. Furthermore, note that the alternative operator is right associative and binds stronger than any operator. That is, ID \",\" | ID \";\" expresses ID (\",\" | ID) \";\" . To express (ID \",\") | (ID \";\") , we can use a sequence symbol. Sequence \u00b6 A sequence operator allows grouping of two or more symbols. Sequences are useful when combined with other symbols such, lists or optionals, for example (\"e\" [0-9]+)? . Like alternative symbols, sequences can only occur in lexical syntax. A sequence symbol is normalized as (\"e\" [0-9]+) = \"e\" [0-9]+ Labeled symbols \u00b6 SDF3 supports decorating symbols with labels, such as myList:{elem:Stmt \";\"}* . The labels have no semantics but can be used by other tools that use SDF3 grammars as input. LAYOUT \u00b6 The LAYOUT symbol is a reserved sort name. It is used to indicate the whitespace that can appear in between context-free symbols. The user must define the symbol LAYOUT such as: LAYOUT = [\\ \\t\\n] Note that the production above should be defined in the lexical syntax.","title":"Symbols"},{"location":"references/syntax/symbols/#symbols","text":"The building block of SDF3 productions is a symbol. SDF3 symbols can be compared to terminals and non-terminals in other grammar formalisms. The elementary symbols are character classes, literals, and sorts. Intrinsically, only character classes are real terminal symbols. All other symbols represent non-terminals. SDF3 also support symbols that capture BNF-like notation such as lists, optionals, alternatives, and sequences. Note that these symbols are also non-terminals, and are just shorthands for common structures present in context-free grammars.","title":"Symbols"},{"location":"references/syntax/symbols/#character-classes","text":"Character classes occur only in lexical syntax and are enclosed by [ and ] . A character class consists of a list of zero or more characters (which stand for themselves) such as [x] to represent the character x , or character ranges, as an abbreviation for all the characters in the range such as [0-9] representing 0 , 1 , ..., 9 . A valid range consists of [c1-c2] , where the character c2 has a higher ASCII code than c1 . Note that nested character classes can also be concatenated within the same character class symbol, for example [c1c2-c3c4-c5] includes the characters c1 and the ranges c2-c3 , c4-c5 . In this case, the nested character classes do not need to be ordered, as SDF3 orders them when performing a normalization step. Escaped Characters : SDF3 uses a backslash ( \\ ) as a escape for the quoting of special characters. One should use \\c whenever c is not a digit or a letter in a character class. Arbitrary Unicode code points can be included in a character class by writing an escaped integer, which is particularly useful for representing characters outside the printable ASCII range. The integer can be a binary, octal, decimal, or hexadecimal number, for example: \\0b101010 , \\052 , \\42 , and \\0x2A all represent the code point 42, or the '*' character. Additionally, special ASCII characters are represented by: \\t : horizontal tabulation \\n : newline character \\v : vertical tabulation \\f : form feed \\r : carriage return Character Class Operators : SDF3 provides the following operators for character classes: (complement) ~ : Accepts all the characters that are not in the original class. (difference) / : Accepts all the characters in the first class unless they are in a second class. (union) \\/ : Accepts all the characters in either character classes. (intersection) /\\ : Accepts all the characters that are accepted by both character classes. Note that the first operator is unary and the other ones are left associative binary operators. Furthermore, such operators are not applicable to other symbols in general.","title":"Character classes"},{"location":"references/syntax/symbols/#literals","text":"A literal symbol defines a fixed length word. This usually corresponds to a terminal symbol in ordinary context-free grammars, for example \"true\" or \"+\" . Literals must always be quoted and consist of (possibly escaped) ASCII characters. As literals are also regular non-terminals, SDF3 automatically generates productions for them in terms of terminal symbols. \"definition\" = [d][e][f][i][n][i][t][i][o][n] Note that the production above defines a case-sensitive implementation of the defined literal. Case-insensitive literals are defined using single-quoted strings as in 'true' or 'else' . SDF3 generates a different production for case-insensitive literals as 'definition' = [dD][eE][fF][iI][nN][iI][tT][iI][oO][nN] The literal above accepts case-insensitive inputs such as definition , DEFINITION , DeFiNiTiOn or defINITION .","title":"Literals"},{"location":"references/syntax/symbols/#sorts","text":"A sort corresponds to a plain non-terminal, e.g. Statement or Exp . Sort names start with a capital letter and may be followed by letters, digits, hyphens, or underscores. Note that unlike SDF2, SDF3 does not support parameterized sorts (yet!). Sorts are declared by listing their name in the appropriate sorts section, which have the following forms. For context-free sorts: context-free sorts <Sort>* For lexical sorts: lexical sorts <Sort>* SDF3 also supports kernel sorts: sorts <Sort>* Note Kernel sorts should be suffixed with -CF or -LEX , depending on whether they are context-free sorts or lexical sorts. When a sort in a sorts block does not have a suffix, it is treated as a context-free sort. Writing a sort in these sections only indicates that a sort has been declared, even if it does not have any explicit production visible.","title":"Sorts"},{"location":"references/syntax/symbols/#optionals","text":"SDF3 provides a shorthand for describing zero or exactly one occurrence of a sort by appending the sort with ? . For example, the sort Extends? can be parsed as Extends or without consuming any input. Internally, SDF3 generates the following productions after normalizing the grammar:: Extends?.None = Extends?.Some = Extends Note that using ? adds the constructors None and Some to the final abstract syntax tree.","title":"Optionals"},{"location":"references/syntax/symbols/#lists","text":"Lists symbols as the name says, indicate that a symbol should occur several times. In this way, it is also possible to construct flat structures to represent them. SDF3 provides support for two types of lists, with and without separators. Furthermore, it is also possible to indicate whether a list can be empty ( * ) or should have at least one element ( + ). For example, a list Statement* indicates zero or more Statement , whereas a list with separator {ID \",\"}+ indicates one or more ID separated by , . Note that SDF3 only supports literal symbols as separators. Again, SDF3 generates the following productions to represent lists, when normalizing the grammar. Statement* = Statement* = Statement+ Statement+ = Statement+ Statement Statement+ = Statement {ID \",\"}* = {ID \",\"}* = {ID \",\"}+ {ID \",\"}+ = {ID \",\"}+ \",\" {ID \",\"} {ID \",\"}+ = {ID \",\"} When parsing a context-free list, SDF3 produces a flattened list as an AST node such as [Statement, ..., Statement] or [ID, ..., ID] . Note that because the separator is a literal, it does not appear in the AST.","title":"Lists"},{"location":"references/syntax/symbols/#alternative","text":"Alternative symbols express the choice between two symbols, for example, ID | INT . That is, the symbol ID | INT can be parsed as either ID or INT . For that reason, SDF3 normalizes alternatives by generating the following productions: ID | INT = ID ID | INT = INT Note that SDF3 only allow alternative symbols to occur in lexical syntax. Furthermore, note that the alternative operator is right associative and binds stronger than any operator. That is, ID \",\" | ID \";\" expresses ID (\",\" | ID) \";\" . To express (ID \",\") | (ID \";\") , we can use a sequence symbol.","title":"Alternative"},{"location":"references/syntax/symbols/#sequence","text":"A sequence operator allows grouping of two or more symbols. Sequences are useful when combined with other symbols such, lists or optionals, for example (\"e\" [0-9]+)? . Like alternative symbols, sequences can only occur in lexical syntax. A sequence symbol is normalized as (\"e\" [0-9]+) = \"e\" [0-9]+","title":"Sequence"},{"location":"references/syntax/symbols/#labeled-symbols","text":"SDF3 supports decorating symbols with labels, such as myList:{elem:Stmt \";\"}* . The labels have no semantics but can be used by other tools that use SDF3 grammars as input.","title":"Labeled symbols"},{"location":"references/syntax/symbols/#layout","text":"The LAYOUT symbol is a reserved sort name. It is used to indicate the whitespace that can appear in between context-free symbols. The user must define the symbol LAYOUT such as: LAYOUT = [\\ \\t\\n] Note that the production above should be defined in the lexical syntax.","title":"LAYOUT"},{"location":"references/syntax/templates/","text":"Templates \u00b6 Templates are a major change in SDF3 when comparing to SDF2. They are essential when aiming to generate a nice pretty printer or generate proper syntactic code completion templates. When generating such artifacts, a general production simply introduces a whitespace in between symbols. For example, when writing a grammar rule Statement.If = \"if\" \"(\" Exp \")\" Exp \"else\" Exp and pretty printing a valid program, we would get the text in a single line separated by spaces, as: Furthermore, code completion would consider the same indentation when inserting code snippets. However, when using template productions such as Statement.If = < if (<Exp>) <Exp> else <Exp>> We would get the following program: Again, code completion would also consider this indentation for proposals. That is, in template productions, the surrounding layout is used to nicely pretty print programs and its code completion suggestions. Template Productions \u00b6 Template productions are an alternative way of defining productions. Similarly, they consist of a left-hand side and a right-hand side separated by = . The left-hand side is the same as for productive rules. The right-hand side is a template delimited by < and > . The template can contain zero or more symbols: <Sort> = < <Symbol>* > <Sort>.<Constructor> = < <Symbol>* > Alternatively, square brackets can be used to delimit a template: <Sort> = [ <Symbol>* ] <Sort>.<Constructor> = [ <Symbol>* ] The symbols in a template can either be placeholders or literal strings. It is worth noting that: placeholders need to be enclosed within the same delimiters (either <...> or [...] ) as the template; literal strings need not not be enclosed within quotation marks; literal strings are tokenized on space characters (whitespace, tab); additionally, literal strings are tokenized on boundaries between characters from the set given by the tokenize option, see the tokenize template option; placeholders translate literally. If a separator containing any layout characters is given, the placeholder maps to a list with separator that strips the layout. An example of a template rule: Exp.Addition = < <Exp> + <Exp> > Here, the + symbol is a literal string and <Exp> is a placeholder for sort Exp . Placeholders are of the form: <Sort?> : optional placeholder <Sort*> : repetition (0...n) <Sort+> : repetition (1...n) <{Sort \",\"}*> : repetition with separator Case-insensitive Literals \u00b6 As we showed before, SDF3 allows defining case-insensitive literals as single-quoted strings in regular productions. For example: Exp.If = 'if' \"(\" Exp \")\" Exp 'else' Exp accepts case-insensitive keywords for if and else such as if , IF , If , else , ELSE or ELsE . However, to generate case-insensitive literals from template productions, it is necessary to add annotate these productions as case-insensitive. For example, a template production: Exp.If = < if(<Exp>) <Exp> else <Exp> > {case-insensitive} accepts the same input as the regular production mentioned before. Moreover, lexical symbols can also be annotated as case-insensitive to parse as such. The constructed abstract syntax tree contains lower-case symbols, but the original term is preserved via origin-tracking. For example: ID = [a-zA-z][a-zA-Z0-9]* {case-insensitive} can parse foo , Foo , FOo , fOo , foO , fOO or FOO . Whichever option generates a node \"foo\" in the abstract syntax tree. By consulting the origin information on this node, it is possible to know which term was used as input to the parser. Template options \u00b6 Template options are options that are applied to the current file. A template options section is structured as follows: template options <TemplateOption*> Multiple template option sections are not supported. If multiple template option sections are specified, the last one is used. There are three kinds of template options. keyword \u00b6 Convenient way for setting up lexical follow restrictions for keywords. See the section on follow restrictions for more information. The structure of the keyword option is as follows: keyword -/- <Pattern> This will add a follow restriction on the pattern for each keyword in the language. Keywords are automatically detected, any terminal that ends with an alphanumeric character is considered a keyword. Multiple keyword options are not supported. If multiple keyword options are specified, the last one is used. Note that this only sets up follow restrictions, rejection of keywords as identifiers still needs to be written manually. tokenize \u00b6 Specifies which characters may have layout around them. The structure of a tokenize option is as follows: tokenize : \"<Character*>\" Consider the following grammar specification: template options tokenize : \"(\" context-free syntax Exp.Call = <<ID>();> Because layout is allowed around the ( and ) characters, there may be layout between () and ; in the template rule. If no tokenize option is specified, it defaults to the default value of () . Multiple tokenize options are not supported. If multiple tokenize options are specified, the last one is used. reject Convenient way for setting up reject rules for keywords. See the section on rejections_ for more information. The structure of the reject option is as follows: Symbol = keyword {attrs} where Symbol is the symbol to generate the rules for. Note that attrs can be include any attribute, but by using reject , reject rules such as ID = \"true\" {reject} are generated for all keywords that appear in the templates. Multiple reject template options are not supported. If multiple reject template options are specified, the last one is used.","title":"Templates"},{"location":"references/syntax/templates/#templates","text":"Templates are a major change in SDF3 when comparing to SDF2. They are essential when aiming to generate a nice pretty printer or generate proper syntactic code completion templates. When generating such artifacts, a general production simply introduces a whitespace in between symbols. For example, when writing a grammar rule Statement.If = \"if\" \"(\" Exp \")\" Exp \"else\" Exp and pretty printing a valid program, we would get the text in a single line separated by spaces, as: Furthermore, code completion would consider the same indentation when inserting code snippets. However, when using template productions such as Statement.If = < if (<Exp>) <Exp> else <Exp>> We would get the following program: Again, code completion would also consider this indentation for proposals. That is, in template productions, the surrounding layout is used to nicely pretty print programs and its code completion suggestions.","title":"Templates"},{"location":"references/syntax/templates/#template-productions","text":"Template productions are an alternative way of defining productions. Similarly, they consist of a left-hand side and a right-hand side separated by = . The left-hand side is the same as for productive rules. The right-hand side is a template delimited by < and > . The template can contain zero or more symbols: <Sort> = < <Symbol>* > <Sort>.<Constructor> = < <Symbol>* > Alternatively, square brackets can be used to delimit a template: <Sort> = [ <Symbol>* ] <Sort>.<Constructor> = [ <Symbol>* ] The symbols in a template can either be placeholders or literal strings. It is worth noting that: placeholders need to be enclosed within the same delimiters (either <...> or [...] ) as the template; literal strings need not not be enclosed within quotation marks; literal strings are tokenized on space characters (whitespace, tab); additionally, literal strings are tokenized on boundaries between characters from the set given by the tokenize option, see the tokenize template option; placeholders translate literally. If a separator containing any layout characters is given, the placeholder maps to a list with separator that strips the layout. An example of a template rule: Exp.Addition = < <Exp> + <Exp> > Here, the + symbol is a literal string and <Exp> is a placeholder for sort Exp . Placeholders are of the form: <Sort?> : optional placeholder <Sort*> : repetition (0...n) <Sort+> : repetition (1...n) <{Sort \",\"}*> : repetition with separator","title":"Template Productions"},{"location":"references/syntax/templates/#case-insensitive-literals","text":"As we showed before, SDF3 allows defining case-insensitive literals as single-quoted strings in regular productions. For example: Exp.If = 'if' \"(\" Exp \")\" Exp 'else' Exp accepts case-insensitive keywords for if and else such as if , IF , If , else , ELSE or ELsE . However, to generate case-insensitive literals from template productions, it is necessary to add annotate these productions as case-insensitive. For example, a template production: Exp.If = < if(<Exp>) <Exp> else <Exp> > {case-insensitive} accepts the same input as the regular production mentioned before. Moreover, lexical symbols can also be annotated as case-insensitive to parse as such. The constructed abstract syntax tree contains lower-case symbols, but the original term is preserved via origin-tracking. For example: ID = [a-zA-z][a-zA-Z0-9]* {case-insensitive} can parse foo , Foo , FOo , fOo , foO , fOO or FOO . Whichever option generates a node \"foo\" in the abstract syntax tree. By consulting the origin information on this node, it is possible to know which term was used as input to the parser.","title":"Case-insensitive Literals"},{"location":"references/syntax/templates/#template-options","text":"Template options are options that are applied to the current file. A template options section is structured as follows: template options <TemplateOption*> Multiple template option sections are not supported. If multiple template option sections are specified, the last one is used. There are three kinds of template options.","title":"Template options"},{"location":"references/syntax/templates/#keyword","text":"Convenient way for setting up lexical follow restrictions for keywords. See the section on follow restrictions for more information. The structure of the keyword option is as follows: keyword -/- <Pattern> This will add a follow restriction on the pattern for each keyword in the language. Keywords are automatically detected, any terminal that ends with an alphanumeric character is considered a keyword. Multiple keyword options are not supported. If multiple keyword options are specified, the last one is used. Note that this only sets up follow restrictions, rejection of keywords as identifiers still needs to be written manually.","title":"keyword"},{"location":"references/syntax/templates/#tokenize","text":"Specifies which characters may have layout around them. The structure of a tokenize option is as follows: tokenize : \"<Character*>\" Consider the following grammar specification: template options tokenize : \"(\" context-free syntax Exp.Call = <<ID>();> Because layout is allowed around the ( and ) characters, there may be layout between () and ; in the template rule. If no tokenize option is specified, it defaults to the default value of () . Multiple tokenize options are not supported. If multiple tokenize options are specified, the last one is used. reject Convenient way for setting up reject rules for keywords. See the section on rejections_ for more information. The structure of the reject option is as follows: Symbol = keyword {attrs} where Symbol is the symbol to generate the rules for. Note that attrs can be include any attribute, but by using reject , reject rules such as ID = \"true\" {reject} are generated for all keywords that appear in the templates. Multiple reject template options are not supported. If multiple reject template options are specified, the last one is used.","title":"tokenize"},{"location":"references/testing/","text":"SPT: Spoofax Testing Language \u00b6","title":"SPT: Spoofax Testing Language"},{"location":"references/testing/#spt-spoofax-testing-language","text":"","title":"SPT: Spoofax Testing Language"},{"location":"tutorials/","text":"Tutorials \u00b6 This page lists tutorials that take you step-by-step through a project to learn a variety of concepts and aspects of Spoofax in a specific scope. For guides on achieving specific tasks, see the How To's section. For the Spoofax language reference, see the References section. No tutorials yet.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"This page lists tutorials that take you step-by-step through a project to learn a variety of concepts and aspects of Spoofax in a specific scope. For guides on achieving specific tasks, see the How To's section. For the Spoofax language reference, see the References section. No tutorials yet.","title":"Tutorials"}]}